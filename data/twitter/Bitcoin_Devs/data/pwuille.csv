username;date;retweets;favorites;text;geo;mentions;hashtags;id;permalink
pwuille;2018-03-05 11:32;0;1;"Oh, you want O(log n) for adding N elements. I thought you wanted O(log n) *per element* for adding N elements. Yeah, no idea.";;;;"970743839148400645";https://twitter.com/pwuille/status/970743839148400645
pwuille;2018-03-05 10:43;0;1;"When inserting a new element to the tree, you show the two leaves it falls between (proving that it's being inserted in the right place), and enough information to do the rebalancing (which just depends on the position of inserting), for example in a red-black tree.";;;;"970731454916386816";https://twitter.com/pwuille/status/970731454916386816
pwuille;2018-03-05 09:23;0;3;"If the elements in your tree are required to be sorted, you can do non-inclusion proofs by revealing the two adjacent leafs which the query should be between. I believe proving a rebalancing of a Merkle tree is amortized O(log(n)) at least?";;;;"970711403207282690";https://twitter.com/pwuille/status/970711403207282690
pwuille;2018-03-03 06:19;19;151;"At Financial Cryptography 2018 even the food needs to be quantum resistant. pic.twitter.com/fHJfoJu8eE";;;;"969940286448205825";https://twitter.com/pwuille/status/969940286448205825
pwuille;2018-03-02 09:07;6;43;"FWIW, my estimate for batch validation of a Sapling-sized circuit in BP is around 200ms. I very much agree that that is still not an acceptable time in a blockchain setting.";;;;"969620290828406787";https://twitter.com/pwuille/status/969620290828406787
pwuille;2018-03-02 08:57;2;22;"I'm sad to hear there are misunderstandings, but we do observe in the post "for more than a few thousand gates, SNARKs are the clear winner". I'm happy to relay suggestions for improving it, but we can't explain all subtle trade-offs either in a blog post for a general audience.";;;;"969617614061400066";https://twitter.com/pwuille/status/969617614061400066
pwuille;2018-03-02 08:07;6;30;"To me, the largest advantage is indeed the lack of trusted setup, and I believe that for some applications this is the difference between feasible and not. However, that choice comes with serious trade-offs that matter in many cases and not in some. More options is better.";;;;"969605162640789504";https://twitter.com/pwuille/status/969605162640789504
pwuille;2018-03-02 08:05;0;5;"Of course, not all things are equal, and for most applications BPs come with serious downsides. But not all; I'm just happy to see more possible trade-offs.";;;;"969604586288959494";https://twitter.com/pwuille/status/969604586288959494
pwuille;2018-03-02 08:04;1;13;"I'm very happy to see research on improving the trusted setup and its scalability. I don't believe it counts as "solving" it though - all other things equal, you'd much rather have no setup, if only for simplifying deployability.";;;;"969604357070172166";https://twitter.com/pwuille/status/969604357070172166
pwuille;2018-03-02 08:00;3;15;"No offence, but I think you're overstating BP's advantages. (1) For simple statements BPs are faster to batch validate than SNARKs, but for the more common case of complex circuits or no ability to batch, SNARKs clearly win (2) Depends on context (3) BPs also build on past work";;;;"969603296523669504";https://twitter.com/pwuille/status/969603296523669504
pwuille;2018-03-01 03:29;29;118;"If the question is could Bitcoin surpass Monero's privacy at it exists today: probably. Will Bitcoin be able to surpass research projects of that time: probably not. And that is fine.";;;;"969172818297581568";https://twitter.com/pwuille/status/969172818297581568
pwuille;2018-03-01 03:26;1;22;"No apology needed. I'm just trying to clear up misunderstandings that many people have about the various ways these technologies interact.";;;;"969172063062839297";https://twitter.com/pwuille/status/969172063062839297
pwuille;2018-03-01 03:21;5;32;"So I'm happy to see research in that area, but IMO the tradeoffs such systems make are unacceptable for Bitcoin. Pure CT (which only hides amounts), and using other tech (incentivized mixing, tumblebit, ...) for reducing linkability of transactions seems much more viable.";;;;"969170866016804864";https://twitter.com/pwuille/status/969170866016804864
pwuille;2018-03-01 03:10;2;13;"So I think the only real question to ask is about opinions on what should be prioritized and hopefully proposed. All privacy technology comes with a cost, and unfortunately Monero (and Zcash) style transactions have a very significant impact on scalability (spent coins db).";;;;"969168010111012864";https://twitter.com/pwuille/status/969168010111012864
pwuille;2018-03-01 03:06;2;19;"If you're talking about what technology Bitcoin can adopt, the answer is of course (almost) anything the ecosystem agrees upon. If we all want a way to do Monero-style transactions in Bitcoin, then Bitcoin could adopt an extension block with exactly that.";;;;"969167062642909184";https://twitter.com/pwuille/status/969167062642909184
pwuille;2018-03-01 03:04;1;11;"Perhaps the question you want to ask is what a Bitcoin-with-confidential-transactions would look like (and those could optionally use Bulletproofs). The answer however depends very much on what that hypothetical looks like.";;;;"969166380980416512";https://twitter.com/pwuille/status/969166380980416512
pwuille;2018-03-01 03:02;8;42;""Even with bulletproofs" is a meaningless question. Bulletproofs are a way of implementing zero-knowledge proofs. Bitcoin (right now) doesn't use zero knowledge proofs, so there is no way Bulletproofs fit in in any way.";;;;"969165857589997568";https://twitter.com/pwuille/status/969165857589997568
pwuille;2018-02-27 20:39;0;1;"More accurate numbers: 10 min, 6.93 min, 20 min, 16.78 min.";;;;"968707195616530433";https://twitter.com/pwuille/status/968707195616530433
pwuille;2018-02-27 05:36;1;4;"Mean time between random blocks: 10 min. Median time between random blocks: 7 min. Mean time between blocks around random time: 20 min. Median time between blocks around random time: 17 min.";;;;"968479999463444482";https://twitter.com/pwuille/status/968479999463444482
pwuille;2018-02-26 15:09;0;8;"That's what makes it a great question";;;;"968261651358277632";https://twitter.com/pwuille/status/968261651358277632
pwuille;2018-02-26 15:04;1;13;"No. The rate of blocks is one per 10 minutes. It's only when picking blocks based on a random point in time (rather than a random block) you get the average 20 minutes. This is because you're more likely to be randomly looking during a longer block than a shorter block.";;;;"968260572331630593";https://twitter.com/pwuille/status/968260572331630593
pwuille;2018-02-26 14:32;0;10;"It's 10 minutes on average between random blocks. It's 20 minutes between the blocks when chosen based on a random point in time between them (which is biased towards longer blocks).";;;;"968252576721489920";https://twitter.com/pwuille/status/968252576721489920
pwuille;2018-02-26 14:31;0;3;"It is true for random points in time. And times at which transactions are created (or better: the time that you happen to look at how long it's been) are uncorrelated with blocks, so they can be treated as uniformly random times.";;;;"968252256582848512";https://twitter.com/pwuille/status/968252256582848512
pwuille;2018-02-26 14:16;0;4;"I formulated the question differently, by making it explicit that I start with a random point in time. However, the scenario in the blog is identical; it's wondering how long the block will be that your transaction is trying to get into, without knowledge of when the last one was";;;;"968248531889852417";https://twitter.com/pwuille/status/968248531889852417
pwuille;2018-02-26 14:06;0;0;"Given how many people explained their 15 answer as "5 minutes since the last block (?) and 10 minutes until the next one", I guess you were right! I intended to add twice the median block interval, but had an off-by-one and typed 15 instead of 14.";;;;"968245795861475328";https://twitter.com/pwuille/status/968245795861475328
pwuille;2018-02-26 14:03;0;1;"This is unfortunately wrong; the time since the last block or the time until the next block are identical (both are 10 minutes, so the total is 20 minutes).";;;;"968245038626082821";https://twitter.com/pwuille/status/968245038626082821
pwuille;2018-02-26 14:01;0;15;"But if it's not urgent, you'll not even be looking at the total time since the last block. So in a way you don't even need to invoke Murphy. Just the fact that you care about the timing will make it look longer...";;;;"968244571489624065";https://twitter.com/pwuille/status/968244571489624065
pwuille;2018-02-26 13:51;6;38;"Here is the answer: https:// twitter.com/pwuille/status /968241292189761536 …";;;;"968242185987678211";https://twitter.com/pwuille/status/968242185987678211
pwuille;2018-02-26 13:48;34;176;"The correct answer to https:// twitter.com/pwuille/status /967878361782652928 … is: 20 minutes. See Russell's blog for more information: http:// r6.ca/blog/20180225T 160548Z.html …";;;;"968241292189761536";https://twitter.com/pwuille/status/968241292189761536
pwuille;2018-02-26 07:52;0;1;"It's nitpicking for sure, but I think you may miss what Tim is asking: is your statement true for *every* point, or only when they're picked randomly?";;;;"968151733741543425";https://twitter.com/pwuille/status/968151733741543425
pwuille;2018-02-26 07:24;0;0;"https:// en.wikipedia.org/wiki/Expected_ value …";;;;"968144716838658048";https://twitter.com/pwuille/status/968144716838658048
pwuille;2018-02-26 06:09;0;0;"That's called a confidence interval.";;;;"968125771507294208";https://twitter.com/pwuille/status/968125771507294208
pwuille;2018-02-26 05:36;0;1;"The question assumes that the hashrate/difficulty ratio is accurate, so the rate of blocks is 1 per 10 minutes on average all the time.";;;;"968117484082647040";https://twitter.com/pwuille/status/968117484082647040
pwuille;2018-02-26 05:25;0;22;"Twice as random as 4.";;;;"968114802710274048";https://twitter.com/pwuille/status/968114802710274048
pwuille;2018-02-26 04:33;0;1;"That's apparently not one of the options.";;;;"968101769644597248";https://twitter.com/pwuille/status/968101769644597248
pwuille;2018-02-26 01:09;0;1;"There is no "current". The question is just: pick a point in time T. What is the average time between the last block created before T and the first block after T.";;;;"968050260684787712";https://twitter.com/pwuille/status/968050260684787712
pwuille;2018-02-25 20:32;0;0;"The expected value is the average of what you would observe after many experiments. I'm not going to comment on the rest until the poll ends.";;;;"967980672160862208";https://twitter.com/pwuille/status/967980672160862208
pwuille;2018-02-25 18:56;0;0;"Read the question again.";;;;"967956448671133696";https://twitter.com/pwuille/status/967956448671133696
pwuille;2018-02-25 15:44;0;2;"But the question is not about "per block". It's about a random point in time and the blocks around it.";;;;"967908286845550593";https://twitter.com/pwuille/status/967908286845550593
pwuille;2018-02-25 15:35;0;2;"The problem is stated correctly.";;;;"967905879071821824";https://twitter.com/pwuille/status/967905879071821824
pwuille;2018-02-25 15:11;0;5;"The assumption is that the difficulty is always accurate (which is not true in reality).";;;;"967899789865242624";https://twitter.com/pwuille/status/967899789865242624
pwuille;2018-02-25 14:57;0;13;"Assuming the hashrate/difficulty ratio was always accurate, the answer should be 10 minutes.";;;;"967896411210682368";https://twitter.com/pwuille/status/967896411210682368
pwuille;2018-02-25 14:52;0;3;"The tblb command is about what percentage of *blocks* have a certain duration. This question is about a random point in *time* and the blocks around it.";;;;"967895103909003265";https://twitter.com/pwuille/status/967895103909003265
pwuille;2018-02-25 14:47;0;5;"That's not answering the same thing.";;;;"967893870724907011";https://twitter.com/pwuille/status/967893870724907011
pwuille;2018-02-25 14:31;0;8;"It's still capital gains. The tax rate for short term capital gains just happens to be equal to the income tax rate.";;;;"967889813193003010";https://twitter.com/pwuille/status/967889813193003010
pwuille;2018-02-25 14:10;0;5;""Translate from Indonesian"";;;;"967884638977970176";https://twitter.com/pwuille/status/967884638977970176
pwuille;2018-02-25 14:09;0;8;"Ok. Pick a window of time, and look at all the blocks generated within that window. Pick a uniformly random point in that window, and look at the block before it and the one after it. As the size of the window grows, the difference between them converges to what number?";;;;"967884174282563584";https://twitter.com/pwuille/status/967884174282563584
pwuille;2018-02-25 13:53;0;7;"There is no "current" block. The question is asking about the time between the last mined block at the point in time you're looking at, and the first block found after that point in time.";;;;"967880311005642753";https://twitter.com/pwuille/status/967880311005642753
pwuille;2018-02-25 13:52;0;2;"Well, I think it may be less intuitive than that. For example, unrealized gains are not taxed I believe. For someone entirely unfamiliar with taxation this may be no less a surprise than the fact that realized gains are taxable.";;;;"967879886546309131";https://twitter.com/pwuille/status/967879886546309131
pwuille;2018-02-25 13:45;40;105;"Assume a hashrate and difficulty corresponding to 1 block per 10 minutes. If I uniformly randomly pick a point in time, what is the expected time between the previous block and the next block? (credit: Russell O'Connor)";;;;"967878361782652928";https://twitter.com/pwuille/status/967878361782652928
pwuille;2018-02-25 13:00;0;1;"I guess what you're saying is "Why do people think they can make money in a way that isn't considered taxable in some way". I don't know...";;;;"967866934250352640";https://twitter.com/pwuille/status/967866934250352640
pwuille;2018-02-25 12:24;1;19;"Actually, gains from selling cryptocurrency are not treated as income but as capital gains, and subject to capital gains tax in the US (IANAL).";;;;"967857924994420738";https://twitter.com/pwuille/status/967857924994420738
pwuille;2018-02-23 06:50;0;5;"I think systems that require setup MPCs will always be a burden for inclusion in a protocol; lowering the barrier is great, but it's not the same. About reducing memory requirements: great to hear!";;;;"967048967874924545";https://twitter.com/pwuille/status/967048967874924545
pwuille;2018-02-23 06:45;9;41;"For many applications SNARKs are the only feasible option. But it also goes the other way: if a trusted setup is no option, or prover memory is very constrained, BPs may be the only feasible option as well. All these systems have different trade-offs, and more options is great.";;;;"967047695620853761";https://twitter.com/pwuille/status/967047695620853761
pwuille;2018-02-23 06:38;0;9;"That's fair. To me BP is exciting because they make for some - not all - applications using a ZKP a realistic option. Sure, SNARKs are available, but the extra assumptions and setup make it a very nontrivial decision to include in a protocol.";;;;"967046008680189953";https://twitter.com/pwuille/status/967046008680189953
pwuille;2018-02-23 06:21;21;53;"Another data point: MRL's Bulletproofs implementation uses Ed25519 and verifies a 64-bit rangeproof in 5.2 ms. Our implementation in libsecp256k1 does that (on same hardware) in 2.4 ms. I don't know how comparable the optimizations are, so not necessarily a fair curve comparison.";;;;"967041659816030210";https://twitter.com/pwuille/status/967041659816030210
pwuille;2018-02-23 06:14;0;4;"Please, it says "under standard assumptions with no trusted setup". Nobody is claiming SNARKs can't be 128-bit secure. And for sufficiently simple circuits, when using batch validation, BP verification is faster than SNARK implementations (AFAIK).";;;;"967039877115207680";https://twitter.com/pwuille/status/967039877115207680
pwuille;2018-02-23 05:39;0;5;"For complex proofs in performance-critical applications, SNARKs will obviously win. Though the fact that Bulletproofs can natively deal with Pedersen commitments means that some circuits can be much simpler (no EC multiply inside circuit), plus batch validation helps for some.";;;;"967031048210141184";https://twitter.com/pwuille/status/967031048210141184
pwuille;2018-02-23 05:29;0;6;"The last time I compared them (maybe 2 years ago), libsecp256k1 with all optimizations enabled was slightly faster than ed25519-donna. Perhaps that changed since, but I expect it to be a very small constant factor at best.";;;;"967028622652567552";https://twitter.com/pwuille/status/967028622652567552
pwuille;2018-02-23 02:08;0;11;"Looks like a totally reasonable ring signature with ring size 1 to me.";;;;"966978002725765120";https://twitter.com/pwuille/status/966978002725765120
pwuille;2018-02-22 13:23;4;12;"Also note that "privacy" is not a yes-no thing. Good privacy requires measures on several fronts, and that's not restricted to consensus changes. Also P2P routing, tx relay, address reuse practices...";;;;"966785659833810944";https://twitter.com/pwuille/status/966785659833810944
pwuille;2018-02-22 13:02;0;6;"Of course, I wouldn't be working on projects like this otherwise. However this is not a short term thing, and depends on many factors.";;;;"966780365460340738";https://twitter.com/pwuille/status/966780365460340738
pwuille;2018-02-22 13:01;0;3;"This is complicated, because there is no such thing as a "roadmap for BTC"; people contribute their time and have their own priorities, and what eventually becomes part of Bitcoin depends on their time as well as what the community accepts.";;;;"966780058546458625";https://twitter.com/pwuille/status/966780058546458625
pwuille;2018-02-22 12:37;1;6;""Will Bitcoin able to have STARKs" is as meaningless as asking if Bitcoin will be able to have tape drives. The answer is.... eh, maybe if you find a use case. Otherwise they're just solutions looking for a problem.";;;;"966773894601461760";https://twitter.com/pwuille/status/966773894601461760
pwuille;2018-02-22 12:33;0;7;"CT does not belong in that sequence at all. CT is a way to hide transaction amounts in blockchains. STARKs, BPs and SNARKs are zero-knowledge proof systems. CT just happens to need such a proof system (and it could use any of those).";;;;"966772957057093634";https://twitter.com/pwuille/status/966772957057093634
pwuille;2018-02-22 11:57;0;1;"Yes, thanks for pointing that out. I should clarify by adding "for reasonable problem sizes" or so.";;;;"966763845644619777";https://twitter.com/pwuille/status/966763845644619777
pwuille;2018-02-22 11:28;9;48;"Bulletproofs are more efficient than STARKs (but BP is not quantum resistant), but certainly not more efficient than SNARKs (but BP needs no trusted setup).";;;;"966756657630937093";https://twitter.com/pwuille/status/966756657630937093
pwuille;2018-02-22 05:08;0;3;"Binary xor with 1 = flip the lower bit = swap odd with even.";;;;"966660870582521856";https://twitter.com/pwuille/status/966660870582521856
pwuille;2018-02-22 05:02;0;3;"You win.";;;;"966659583849705472";https://twitter.com/pwuille/status/966659583849705472
pwuille;2018-02-22 05:02;0;1;"(i ^ 1) swaps even and odd positions. Negative indices in Python count backwards from the end. Together: reverse characters, but undo that effect within groups of 2.";;;;"966659439209123842";https://twitter.com/pwuille/status/966659439209123842
pwuille;2018-02-22 03:55;0;9;"Ok, what about: "".join(a[-(i^1)-1] for i in range(len(a)))";;;;"966642618833743872";https://twitter.com/pwuille/status/966642618833743872
pwuille;2018-02-22 03:49;1;1;"Correct, Bulletproofs don't have a trusted setup, so no need for a ceremony. Confidential transactions using Bulletproofs still use a Pedersen commitment for amounts; it's just a better better technology for proving the amounts don't overflow.";;;;"966641182905458689";https://twitter.com/pwuille/status/966641182905458689
pwuille;2018-02-22 03:46;0;9;"No they're not. Bulletproofs are more powerful and more efficient than the technology used behind earlier confidential transaction approaches. SNARKS are even more efficient, but require a trusted setup and more novel cryptographic assumptions.";;;;"966640233671520256";https://twitter.com/pwuille/status/966640233671520256
pwuille;2018-02-21 21:56;0;4;"Oh! reversed("".join([a[i ^ 1] for i in range(len(a))])) then? This doesn't look really better anymore...";;;;"966552170400239616";https://twitter.com/pwuille/status/966552170400239616
pwuille;2018-02-21 21:52;0;3;"How about [a[i ^ 1] for i in range(len(a))] ?";;;;"966551241374470144";https://twitter.com/pwuille/status/966551241374470144
pwuille;2018-02-21 17:26;153;363;"A blog post about #Bulletproofs , their performance, applications, and history by Andrew Poelstra (cc @benediktbuenz ): https:// blockstream.com/2018/02/21/bul letproofs-faster-rangeproofs-and-much-more.html …";;@benediktbuenz;#Bulletproofs;"966484355962032133";https://twitter.com/pwuille/status/966484355962032133
pwuille;2018-02-19 23:50;0;7;"Correct. The old ring signature based CT construction could be made either perfectly hiding or unconditionally sound, but not both (which is theoretically impossible). Bulletproofs cannot be made unconditionally sound.";;;;"965856128557969408";https://twitter.com/pwuille/status/965856128557969408
pwuille;2018-02-17 14:57;0;21;"It's an 8 character checksum, of course it has an (even) lower chance of failure than Bech32 (which has 6 checksum characters). However, even with a 10% typo chance per character Bech32 fails to less than once per 4 billion. Adding characters to reduce that further is overkill.";;;;"964997301558132736";https://twitter.com/pwuille/status/964997301558132736
pwuille;2018-02-12 18:47;1;39;"Hello @breadapp , I think you misunderstood the context of that paper. It's not an actual proposal for Schnorr signatures in Bitcoin, where many possibilities are still open. There is a lot of interesting research going on, but these are not things that will happen immediately.";;@breadapp;;"963243283399942144";https://twitter.com/pwuille/status/963243283399942144
pwuille;2018-02-11 13:29;0;2;"More: what you want is a new signature scheme whose pubkeys can be derived from the existing pubkeys without access to private keys. Any such scheme will be subject to the same cryptographic assumptions as the original scheme (this is just my intuition, i may be wrong).";;;;"962800812102631424";https://twitter.com/pwuille/status/962800812102631424
pwuille;2018-02-11 11:36;0;3;"Technically, you could devise a different scheme with different assumptions that can reuse private keys but not public keys. This is pointless however for the situation you're asking about, as you'd still need access to the private key to compute the new public keys.";;;;"962772312918339584";https://twitter.com/pwuille/status/962772312918339584
pwuille;2018-02-11 11:31;0;2;"I don't think this works. The fear is not that ECDSA would be broken, but the secp256k1 curve or EC itself. Switching to another algorithm that uses the same keys would necessarily mean remaining vulnerable to the same EC breaks.";;;;"962771112231759872";https://twitter.com/pwuille/status/962771112231759872
pwuille;2018-02-08 19:16;0;7;"You have an image of your boat?";;;;"961800957842477056";https://twitter.com/pwuille/status/961800957842477056
pwuille;2018-02-08 16:01;0;7;"Yes, the same argument applies. Whenever your attacker can potentially collaborate with you in the creation of the address, you want 128-bit collision resistance (= 256 bit hash).";;;;"961751787047825408";https://twitter.com/pwuille/status/961751787047825408
pwuille;2018-02-08 15:53;0;11;"You totally can have pay-to-pubkey hash. But the hash would need to be 256 bits.";;;;"961749831470366720";https://twitter.com/pwuille/status/961749831470366720
pwuille;2018-02-08 10:55;3;21;"ZKPs however are used inside the Confidential Transactions concept, which may make it to Bitcoin one day. Bulletproofs certainly reduced some of the hurdles there compared to earlier ideas (which required larger proofs, and were slower to verify).";;;;"961674900254552065";https://twitter.com/pwuille/status/961674900254552065
pwuille;2018-02-08 10:53;3;19;"Bulletproofs are a better way to create zero-knowledge proofs (ZKPs) without trusted setup. However, Bitcoin at this point doesn't use ZKPs anywhere, so it's not that they can just be dropped in somewhere.";;;;"961674281133355008";https://twitter.com/pwuille/status/961674281133355008
pwuille;2018-02-07 03:37;0;12;"Personally I'd go for one made out of C shells.";;;;"961202313162457088";https://twitter.com/pwuille/status/961202313162457088
pwuille;2018-02-07 00:44;4;67;"I don't think Python is the right approach when implementing a necklace.";;;;"961158601900400640";https://twitter.com/pwuille/status/961158601900400640
pwuille;2018-02-06 13:11;0;43;"I see what you did there.";;;;"960984399868174336";https://twitter.com/pwuille/status/960984399868174336
pwuille;2018-02-04 09:42;0;2;"Yes. However, BN is a multi-signature scheme (1 msg, many keys), while we need a signature aggregation scheme (many keys, each their own msg). It's easy to turn an MS into an interactive AS, thankfully.";;;;"960206935201955840";https://twitter.com/pwuille/status/960206935201955840
pwuille;2018-02-03 18:05;1;21;"It's confusing. The term "Schnorr" is used for a wide class of signature schemes. Bellare-Neven is one specific multi-signature scheme within that class.";;;;"959971029505331201";https://twitter.com/pwuille/status/959971029505331201
pwuille;2018-02-02 14:47;0;20;"You have weird friends.";;;;"959558884275793920";https://twitter.com/pwuille/status/959558884275793920
pwuille;2018-01-31 14:39;1;24;"I really wish we had aggregate signatures, so I could have signed for all of them at once!";;;;"958832096914456576";https://twitter.com/pwuille/status/958832096914456576
pwuille;2018-01-31 10:54;0;7;"We'll have updated numbers soon.";;;;"958775557805637634";https://twitter.com/pwuille/status/958775557805637634
pwuille;2018-01-30 22:40;0;3;"0.16.0 is not released yet. This document is the work in progress release notes. They're not finished yet.";;;;"958590716585922560";https://twitter.com/pwuille/status/958590716585922560
pwuille;2018-01-30 22:36;4;30;"It's faster than verifying ECDSA signatures by OpenSSL!";;;;"958589818379882496";https://twitter.com/pwuille/status/958589818379882496
pwuille;2018-01-30 19:18;1;31;"Unfortunately, @benediktbuenz was off by an order of magnitude about the speed of ECDSA verification. The latest number seems to be around 5x-7x slower than ECDSA when verifying many rangeproofs simultaneously. Not bad at all.";;@benediktbuenz;;"958539857139126272";https://twitter.com/pwuille/status/958539857139126272
pwuille;2018-01-30 11:42;147;406;"My talk on Schnorr signatures for Bitcoin at BPASE18 is online: https://www. youtube.com/watch?v=oTsjMz 3DaLs … (slides: https:// prezi.com/bihvorormznd/s chnorr-signatures-for-bitcoin/ … )";;;;"958425264861560832";https://twitter.com/pwuille/status/958425264861560832
pwuille;2018-01-30 10:12;0;3;"This is the *work in progress* document with release notes. It's the place where developers are working to write the notes for an upcoming release. 0.16.0 does not exist yet, so the link in that document indeed does not work.";;;;"958402504219181056";https://twitter.com/pwuille/status/958402504219181056
pwuille;2018-01-29 23:37;2;29;"You need a setup protocol though, to make sure keys aren't chosen to cancel out other keys. MuSig solves this if you don't want a setup. If you do a setup, you can actually do a lot more (like k-of-n thresholds and arbitrary combinations of subsets of signers).";;;;"958242797303226368";https://twitter.com/pwuille/status/958242797303226368
pwuille;2018-01-29 10:59;0;12;"Raising the block reward is absolutely a HF. But following the pre-existing reward schedule drop is not a fork at all - it's just following the rules.";;;;"958051966143180800";https://twitter.com/pwuille/status/958051966143180800
pwuille;2018-01-29 10:58;0;4;"I don't understand this analogy. A chain which maintains the 50 BTC reward forever will be invalid to old nodes. A chain which follows the subsidy reduction is compatible with all nodes.";;;;"958051620243193857";https://twitter.com/pwuille/status/958051620243193857
pwuille;2018-01-28 08:09;0;1;"Toevallig niet! :(";;;;"957646769206190086";https://twitter.com/pwuille/status/957646769206190086
pwuille;2018-01-27 21:46;0;33;"The only actual malleability-fixing proposals that would have resolved issues for multi-tx contracts were SegWit and normalized txids. The latter would have come with a 2x blowup of the UTXO set, and other complications.";;;;"957490119413387265";https://twitter.com/pwuille/status/957490119413387265
pwuille;2018-01-27 21:44;1;10;"That was indeed one of the most common sources of malleability, but perhaps ironically, not one that mattered for typical multi-transaction contracts (like LN). What did hurt was that in a multi-signature input one of the parties could just produce a second signature.";;;;"957489579153440768";https://twitter.com/pwuille/status/957489579153440768
pwuille;2018-01-26 22:46;0;10;"cryptozoology**";;;;"957142873173934080";https://twitter.com/pwuille/status/957142873173934080
pwuille;2018-01-26 09:46;0;2;"Typo in the slide, his name is Peter Dettman.";;;;"956946399228190720";https://twitter.com/pwuille/status/956946399228190720
pwuille;2018-01-25 22:17;1;123;"But are they worse than DAG jokes? - apoelstra";;;;"956773097541005312";https://twitter.com/pwuille/status/956773097541005312
pwuille;2018-01-25 22:04;2;153;"So we don't know which of you two actually signed the contract?";;;;"956769902743887872";https://twitter.com/pwuille/status/956769902743887872
pwuille;2018-01-25 11:58;0;9;"I believe it will be published soon.";;;;"956617238055870465";https://twitter.com/pwuille/status/956617238055870465
pwuille;2018-01-25 00:34;1;29;"Damn clickbait. #4 didn't surprise me at all :(";;;#4;"956445124191436801";https://twitter.com/pwuille/status/956445124191436801
pwuille;2018-01-24 15:41;0;2;"Updated!";;;;"956311110906335232";https://twitter.com/pwuille/status/956311110906335232
pwuille;2018-01-24 07:49;0;5;"That makes sense. The post clarifies afterwards that schemes already exist that provide key aggregation, but I'll try to reformulate it in a less confusing way.";;;;"956192136596111360";https://twitter.com/pwuille/status/956192136596111360
pwuille;2018-01-24 07:15;3;23;"I never claimed all Schnorr multi-signature uses should switch to MuSig, only that it's an interesting scheme that combines key aggregation with plain public-key security (please read the whole post). Even in Bitcoin I think it's only useful privately between multiple signers.";;;;"956183757526007810";https://twitter.com/pwuille/status/956183757526007810
pwuille;2018-01-24 06:58;0;4;"That's fair. The quote misses some context from the post: "is novel in combining: support for key aggregation, security in the plain public-key model". By key aggregation being new I only meant this is new terminology we're introducing - it states several schemes already have it";;;;"956179355675197441";https://twitter.com/pwuille/status/956179355675197441
pwuille;2018-01-23 17:09;0;0;"CoSi does not protect against related key attacks (section 8.5 https://www. ietf.org/archive/id/dra ft-ford-cfrg-cosi-00.txt … ). MuSig lets you combine any set of keys without restriction.";;;;"955970792046567424";https://twitter.com/pwuille/status/955970792046567424
pwuille;2018-01-23 14:21;0;0;"Well, everyone who cares about the set of signers. In a Bitcoin transaction output, I can tell someone I'll accept a payment to key X (which is really an aggregate of Y and Z). When Y and Z then spend that output, the network does not care that X is an aggregate.";;;;"955928578331369472";https://twitter.com/pwuille/status/955928578331369472
pwuille;2018-01-23 14:18;0;0;"Exactly. An earlier idea we had was using H(Xi)Xi instead, but that was vulnerable to an attack where multiple attackers together use Wagner's generalized birthday algorithm to find keys that cancel out a given key. Adding L into the hash makes that impossible (assuming DL).";;;;"955927816041742336";https://twitter.com/pwuille/status/955927816041742336
pwuille;2018-01-23 13:44;0;4;"There are many schemes that rely on the ability to combine keys together. However, to the best of my knowledge, MuSig is the first that lets you do so without additional measures to prevent some keys to be chosen to cancel out others.";;;;"955919222898548739";https://twitter.com/pwuille/status/955919222898548739
pwuille;2018-01-23 11:13;164;436;"I wrote a blog post about MuSig, introduced in the paper we published on Monday: https:// blockstream.com/2018/01/23/mus ig-key-aggregation-schnorr-signatures.html …";;;;"955881192598859776";https://twitter.com/pwuille/status/955881192598859776
pwuille;2018-01-21 16:21;1;1;"I believe yes.";;;;"955233815407947776";https://twitter.com/pwuille/status/955233815407947776
pwuille;2018-01-18 19:37;0;11;"I don't think you qualify as a gmax parody.";;;;"954196026574827520";https://twitter.com/pwuille/status/954196026574827520
pwuille;2018-01-18 14:00;2;43;"The naming is complicated and confusing. Schnorr really refers to a class of different signature schemes, but the specific schemes discussed are Bellare-Neven (2006) and MuSig (introduced in the paper) - not specifically Schnorr signatures.";;;;"954111168154451968";https://twitter.com/pwuille/status/954111168154451968
pwuille;2018-01-18 08:07;1;15;"Note that the paper is primarily about a new Schnorr-based multisignature scheme and its advantages. It is not a proposal for integrating Schnorr into Bitcoin.";;;;"954022436168613888";https://twitter.com/pwuille/status/954022436168613888
pwuille;2018-01-18 08:01;0;21;"Imagine it was not Schnorr, but a very novel new signature scheme that not everyone believes is secure. Would you be ok with your money suddenly being spendable using it? Of course not, and thankfully that's also impossible in a softfork.";;;;"954020876629942273";https://twitter.com/pwuille/status/954020876629942273
pwuille;2018-01-18 06:56;344;841;"Our paper on Schnorr-based key and signature aggregation for Bitcoin is on eprint: https:// eprint.iacr.org/2018/068";;;;"954004690223579137";https://twitter.com/pwuille/status/954004690223579137
pwuille;2018-01-17 21:43;16;63;"Bitcoin is defined by what full nodes people use: https:// twitter.com/jmcorgan/statu s/945068079893110785 …";;;;"953865331990175745";https://twitter.com/pwuille/status/953865331990175745
pwuille;2018-01-12 23:54;0;12;"What's wrong with someone waving a flag?";;;;"952086519979888640";https://twitter.com/pwuille/status/952086519979888640
pwuille;2018-01-12 02:42;0;5;"Its days are numbered. I guess that means they may be countably infinite.";;;;"951766217789968384";https://twitter.com/pwuille/status/951766217789968384
pwuille;2018-01-11 15:39;0;3;"Less professional but more Professional™.";;;;"951599571070803968";https://twitter.com/pwuille/status/951599571070803968
pwuille;2018-01-11 08:06;0;6;"As we're going to repeat our discussion on Twitter, I should probably also point out that block-wide aggregation complicates transaction validation caching significantly (need to cache a (large) pairing group element, and combine them)";;;;"951485542843273217";https://twitter.com/pwuille/status/951485542843273217
pwuille;2018-01-10 02:28;1;10;"BIP42 predicted a dispute over what to call 1 billion BTC. It was just off by 15 orders of magnitude.";;;;"951038131385532418";https://twitter.com/pwuille/status/951038131385532418
pwuille;2018-01-09 02:09;58;220;"Translation: Let's make 2018 the year in which we're not going to solve everything in a hilarious and irrelevant way using a #blockchain . https:// twitter.com/jbaert/status/ 950668220956102656 …";;;#blockchain;"950670913057390592";https://twitter.com/pwuille/status/950670913057390592
pwuille;2018-01-09 01:03;0;15;"Too bad. It seems fashionable to have a desk in a container these days.";;;;"950654358626226176";https://twitter.com/pwuille/status/950654358626226176
pwuille;2018-01-08 16:16;0;52;"You mean your desk isn't on AWS?";;;;"950521599656161282";https://twitter.com/pwuille/status/950521599656161282
pwuille;2018-01-08 07:17;0;0;"*between *nodes* that have different ideas about what the mempool is.";;;;"950385944288485378";https://twitter.com/pwuille/status/950385944288485378
pwuille;2018-01-08 07:15;0;2;"There is no consistency about the mempool between nodes. If there was, we wouldn't need a blockchain. Validity cannot depend on data that is not guaranteed to be consistent, or you risk forks between blocks that have different ideas about what the mempool is.";;;;"950385379479257089";https://twitter.com/pwuille/status/950385379479257089
pwuille;2018-01-08 02:15;0;36;"And then someone makes a fork of Manero called Manuro? It never ends...";;;;"950310047963283456";https://twitter.com/pwuille/status/950310047963283456
pwuille;2018-01-06 10:22;0;18;"Ah, I guess I misunderstood. It's not a way to vote on what the future feerate should be, but just a way to expose the actual min feerate in the given block? If so, that may be useful to simplify feerate discovery (but beware of OOB payments), but is not much a signalling.";;;;"949707689583677441";https://twitter.com/pwuille/status/949707689583677441
pwuille;2018-01-06 10:10;1;10;"It may indeed function as a signalling mechanism, but that does not need any consensus enforcement. I'm skeptical that a signalling mechanism would actually result in miners to choose to not include some transactions they'd otherwise include.";;;;"949704836391546880";https://twitter.com/pwuille/status/949704836391546880
pwuille;2018-01-06 10:05;0;21;"If one miner chooses not to include a transaction, another miner still can - and the first one will still pay the bandwidth and validation costs. Setting a nonzero value at best has no effect; at worst, it's a monetary loss.";;;;"949703371421872129";https://twitter.com/pwuille/status/949703371421872129
pwuille;2018-01-06 06:33;1;12;"I wouldn't say that's accurate. I think of the P2WPKH or P2WSH hash as a program itself. It's certainly an unusual one, but that hash defines the semantics entirely. Would you agree it's a program if it we extended to allow including actual opcodes in the 2-40 bytes?";;;;"949650253384441856";https://twitter.com/pwuille/status/949650253384441856
pwuille;2018-01-06 06:24;0;1;"I commented a bit on StackExchange.";;;;"949647769177853953";https://twitter.com/pwuille/status/949647769177853953
pwuille;2018-01-06 05:47;0;10;"I think the name just evolved over time. Originally I wanted to call it "Witness protected program", but for some reason that didn't end up in the BIP :)";;;;"949638521349988352";https://twitter.com/pwuille/status/949638521349988352
pwuille;2018-01-06 03:35;0;62;"Why would any miner set this to a non-zero value? They still get all the fees that people pay above the advertized minimum feerate.";;;;"949605320468451333";https://twitter.com/pwuille/status/949605320468451333
pwuille;2018-01-04 13:05;2;18;"BLS requires pairing-based crypto, which is slower than EC, and a strictly stronger (and newer) security assumption. On the other hand, it lets you do cooler things too :)";;;;"949023999350231041";https://twitter.com/pwuille/status/949023999350231041
pwuille;2018-01-03 09:27;69;235;"To the many concerns I've been hearing about whether BIP173 (bech32) addresses were ready to be implemented, the proposal was just changed from Draft to Proposed: https:// github.com/bitcoin/bips/p ull/627 …";;;;"948606676290232321";https://twitter.com/pwuille/status/948606676290232321
pwuille;2018-01-03 04:36;32;180;"Idea: create a cryptocurrency where every address has an implicit 1 coin available at genesis. As soon as anyone trades a coin for non-zero value, it will have a multi-zillion market cap.";;;;"948533583064567808";https://twitter.com/pwuille/status/948533583064567808
pwuille;2018-01-02 07:21;2;19;"On their own, this is certainly true. But they're only one tool in a toolbox to better privacy. For example, they simplify mixing (no need for identical amounts) and make change output tracking harder.";;;;"948212660637757440";https://twitter.com/pwuille/status/948212660637757440
pwuille;2018-01-01 11:47;0;3;"I guess the difference is that no unspendable output was ever created. But as the outcome is pretty much the same, I guess this is semantics.";;;;"947917271678234624";https://twitter.com/pwuille/status/947917271678234624
pwuille;2018-01-01 01:32;22;158;"Will I need to start tweeting in Haiku's now? https:// twitter.com/coindesk/statu s/947699170353340416 …";;;;"947762541345767424";https://twitter.com/pwuille/status/947762541345767424
pwuille;2018-01-01 00:06;0;25;"Wow, thank you :)";;;;"947740863177854976";https://twitter.com/pwuille/status/947740863177854976
pwuille;2017-12-31 01:20;0;5;"No. This has permanently reduced the total number of BTC.";;;;"947397026307854341";https://twitter.com/pwuille/status/947397026307854341
pwuille;2017-12-30 22:17;1;15;"I've updated the StackExchange answer to include the block 501726 incident.";;;;"947351072124932096";https://twitter.com/pwuille/status/947351072124932096
pwuille;2017-12-30 22:15;0;5;"BIP 42 specifies switching to the new rules in the year 2214, but I believe all software is already prepared for it :)";;;;"947350479469731841";https://twitter.com/pwuille/status/947350479469731841
pwuille;2017-12-30 12:37;2;8;"Did you find any? I believe repeated R values in Bitcoin signatures were exploited as early as 2013... I hope wallet authors have learned by now.";;;;"947204897837060097";https://twitter.com/pwuille/status/947204897837060097
pwuille;2017-12-30 12:00;0;4;"You mean you didn't?";;;;"947195766602420226";https://twitter.com/pwuille/status/947195766602420226
pwuille;2017-12-30 05:39;41;152;"The miner failed to claim the 12.5 BTC they were allowed to take, so no BTC was destroyed - it was simply never brought into existence.";;;;"947099746639974400";https://twitter.com/pwuille/status/947099746639974400
pwuille;2017-12-30 04:47;3;30;"The most #34c3 thing so far: people driving a Club Mate crate powered by a hoverboard.";;;#34c3;"947086852414197760";https://twitter.com/pwuille/status/947086852414197760
pwuille;2017-12-30 04:37;0;1;"Have you to the Bitcoin assembly?";;;;"947084193162584064";https://twitter.com/pwuille/status/947084193162584064
pwuille;2017-12-30 01:31;0;7;"Level 0x21? So you're finally allowed to drink 0xbeer in the US?";;;;"947037361116008448";https://twitter.com/pwuille/status/947037361116008448
pwuille;2017-12-30 01:28;0;3;"Oh, congrats! I missed that this was about more than your SE identity.";;;;"947036540210962432";https://twitter.com/pwuille/status/947036540210962432
pwuille;2017-12-30 01:19;0;1;"What is Level 0x21?";;;;"947034399794659328";https://twitter.com/pwuille/status/947034399794659328
pwuille;2017-12-29 06:36;1;16;"I think part of the reason businesses use it is exactly that - it's reliable and supported. That does not mean things like LN can't be included when widely adopted, but it's just a reality that that will take a long time.";;;;"946751817609895936";https://twitter.com/pwuille/status/946751817609895936
pwuille;2017-12-29 06:31;4;33;"I see your motivation, but I think it's inconsistent. Core is not the place to push for experimental new wallet designs - it's a stable wallet with a very high bar for review. Integrating something as novel as LN at this point seems so out of place I'm confused why we discuss it.";;;;"946750539689287681";https://twitter.com/pwuille/status/946750539689287681
pwuille;2017-12-29 03:00;6;36;"LN integrating in Core would also take months/years to develop and review. I am a big fan of all the great work the LN people are doing, but they're much more effective working on their own. Maybe at some point enough people will want LN in Core. Will you help make it happen?";;;;"946697404924989441";https://twitter.com/pwuille/status/946697404924989441
pwuille;2017-12-29 02:57;0;2;"But maturity in no way implies that it is "done" - done depends on the use case. To me, it refers to how we deal with the existing features.";;;;"946696582560325632";https://twitter.com/pwuille/status/946696582560325632
pwuille;2017-12-29 02:43;1;8;"Certainly full nodes are useful without built-in wallets?";;;;"946693096317833216";https://twitter.com/pwuille/status/946693096317833216
pwuille;2017-12-29 02:40;5;42;"Bitcoin Core doesn't really have a roadmap, people do. Things happen when they're done by someone. Nobody in its organization gets to decide what others work on. I don't see why you'd need two full nodes to use LN; existing LN software connects to existing node software.";;;;"946692407625740288";https://twitter.com/pwuille/status/946692407625740288
pwuille;2017-12-29 02:37;0;7;"Yes, that would be great, but that will require a great deal of work that someone will have to do. My point is that I don't understand how a proposed system that isn't even active on the network today could be a criterion for the maturity of Bitcoin Core.";;;;"946691563937239040";https://twitter.com/pwuille/status/946691563937239040
pwuille;2017-12-29 02:33;2;17;"I don't see how LN is related. I expect it to become a major part of Bitcoin's ecosystem, but there is no reason to assume that it will be part of Bitcoin Core (or that it won't be).";;;;"946690574828089344";https://twitter.com/pwuille/status/946690574828089344
pwuille;2017-12-29 02:30;5;33;"I support dropping the 0 now. Not because I think we just passed some major milestone, but because I don't think such a milestone will happen as a clear discrete event. And as a result, the 0 in front is just redundant.";;;;"946689982034477056";https://twitter.com/pwuille/status/946689982034477056
pwuille;2017-12-29 02:29;3;21;"I don't consider Bitcoin "done", but I do consider Bitcoin Core a mature client for the system as it exists today, and it will continue to do so.";;;;"946689521147662336";https://twitter.com/pwuille/status/946689521147662336
pwuille;2017-12-29 02:27;1;16;"Production ready for what purpose? Clearly the software is used actively in production. It has an extensive review, QA, and release cycle. There is active maintenance of supported feature with compatibility across versions.";;;;"946689211469623296";https://twitter.com/pwuille/status/946689211469623296
pwuille;2017-12-29 02:23;0;33;"But there are no expected features. It's open source - if someone works on them and integrates them, they get integrated; otherwise they don't. I don't think maturity is about whether every feature is supported. It's about stability and maintenance of those that are.";;;;"946688039807586304";https://twitter.com/pwuille/status/946688039807586304
pwuille;2017-12-29 02:17;0;1;""its most expected upgrade established" I fail to parse that sentence.";;;;"946686641007153153";https://twitter.com/pwuille/status/946686641007153153
pwuille;2017-12-28 21:28;16;91;"Finally a good explanation to refer to when voting on the blockchain is brought up again. https:// twitter.com/benadida/statu s/946524757423374336 …";;;;"946613886165405696";https://twitter.com/pwuille/status/946613886165405696
pwuille;2017-12-28 02:20;0;4;"Makes sense. It's similar to the risks of some of the "softfork PoW changes" that have been discussed. Despite not making any invalid things valid, the property that a hashrate majority is sufficient does not exist (as the definition of hashrate before/after changes).";;;;"946325069248200704";https://twitter.com/pwuille/status/946325069248200704
pwuille;2017-12-28 02:15;0;6;"But the introduction of OP_NOPx coincided with the removal of OP_VER I think? So it's perhaps a bit fuzzy. Agree that the change in how the longest chain is decided was a potential forking risk (despite not changing validity, it incurred many of a HF's risks).";;;;"946323742086565888";https://twitter.com/pwuille/status/946323742086565888
pwuille;2017-12-28 02:08;0;12;"I was about to comment that before the removal of OP_VER technically every release was a hardfork, but I saw you already have a footnote about that. Perhaps it's fairer to say that that removal was the start of the modern notion of forks, and that before that, it was too fuzzy.";;;;"946321957909344256";https://twitter.com/pwuille/status/946321957909344256
pwuille;2017-12-28 01:32;61;192;"Very nice overview! https:// twitter.com/BitMEXResearch /status/946263906418286595 …";;;;"946313011010121728";https://twitter.com/pwuille/status/946313011010121728
pwuille;2017-12-27 22:50;0;17;"Well, maybe that's the problem? Not enough people are interested in sidechains to make it happen? This is not about Core. This is about lack of enthousiasm from the development community at large (which includes, but is not limited to Core contributors).";;;;"946272233558814720";https://twitter.com/pwuille/status/946272233558814720
pwuille;2017-12-27 10:14;0;1;"manpage smb.conf: IT'S OVER 9000 lines!!!";;;;"946081915349667841";https://twitter.com/pwuille/status/946081915349667841
pwuille;2017-12-27 01:09;0;3;"And I agree it's a bogus argument. As I said, if PCQ is ever needed in Bitcoin, we'll easily find consensus to incorporate it. My point is that you're dismissing it with more nonsense (there is no encryption/decryption involved anywhere, and it's not just about increasing power).";;;;"945944751773241344";https://twitter.com/pwuille/status/945944751773241344
pwuille;2017-12-27 01:01;1;10;"Please. It's fine to say "Quantum computing is not a serious threat in the short term", which I would agree with. Dismissing it with nonsense like "Increasing computing pwer is a constant" is just not constructive. A day may come that Bitcoin may need PQC, even if that is not now";;;;"945942629199568898";https://twitter.com/pwuille/status/945942629199568898
pwuille;2017-12-27 00:36;1;16;"Another thing that may play a role is that Bitcoin makes some (from a cryptographic perspective) uninteresting assumptions, like relying on participants acting rationally (as opposed to just making it impossibly hard for them to misbehave).";;;;"945936376536666113";https://twitter.com/pwuille/status/945936376536666113
pwuille;2017-12-26 23:40;1;17;"Of course I disagree with the assessment that Bitcojn's way of governance is problematic - if it becomes clear that PQC is needed, I don't expect it hard to achieve consensus to provide it.";;;;"945922418454953986";https://twitter.com/pwuille/status/945922418454953986
pwuille;2017-12-26 23:39;1;23;"I don't understand this. If sufficient breakthroughs in quantum computing are made, every system will need to upgrade to post-quantum algorithms, including Bitcoin. QC does not just make things faster; it fundamentally makes certain types of algorithms insecure.";;;;"945922094914818049";https://twitter.com/pwuille/status/945922094914818049
pwuille;2017-12-26 12:22;0;2;"http:// cryptoisnotcryptocurrency.com /";;;;"945751609073635328";https://twitter.com/pwuille/status/945751609073635328
pwuille;2017-12-26 05:47;0;4;"I don't know about 34C4 - I'm going to #34C3 instead I'm afraid.";;;#34C3;"945652194036068353";https://twitter.com/pwuille/status/945652194036068353
pwuille;2017-12-23 12:06;0;4;"The character error rate in your transcript seems a bit high, though. Perhaps this protocol can be improved by applying forward error correction?";;;;"944660451794747392";https://twitter.com/pwuille/status/944660451794747392
pwuille;2017-12-23 12:01;0;5;"Low transcript propagation latency compared to the average inter-Greg-talk interval?";;;;"944659150662926336";https://twitter.com/pwuille/status/944659150662926336
pwuille;2017-12-19 21:02;0;1;"(credit @philippedreesen )";;@philippedreesen;;"943345837895188482";https://twitter.com/pwuille/status/943345837895188482
pwuille;2017-12-19 17:02;0;1;"Yes! A naive checksum (like SHA256 in Base58Check) treats all errors equally - any change at all has the same chance of being missed. A structured checksum like the one in Bech32 is *biased* in favor of detecting small numbers of errors occurring within a small window.";;;;"943285479033597952";https://twitter.com/pwuille/status/943285479033597952
pwuille;2017-12-19 16:57;0;6;"Bitcoin: mining our own business since 2009.";;;;"943284303206772737";https://twitter.com/pwuille/status/943284303206772737
pwuille;2017-12-19 16:44;0;2;"However, if those 6 errors occur randomly distributed within a window of 10 characters, there is a 0.714/2^30 = 1 in 1.5 billion chance it won't be detected. If 2 errors within a window of 1200 characters there is a 8517.45/2^30 = 1 in 126063.7 chance it won't be detected.";;;;"943281000150310913";https://twitter.com/pwuille/status/943281000150310913
pwuille;2017-12-19 16:34;0;1;"No, in fact changing *any* consecutive 6 characters in bech32 (including the last 6) will *always* be detected (look at the 0.0000 in column "6 Errors" under "Len 6").";;;;"943278315632254976";https://twitter.com/pwuille/status/943278315632254976
pwuille;2017-12-19 16:24;0;1;"I'm working on an "extended" Bech32 for use cases where you want more error correction or longer strings. In general: a code that guaranteed detecting N errors can also correct N/2 (rounded down) errors.";;;;"943275828095234048";https://twitter.com/pwuille/status/943275828095234048
pwuille;2017-12-19 15:24;0;1;"No they don't. I was too late, and they're sold out. I'm just wondering if someone has a ticket who isn't planning to use it.";;;;"943260657247338496";https://twitter.com/pwuille/status/943260657247338496
pwuille;2017-12-19 13:28;6;9;"Does anyone have a registration left for RWC2018 Zürich? It seems I'm too late...";;;;"943231639412359168";https://twitter.com/pwuille/status/943231639412359168
pwuille;2017-12-19 10:31;0;1;"Here is I just posted this analysis of the Bech32 checksum: https:// gist.github.com/sipa/a87bedf21 69f7018d2afc10122e43111 … Let me know if you have any questions.";;;;"943187041902256128";https://twitter.com/pwuille/status/943187041902256128
pwuille;2017-12-19 09:28;0;1;"Up to 89 characters (excluding separator) bech32 guarantees detecting 4 errors. Up to 1023 it guarantees detecting 3 errors. Above 1023 it only guarantees detecting 1. You really want something else for such long strings.";;;;"943171134823923712";https://twitter.com/pwuille/status/943171134823923712
pwuille;2017-12-19 00:22;0;8;"Looks like a highly speculous ( https:// en.wikipedia.org/wiki/Speculaas ) investment.";;;;"943033723737456640";https://twitter.com/pwuille/status/943033723737456640
pwuille;2017-12-18 10:49;293;1017;"Happy block #500000, #bitcoin ! What a ride it has been. https:// twitter.com/jfnewbery/stat us/942826623371530240 …";;;#500000 #bitcoin;"942829090406481920";https://twitter.com/pwuille/status/942829090406481920
pwuille;2017-12-12 18:22;1;22;"There is no way to know just based on that information. It's perfectly possible those TPUs can do *zero* integer/bitwise operations per second (or only using very slow FP emulation) in which case the answer is perhaps close to infinity.";;;;"940768779365122048";https://twitter.com/pwuille/status/940768779365122048
pwuille;2017-12-12 00:50;0;9;"To be clear: fees being proportional to vsize (or weight) is not by decree or anything; it's a direct result of weight being the constrained resource per block. vsize is just rescaled for convenience of expressing feerate.";;;;"940503995352678401";https://twitter.com/pwuille/status/940503995352678401
pwuille;2017-12-12 00:44;0;9;"@nopara73 Weight = 3*size + stripped_size (= discount factor 4 for witness data) because not counting witnesses would be a trivial DoS attack on the network (spam witnesses for free). Vsize = scaled version of weight because otherwise sorting by fee/vsize is not best strategy.";;@nopara73;;"940502717243441152";https://twitter.com/pwuille/status/940502717243441152
pwuille;2017-12-11 23:50;0;7;"I'm not talking about weight or the witness discount factor (there are plenty of resources about that). I'm talking about why vsize = weight/4 was introduced: to be compatible with the 'size' concept that existed before SegWit.";;;;"940489098237583361";https://twitter.com/pwuille/status/940489098237583361
pwuille;2017-12-11 23:36;44;138;"Please, block explorers, listen to @murchandamus here. The concept of vsize was introduced in SegWit specifically to simplify reasoning about fees regardless of witnesses or not. https:// twitter.com/murchandamus/s tatus/940476306889814016 …";;@murchandamus;;"940485374882619392";https://twitter.com/pwuille/status/940485374882619392
pwuille;2017-12-11 10:44;0;0;"En terecht. In vraag me af wat ze op haar kerfstok heeft.";;;;"940291176258617348";https://twitter.com/pwuille/status/940291176258617348
pwuille;2017-12-11 10:38;0;0;"Ze kan de boom in.";;;;"940289775436677120";https://twitter.com/pwuille/status/940289775436677120
pwuille;2017-12-11 10:30;0;0;"Ik denk dat je er best een stokje voor steekt.";;;;"940287748685959169";https://twitter.com/pwuille/status/940287748685959169
pwuille;2017-12-09 10:38;0;3;"Thanks! I'm sure that in practice politicians make such tradeoffs; everyone is human. But their job is *not* about balancing public interest with personal interest. An engineer's job *is* balancing cost, accuracy, lifetime, ...";;;;"939564947876364288";https://twitter.com/pwuille/status/939564947876364288
pwuille;2017-12-09 10:27;0;4;"I don't think you can say that a perfect politician is expected to make decisions against the best interest of those he/she represents. A perfect engineer will absolutely make efficiency/complexity/cost/accuracy tradeoffs.";;;;"939562075621167104";https://twitter.com/pwuille/status/939562075621167104
pwuille;2017-12-09 10:17;4;69;"I would argue that engineering is exactly about knowing where cutting corners is acceptable (as opposed to theoretical science)... if an approximation is good enough for appropriate results, you should use it.";;;;"939559660176097280";https://twitter.com/pwuille/status/939559660176097280
pwuille;2017-12-06 22:33;0;3;"I love how you made a typo in typo.";;;;"938657642108534784";https://twitter.com/pwuille/status/938657642108534784
pwuille;2017-12-05 10:13;0;6;"Maybe. In a hypothetical transaction with 100 inputs and 2 outputs, ECDSA would dominate.";;;;"938109087220297733";https://twitter.com/pwuille/status/938109087220297733
pwuille;2017-12-05 10:09;2;14;"Just to clarify: these numbers are not instead of ECDSA, but in addition to. In CT, rangeproofs are for outputs, while inputs still carry normal signatures for authorization.";;;;"938107996109811712";https://twitter.com/pwuille/status/938107996109811712
pwuille;2017-12-04 15:32;0;76;"Hi, where can I read more about this?";;;;"937826928546811904";https://twitter.com/pwuille/status/937826928546811904
pwuille;2017-12-02 13:36;12;92;"Client mode in the quote almost certainly refers to what we now call SPV mode. And I absolutely agree not every user will run a full node, but that in no way changes the relevance of those who do.";;;;"937072955716124672";https://twitter.com/pwuille/status/937072955716124672
pwuille;2017-11-29 23:56;1;2;"3000. However, you're already asking 2500-3000 from A as well. While continuing, blocks arrive from both peers, which confuses you even more. Then C announces block 12347, and adds another complication...";;;;"936141954340995072";https://twitter.com/pwuille/status/936141954340995072
pwuille;2017-11-29 23:50;1;1;"batch of hashes 1500-2000, and download those, etc. 10 minutes later block 12346 arrives, and peer B is the first to give it to you. So you ask B for block 12346. You still don't have 12344 though. and by now you have maybe synced up to block 2500, so you ask B for hashes 2500-";;;;"936140434526560258";https://twitter.com/pwuille/status/936140434526560258
pwuille;2017-11-29 23:43;1;1;"Pre-0.10 sync: Peer A would give you a new block 12345, you're only synced to block 1000. You ask A for block 12345. A gives you 12345. You don't have 12344 (orphan), so you ask for block hashes 1000-1500 (first 500), and start downloading them. After 1500, you continue with next";;;;"936138724823334912";https://twitter.com/pwuille/status/936138724823334912
pwuille;2017-11-29 13:54;1;3;"Downloading would progress in blobs of 500 blocks at once (all from the same peer!), which is why you see issues appearing every 500 blocks.";;;;"935990358252515328";https://twitter.com/pwuille/status/935990358252515328
pwuille;2017-11-29 13:48;1;6;"Before headers-first sync (introduced in v0.10), block downloading would get disrupted if a new block was found while syncing - in that case it would get stuck or start downloading the same blocks multiple times. It really only worked while syncing took less than 10 minutes...";;;;"935988980914327552";https://twitter.com/pwuille/status/935988980914327552
pwuille;2017-11-27 22:56;3;13;"Bose–Chaudhuri–Hocquenghem";;;;"935402023209517056";https://twitter.com/pwuille/status/935402023209517056
pwuille;2017-11-19 13:18;0;1;"The off-by-one was an independent issue (and whether that was a bug in the code, or an ambiguity in the announcement is debatable).";;;;"932357557057757184";https://twitter.com/pwuille/status/932357557057757184
pwuille;2017-11-19 12:59;0;5;"That doesn't really matter. The program is incorrect if it uses an uninitialized variable anyway. The compiler may assume the code is never executed and optimize it away, or worse.";;;;"932352628163350528";https://twitter.com/pwuille/status/932352628163350528
pwuille;2017-11-19 11:26;0;16;"Je kan een liedje heel eenvoudig zingen...";;;;"932329156758478848";https://twitter.com/pwuille/status/932329156758478848
pwuille;2017-11-17 17:07;60;312;"$ cat test.cpp #include <stdio.h> class C { int x; public: C() { printf("%i\n", x); } }; int main() { C c; } $ g++ test.cpp -o test $ ./test 32764 $ ./test 32767";;;#include;"931690397134237696";https://twitter.com/pwuille/status/931690397134237696
pwuille;2017-11-17 16:54;2;48;"Only static and thread_local non-class variables are default initialized to 0. In this case, it's initialized to an indeterminate value. Using an indeterminate value is undefined behavior.";;;;"931686992961667073";https://twitter.com/pwuille/status/931686992961667073
pwuille;2017-11-17 15:27;5;15;"http:// en.cppreference.com/w/cpp/language /default_initialization … "Default initialization of non-class variables with automatic and dynamic storage duration produces objects with indeterminate values (static and thread-local objects get zero initialized)".";;;;"931665002313826304";https://twitter.com/pwuille/status/931665002313826304
pwuille;2017-11-16 12:13;0;12;"Yes, communication is hard :)";;;;"931253983242477568";https://twitter.com/pwuille/status/931253983242477568
pwuille;2017-11-16 09:28;8;44;"Bulletproofs are a way to compactly produce zero-knowledge proofs. They *could* be used in CT. CT *could* be proposed for bitcoin. Its proofs can't go in any existing structure. A new witness is needed for them. Talking about costing is very premature at this point.";;;;"931212346898264064";https://twitter.com/pwuille/status/931212346898264064
pwuille;2017-11-16 09:25;14;66;"Why do people assume that 3x larger implies 3x more expensive? That would be ridiculous for privacy. With SegWit the (exact) serialized size is no longer the constrained metric. Rangeproofs can be weighed differently again.";;;;"931211626224611328";https://twitter.com/pwuille/status/931211626224611328
pwuille;2017-11-16 09:23;2;13;"CT would inevitably need a new witness type for the rangeproofs (they're per output, existing witnesses are per input), or an extension block. There is no reason why they would be weighed per byte.";;;;"931211018226642944";https://twitter.com/pwuille/status/931211018226642944
pwuille;2017-11-15 16:13;0;4;"Thanks, fixed!";;;;"930951997112459264";https://twitter.com/pwuille/status/930951997112459264
pwuille;2017-11-14 12:25;0;2;"GEEN TIJD VOOR STRUCTS, CASTS ALL OVER EN INLINE ASSEMBLY DAN MAAR";;;;"930532260985442305";https://twitter.com/pwuille/status/930532260985442305
pwuille;2017-11-13 12:53;0;21;"You won't find blocks with invalid PoW or difficulty this way, as `getchaintips` only gives information about accepted headers. Invalid PoW or difficulty get detected before storing a header.";;;;"930176749907746816";https://twitter.com/pwuille/status/930176749907746816
pwuille;2017-10-26 09:48;0;104;"How about Lold?";;;;"923592283433271297";https://twitter.com/pwuille/status/923592283433271297
pwuille;2017-10-26 08:10;0;11;"What do you expect from a dialect that conjugates "yes" and "no" #mobatoet";;;#mobatoet;"923567620506263552";https://twitter.com/pwuille/status/923567620506263552
pwuille;2017-09-11 12:18;1;2;"If you implement the test vectors (including https:// github.com/bitcoin/bips/p ull/582 … ), feel free to PR to https:// github.com/sipa/bech32/tr ee/master/ref … Thanks!";;;;"907322465965060096";https://twitter.com/pwuille/status/907322465965060096
pwuille;2017-09-10 13:34;1;12;"Yes. Bcoin also needed a database redesign to solve this.";;;;"906979239668334592";https://twitter.com/pwuille/status/906979239668334592
pwuille;2017-09-10 13:10;18;79;"There is no way we'd release a complete redesign of the database without going through the normal release process.";;;;"906973195814674432";https://twitter.com/pwuille/status/906973195814674432
pwuille;2017-09-10 13:09;1;9;"Quote from my response: "at least several 100 MB into memory", and I considered that a serious problem.";;;;"906972934857560064";https://twitter.com/pwuille/status/906972934857560064
pwuille;2017-09-10 13:02;55;191;"We merged the fix for this in June, a month before he discovered the attack, just no release since. Testing takes time.";;;;"906971110004056064";https://twitter.com/pwuille/status/906971110004056064
pwuille;2017-08-31 22:06;27;70;"The concept of virtual size (=weight/4) was intended so that fee estimates would carry over. So I suggest: sat/vbyte https:// twitter.com/thomaskerin/st atus/902252206212206592 …";;;;"903484207296417792";https://twitter.com/pwuille/status/903484207296417792
pwuille;2017-08-25 11:59;2;9;"Interesting theorie! Do jij think de same is true voor Flemish mensen?";;;;"901157220498366464";https://twitter.com/pwuille/status/901157220498366464
pwuille;2017-08-23 19:00;312;996;"I'm the proud sender of the 3rd SegWit transaction ever: https://www. smartbit.com.au/tx/c586389e5e4 b3acb9d6c8be1c19ae8ab2795397633176f5a6442a261bbdefc3a … Thanks everyone who helped us get this far! #SegW00t";;;#SegW00t;"900538235956244480";https://twitter.com/pwuille/status/900538235956244480
pwuille;2017-08-11 11:42;1;12;"Hi Tim, thanks for the kind words. I'm not usually on Twitter anymore, but see DM :)";;;;"896079515943698432";https://twitter.com/pwuille/status/896079515943698432
pwuille;2017-05-01 12:17;3;25;"Nowhere in SegWit are multiple messages signed at once, and SegWit does not modify Bitcoin's multisig scheme.";;;;"859124597781741568";https://twitter.com/pwuille/status/859124597781741568
pwuille;2017-05-01 11:50;88;242;"I know of no patents that apply to SegWit, and Blockstream has not filed for any.";;;;"859117723233603584";https://twitter.com/pwuille/status/859117723233603584
pwuille;2017-03-23 17:42;17;55;"SW is jump to 2MB. BU removes consensus between nodes. I will not jump after that.";;;;"845073323511889920";https://twitter.com/pwuille/status/845073323511889920
pwuille;2017-03-08 22:10;0;1;"2TB Samsung M.2 SSDs are slightly less than 1 exabyte per cubic meter, so I think so.";;;;"839719927372144640";https://twitter.com/pwuille/status/839719927372144640
pwuille;2017-03-07 15:03;3;23;"MicroSD card capacity has apparently exceeded 1 exabyte per cubic meter.";;;;"839250246685241344";https://twitter.com/pwuille/status/839250246685241344
pwuille;2017-02-23 12:48;1;3;"Depending on what you want, maybe it doesn't need a fancy script at all: https:// bitcoincore.org/en/2016/02/26/ zero-knowledge-contingent-payments-announcement/ … #zkcp";;;#zkcp;"834867490706448385";https://twitter.com/pwuille/status/834867490706448385
pwuille;2017-02-03 18:15;6;28;"The most northern part of Iceland is more northern than the most northern part of Antarctica is southern.";;;;"827702079670013952";https://twitter.com/pwuille/status/827702079670013952
pwuille;2017-02-01 15:10;0;1;"You mean like C++11's unique_ptr?";;;;"826930789359054848";https://twitter.com/pwuille/status/826930789359054848
pwuille;2017-01-18 11:07;0;1;"And merged!";;;;"821796078236225536";https://twitter.com/pwuille/status/821796078236225536
pwuille;2017-01-02 18:57;0;2;"Number 1 suggestion: increase the database cache size. The default is 300MB. It's much faster if you set it to 4000 or so.";;;;"816116328515928067";https://twitter.com/pwuille/status/816116328515928067