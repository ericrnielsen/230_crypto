{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Input, LSTM, Dropout\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (18,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distribution(df, labels_column_name):\n",
    "    n = df.shape[0]\n",
    "    print(\"{} labels frequency:\".format(labels_column_name))\n",
    "    print(\"Value\\tCount\\tPercent\")\n",
    "    indeces = df[labels_column_name].value_counts().index.tolist()\n",
    "    counts = df[labels_column_name].value_counts().tolist()\n",
    "    for val, count in zip(indeces, counts):\n",
    "        print(\"{}\\t{}\\t{}%\".format(val, count, (count / float(n)) * 100))\n",
    "    \n",
    "def get_max_words(text_arr):\n",
    "    max_words = 0\n",
    "    for line in text_arr:\n",
    "        num_words = len(line.split())\n",
    "        if num_words > max_words:\n",
    "            max_words = num_words\n",
    "    return max_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the csv data\n",
    "reddit_train_df = pd.read_csv(\"../../data/reddit/labeled/score10_all_sub_labeled_train.csv\", index_col=0)\n",
    "reddit_test_df = pd.read_csv(\"../../data/reddit/labeled/score10_all_sub_labeled_dev.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of words per post: 78\n",
      "\n",
      "Getting x_train, y_train, x_test, and y_test...\n",
      "102991 train sequences\n",
      "9353 test sequences\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x121404240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1104dd390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine max post length\n",
    "max_words_train = get_max_words(reddit_train_df.title.values)\n",
    "max_words_test = get_max_words(reddit_test_df.title.values)\n",
    "max_words = max(max_words_train, max_words_test)\n",
    "print(\"Max number of words per post: {}\".format(max_words))\n",
    "\n",
    "# Label and title columns in datasets\n",
    "LABEL_1HR, LABEL_2HR, LABEL_6HR, LABEL_12HR, LABEL_24HR = \\\n",
    "    '1hr_change', '2hr_change', '6hr_change', '12hr_change', '24hr_change'\n",
    "TEXT_COL = 'title'\n",
    "\n",
    "# Split into x_train and y_train\n",
    "print('\\nGetting x_train, y_train, x_test, and y_test...')\n",
    "(x_train, y_train_1hr, y_train_2hr, y_train_6hr, y_train_12hr, y_train_24hr) = \\\n",
    "    reddit_train_df[TEXT_COL].values, reddit_train_df[LABEL_1HR], reddit_train_df[LABEL_2HR], \\\n",
    "    reddit_train_df[LABEL_6HR], reddit_train_df[LABEL_12HR], reddit_train_df[LABEL_24HR]\n",
    "\n",
    "m_train = x_train.shape[0]\n",
    "y_train_1hr = y_train_1hr.values.reshape((m_train, 1))\n",
    "y_train_2hr = y_train_2hr.values.reshape((m_train, 1))\n",
    "y_train_6hr = y_train_6hr.values.reshape((m_train, 1))\n",
    "y_train_12hr = y_train_12hr.values.reshape((m_train, 1))\n",
    "y_train_24hr = y_train_24hr.values.reshape((m_train, 1))\n",
    "    \n",
    "(x_test, y_test_1hr, y_test_2hr, y_test_6hr, y_test_12hr, y_test_24hr) = \\\n",
    "    reddit_test_df[TEXT_COL].values, reddit_test_df[LABEL_1HR], reddit_test_df[LABEL_2HR], \\\n",
    "    reddit_test_df[LABEL_6HR], reddit_test_df[LABEL_12HR], reddit_test_df[LABEL_24HR]\n",
    "\n",
    "m_test = x_test.shape[0]\n",
    "y_test_1hr = y_test_1hr.values.reshape((m_test, 1))\n",
    "y_test_2hr = y_test_2hr.values.reshape((m_test, 1))\n",
    "y_test_6hr = y_test_6hr.values.reshape((m_test, 1))\n",
    "y_test_12hr = y_test_12hr.values.reshape((m_test, 1))\n",
    "y_test_24hr = y_test_24hr.values.reshape((m_test, 1)) \n",
    "\n",
    "# Print info about train and test\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# Plot distributions of labels\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.distplot(reddit_train_df[LABEL_1HR].values, label='Train')\n",
    "sns.distplot(reddit_test_df[LABEL_1HR].values, label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (102991, 78)\n",
      "x_test shape: (9353, 78)\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "max_features = 200000 # Num words in our vocabulary \n",
    "maxlen = max_words  # cut texts after this number of words\n",
    "batch_size = 32  # Mini-batch size\n",
    "epochs = 5 \n",
    "\n",
    "# Train tokenizer to create a vocabulary of words\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Vectorize each headline\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Update x_train and x_test to be 'sequences' of data\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(test_sequences, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding layer using word2vec\n",
    "EMBEDDING_FILE = \"../../data/embeddings/GoogleNews-vectors-negative300.bin\"\n",
    "EMBEDDING_DIM = 300\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "        \n",
    "embedding_layer = Embedding(nb_words,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=maxlen,\n",
    "        trainable=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 3/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual embeddings\n",
    "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "embeddings = embedding_layer(sequence_input)\n",
    "\n",
    "# Construct the model (attempt 1 - didn't work)\n",
    "#X = LSTM(128, return_sequences=True)(embeddings)\n",
    "#X = Dropout(0.5)(X)\n",
    "#X = LSTM(128, return_sequences=False)(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "#X = Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "# Construct the model (attempt 1 - didn't work)\n",
    "X = Bidirectional(LSTM(128, return_sequences=False))(embeddings)\n",
    "X = Dense(5)(X)\n",
    "\n",
    "# Select y labels\n",
    "y_train = np.concatenate((y_train_1hr, y_train_2hr, y_train_6hr, y_train_12hr, y_train_24hr), axis=1)\n",
    "y_test = np.concatenate((y_test_1hr, y_test_2hr, y_test_6hr, y_test_12hr, y_test_24hr), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the BTC model\n",
    "model = Model(inputs=sequence_input, outputs=X)\n",
    "\n",
    "# Compile the BTC model\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error', \n",
    "                    optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Setup model checkpoint\n",
    "checkpoint_5 = ModelCheckpoint(\"checkpoints/reddit-5epochs.hdf5\")\n",
    "\n",
    "# Run the BTC model\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_5])\n",
    "\n",
    "score, acc = model_btc.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC model for 15 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9353/9353 [==============================] - 8s 892us/step\n",
      "Test score: 2.0105437362759964\n",
      "Test accuracy: 0.000748422985011647\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/10\n",
      "102991/102991 [==============================] - 286s 3ms/step - loss: 1.3101 - acc: 0.0011 - val_loss: 2.0688 - val_acc: 6.4151e-04\n",
      "Epoch 2/10\n",
      "102991/102991 [==============================] - 289s 3ms/step - loss: 1.1804 - acc: 0.0011 - val_loss: 2.1797 - val_acc: 5.3459e-04\n",
      "Epoch 3/10\n",
      "102991/102991 [==============================] - 291s 3ms/step - loss: 1.0664 - acc: 0.0011 - val_loss: 2.1731 - val_acc: 5.3459e-04\n",
      "Epoch 4/10\n",
      "102991/102991 [==============================] - 290s 3ms/step - loss: 0.9696 - acc: 0.0011 - val_loss: 2.2821 - val_acc: 4.2767e-04\n",
      "Epoch 5/10\n",
      "102991/102991 [==============================] - 291s 3ms/step - loss: 0.8832 - acc: 0.0011 - val_loss: 2.4185 - val_acc: 6.4151e-04\n",
      "Epoch 6/10\n",
      "102991/102991 [==============================] - 292s 3ms/step - loss: 0.8066 - acc: 0.0011 - val_loss: 2.4223 - val_acc: 2.1384e-04\n",
      "Epoch 7/10\n",
      "102991/102991 [==============================] - 298s 3ms/step - loss: 0.7424 - acc: 0.0011 - val_loss: 2.4710 - val_acc: 4.2767e-04\n",
      "Epoch 8/10\n",
      "102991/102991 [==============================] - 297s 3ms/step - loss: 0.6881 - acc: 0.0011 - val_loss: 2.5580 - val_acc: 2.1384e-04\n",
      "Epoch 9/10\n",
      "102991/102991 [==============================] - 294s 3ms/step - loss: 0.6427 - acc: 0.0011 - val_loss: 2.5826 - val_acc: 2.1384e-04\n",
      "Epoch 10/10\n",
      "102991/102991 [==============================] - 297s 3ms/step - loss: 0.5956 - acc: 0.0012 - val_loss: 2.5865 - val_acc: 3.2075e-04\n",
      "9353/9353 [==============================] - 9s 950us/step\n",
      "Test score: 2.5864633018545042\n",
      "Test accuracy: 0.0003207527092277309\n"
     ]
    }
   ],
   "source": [
    "# Setup model checkpoints\\n\",\n",
    "checkpoint_10 = ModelCheckpoint(\"checkpoints/reddit-10epochs.hdf5\")\n",
    "checkpoint_15 = ModelCheckpoint(\"checkpoints/reddit-15epochs.hdf5\")\n",
    "checkpoint_20 = ModelCheckpoint(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "\n",
    "# Run the BTC model 5 more epochs\\n\",\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_10])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the BTC model 5 more epochs\\n\",\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_15])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the BTC model 5 more epochs\\n\",\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_20])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9353/9353 [==============================] - 8s 893us/step\n",
      "Test score: 11.454025297308688\n",
      "Test accuracy: 0.32535015505596265\n",
      "9353/9353 [==============================] - 8s 894us/step\n",
      "Test score: 14.112859787844622\n",
      "Test accuracy: 0.3053565700860581\n",
      "9353/9353 [==============================] - 8s 898us/step\n",
      "Test score: 16.574149997453823\n",
      "Test accuracy: 0.28931893511059625\n",
      "9353/9353 [==============================] - 8s 900us/step\n",
      "Test score: 18.188835654783336\n",
      "Test accuracy: 0.29338180263176533\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# After 5 epochs\n",
    "###################################################################\n",
    "model_5 = Model(inputs=sequence_input, outputs=X)\n",
    "model_5.load_weights(\"checkpoints/reddit-5epochs.hdf5\")\n",
    "model_5.compile(loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "score_5, acc_5 = model_5.evaluate(x_test,\n",
    "                                  y_test,\n",
    "                                  batch_size=batch_size)\n",
    "predictions_5 = model_5.predict(x_test)\n",
    "print('Test score:', score_5)\n",
    "print('Test accuracy:', acc_5)\n",
    "                     \n",
    "###################################################################\n",
    "# After 10 epochs\n",
    "###################################################################\n",
    "model_10 = Model(inputs=sequence_input, outputs=X)\n",
    "model_10.load_weights(\"checkpoints/reddit-10epochs.hdf5\")\n",
    "model_10.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_10, acc_10 = model_10.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_10 = model_10.predict(x_test)\n",
    "print('Test score:', score_10)\n",
    "print('Test accuracy:', acc_10)\n",
    "\n",
    "###################################################################\n",
    "# After 15 epochs\n",
    "###################################################################\n",
    "model_15 = Model(inputs=sequence_input, outputs=X)\n",
    "model_15.load_weights(\"checkpoints/reddit-15epochs.hdf5\")\n",
    "model_15.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_15, acc_15 = model_15.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_15 = model_15.predict(x_test)\n",
    "print('Test score:', score_15)\n",
    "print('Test accuracy:', acc_15)\n",
    "\n",
    "###################################################################\n",
    "# After 20 epochs\n",
    "###################################################################\n",
    "model_20 = Model(inputs=sequence_input, outputs=X)\n",
    "model_20.load_weights(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "model_20.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_20, acc_20 = model_20.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_20 = model_20.predict(x_test)\n",
    "print('Test score:', score_20)\n",
    "print('Test accuracy:', acc_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the results\n",
    "    - Look at the distribution of the predicted results to see if the model makes large predictions\n",
    "    - Perform some error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER 5 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0228\tMin: -0.9305\t25%: -0.0631\t75%: 0.1112\tMax: 0.9399\n",
      "[+02 hr]\tMean: 0.0195\tMin: -1.5050\t25%: -0.1222\t75%: 0.1651\tMax: 1.8022\n",
      "[+06 hr]\tMean: 0.1159\tMin: -4.7486\t25%: -0.2228\t75%: 0.4615\tMax: 4.9317\n",
      "[+12 hr]\tMean: 0.2400\tMin: -6.5284\t25%: -0.2652\t75%: 0.7602\tMax: 7.4593\n",
      "[+24 hr]\tMean: 0.4623\tMin: -8.7002\t25%: -0.3023\t75%: 1.2281\tMax: 9.2941\n",
      "\n",
      "AFTER 10 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0260\tMin: -1.4070\t25%: -0.1506\t75%: 0.1927\tMax: 2.6116\n",
      "[+02 hr]\tMean: 0.0589\tMin: -2.6301\t25%: -0.2617\t75%: 0.3645\tMax: 5.1058\n",
      "[+06 hr]\tMean: 0.1841\tMin: -8.5745\t25%: -0.6412\t75%: 0.9734\tMax: 13.4106\n",
      "[+12 hr]\tMean: 0.4062\tMin: -12.1255\t25%: -0.8545\t75%: 1.6208\tMax: 20.2075\n",
      "[+24 hr]\tMean: 0.6845\tMin: -15.7347\t25%: -1.2130\t75%: 2.5223\tMax: 28.2422\n",
      "\n",
      "AFTER 15 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0273\tMin: -1.6031\t25%: -0.1787\t75%: 0.2236\tMax: 1.9438\n",
      "[+02 hr]\tMean: 0.0665\tMin: -3.1627\t25%: -0.3402\t75%: 0.4541\tMax: 4.4016\n",
      "[+06 hr]\tMean: 0.1248\tMin: -9.1286\t25%: -0.9506\t75%: 1.1505\tMax: 11.5388\n",
      "[+12 hr]\tMean: 0.2658\tMin: -13.7218\t25%: -1.3889\t75%: 1.8541\tMax: 17.5045\n",
      "[+24 hr]\tMean: 0.4352\tMin: -18.7471\t25%: -2.0951\t75%: 2.9027\tMax: 24.8039\n",
      "\n",
      "AFTER 20 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0131\tMin: -1.6869\t25%: -0.2503\t75%: 0.2130\tMax: 1.8026\n",
      "[+02 hr]\tMean: 0.0049\tMin: -3.2077\t25%: -0.4664\t75%: 0.4484\tMax: 3.9174\n",
      "[+06 hr]\tMean: 0.0861\tMin: -9.8513\t25%: -1.1402\t75%: 1.2496\tMax: 10.1864\n",
      "[+12 hr]\tMean: 0.2396\tMin: -14.6935\t25%: -1.6946\t75%: 2.0798\tMax: 15.8838\n",
      "[+24 hr]\tMean: 0.4763\tMin: -20.3679\t25%: -2.4743\t75%: 3.3964\tMax: 23.5398\n"
     ]
    }
   ],
   "source": [
    "# Store predictions in list\\n\",\n",
    "all_predictions = [('AFTER 5 EPOCHS TRAINING', predictions_5),\n",
    "                   ('AFTER 10 EPOCHS TRAINING', predictions_10),\n",
    "                   ('AFTER 15 EPOCHS TRAINING', predictions_15),\n",
    "                   ('AFTER 20 EPOCHS TRAINING', predictions_20)]\n",
    "\n",
    "# Loop through each set and print summary\\n\",\n",
    "for description, prediction in all_predictions:\n",
    "    pred_1hr, summary_1hr = prediction[:,0], pd.Series(np.squeeze(prediction[:,0])).describe()\n",
    "    pred_2hr, summary_2hr = prediction[:,1], pd.Series(np.squeeze(prediction[:,1])).describe()\n",
    "    pred_6hr, summary_6hr = prediction[:,2], pd.Series(np.squeeze(prediction[:,2])).describe()\n",
    "    pred_12hr, summary_12hr = prediction[:,3], pd.Series(np.squeeze(prediction[:,3])).describe()\n",
    "    pred_24hr, summary_24hr = prediction[:,4], pd.Series(np.squeeze(prediction[:,4])).describe()\n",
    "\n",
    "    print('\\n%s' % description)\n",
    "    print('[+01 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_1hr['mean'], summary_1hr['min'], summary_1hr['25%'], summary_1hr['75%'], summary_1hr['max']))\n",
    "    print('[+02 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_2hr['mean'], summary_2hr['min'], summary_2hr['25%'], summary_2hr['75%'], summary_2hr['max']))\n",
    "    print('[+06 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_6hr['mean'], summary_6hr['min'], summary_6hr['25%'], summary_6hr['75%'], summary_6hr['max']))\n",
    "    print('[+12 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_12hr['mean'], summary_12hr['min'], summary_12hr['25%'], summary_12hr['75%'], summary_12hr['max']))\n",
    "    print('[+24 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_24hr['mean'], summary_24hr['min'], summary_24hr['25%'], summary_24hr['75%'], summary_24hr['max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First check - how many ACTUAL price changes LARGER than cutoff did we PREDICT correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS +1 HOUR IN FUTURE:\n",
      "Num ACTUAL in top 20% (change >= 0.99%): 1881\n",
      "[05 epoch train] Above cutoff: 0 (0.00%), Positive: 1069 (56.83%)\n",
      "[10 epoch train] Above cutoff: 8 (0.43%), Positive: 1015 (53.96%)\n",
      "[15 epoch train] Above cutoff: 15 (0.80%), Positive: 974 (51.78%)\n",
      "[20 epoch train] Above cutoff: 11 (0.58%), Positive: 879 (46.73%)\n",
      "\n",
      "PREDICTIONS +2 HOUR IN FUTURE:\n",
      "Num ACTUAL in top 20% (change >= 1.40%): 1871\n",
      "[05 epoch train] Above cutoff: 0 (0.00%), Positive: 1000 (53.45%)\n",
      "[10 epoch train] Above cutoff: 34 (1.82%), Positive: 998 (53.34%)\n",
      "[15 epoch train] Above cutoff: 52 (2.78%), Positive: 996 (53.23%)\n",
      "[20 epoch train] Above cutoff: 64 (3.42%), Positive: 908 (48.53%)\n",
      "\n",
      "PREDICTIONS +6 HOUR IN FUTURE:\n",
      "Num ACTUAL in top 20% (change >= 2.60%): 1875\n",
      "[05 epoch train] Above cutoff: 1 (0.05%), Positive: 1138 (60.69%)\n",
      "[10 epoch train] Above cutoff: 107 (5.71%), Positive: 1075 (57.33%)\n",
      "[15 epoch train] Above cutoff: 157 (8.37%), Positive: 1011 (53.92%)\n",
      "[20 epoch train] Above cutoff: 188 (10.03%), Positive: 984 (52.48%)\n",
      "\n",
      "PREDICTIONS +12 HOUR IN FUTURE:\n",
      "Num ACTUAL in top 20% (change >= 3.83%): 1883\n",
      "[05 epoch train] Above cutoff: 3 (0.16%), Positive: 1170 (62.13%)\n",
      "[10 epoch train] Above cutoff: 113 (6.00%), Positive: 1070 (56.82%)\n",
      "[15 epoch train] Above cutoff: 163 (8.66%), Positive: 977 (51.89%)\n",
      "[20 epoch train] Above cutoff: 197 (10.46%), Positive: 959 (50.93%)\n",
      "\n",
      "PREDICTIONS +24 HOUR IN FUTURE:\n",
      "Num ACTUAL in top 20% (change >= 6.07%): 1877\n",
      "[05 epoch train] Above cutoff: 2 (0.11%), Positive: 1267 (67.50%)\n",
      "[10 epoch train] Above cutoff: 104 (5.54%), Positive: 1095 (58.34%)\n",
      "[15 epoch train] Above cutoff: 150 (7.99%), Positive: 976 (52.00%)\n",
      "[20 epoch train] Above cutoff: 199 (10.60%), Positive: 976 (52.00%)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "actual_columns = {'title' : 4, '1hr' : 5, '2hr' : 6, '6hr' : 7, '12hr' : 8, '24hr' : 9}\n",
    "\n",
    "num_actual_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "\n",
    "titles_pos = {'1hr' : [], '2hr' : [], '6hr' : [], '12hr' : [], '24hr' : []} \n",
    "\n",
    "num_pred_5_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_10_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_15_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_20_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "\n",
    "num_pred_5_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_10_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_15_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_20_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "\n",
    "# Determine cutoffs to only consider largest 20% of price changes\n",
    "pos_percent = 0.8\n",
    "pos_1hr = pd.Series(np.squeeze(reddit_test_df['1hr_change'])).quantile(pos_percent)\n",
    "pos_2hr = pd.Series(np.squeeze(reddit_test_df['2hr_change'])).quantile(pos_percent)\n",
    "pos_6hr = pd.Series(np.squeeze(reddit_test_df['6hr_change'])).quantile(pos_percent)\n",
    "pos_12hr = pd.Series(np.squeeze(reddit_test_df['12hr_change'])).quantile(pos_percent)\n",
    "pos_24hr = pd.Series(np.squeeze(reddit_test_df['24hr_change'])).quantile(pos_percent)\n",
    "cutoffs = {'1hr' : pos_1hr, '2hr' : pos_2hr, '6hr' : pos_6hr, '12hr' : pos_12hr, '24hr' : pos_24hr} \n",
    "       \n",
    "# Loop through each row in actual test df and prediction dfs\n",
    "for actual, pred_5, pred_10, pred_15, pred_20 in \\\n",
    "    zip(reddit_test_df.values, predictions_5, predictions_10, predictions_15, predictions_20):\n",
    "    \n",
    "    ##################################\n",
    "    # 1 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['1hr']] >= cutoffs['1hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['1hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['1hr']], \\\n",
    "            pred_5[0], pred_10[0], pred_15[0], pred_20[0])\n",
    "        titles_pos['1hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[0] >= cutoffs['1hr']: num_pred_5_above['1hr'] += 1\n",
    "        if pred_10[0] >= cutoffs['1hr']: num_pred_10_above['1hr'] += 1\n",
    "        if pred_15[0] >= cutoffs['1hr']: num_pred_15_above['1hr'] += 1\n",
    "        if pred_20[0] >= cutoffs['1hr']: num_pred_20_above['1hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[0] >= 0: num_pred_5_pos['1hr'] += 1\n",
    "        if pred_10[0] >= 0: num_pred_10_pos['1hr'] += 1\n",
    "        if pred_15[0] >= 0: num_pred_15_pos['1hr'] += 1\n",
    "        if pred_20[0] >= 0: num_pred_20_pos['1hr'] += 1\n",
    "            \n",
    "    ##################################\n",
    "    # 2 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['2hr']] >= cutoffs['2hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['2hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['2hr']], \\\n",
    "            pred_5[1], pred_10[1], pred_15[1], pred_20[1])\n",
    "        titles_pos['2hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[1] >= cutoffs['2hr']: num_pred_5_above['2hr'] += 1\n",
    "        if pred_10[1] >= cutoffs['2hr']: num_pred_10_above['2hr'] += 1\n",
    "        if pred_15[1] >= cutoffs['2hr']: num_pred_15_above['2hr'] += 1\n",
    "        if pred_20[1] >= cutoffs['2hr']: num_pred_20_above['2hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[1] >= 0: num_pred_5_pos['2hr'] += 1\n",
    "        if pred_10[1] >= 0: num_pred_10_pos['2hr'] += 1\n",
    "        if pred_15[1] >= 0: num_pred_15_pos['2hr'] += 1\n",
    "        if pred_20[1] >= 0: num_pred_20_pos['2hr'] += 1\n",
    "            \n",
    "    ##################################\n",
    "    # 6 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['6hr']] >= cutoffs['6hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['6hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['6hr']], \\\n",
    "            pred_5[2], pred_10[2], pred_15[2], pred_20[2])\n",
    "        titles_pos['6hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[2] >= cutoffs['6hr']: num_pred_5_above['6hr'] += 1\n",
    "        if pred_10[2] >= cutoffs['6hr']: num_pred_10_above['6hr'] += 1\n",
    "        if pred_15[2] >= cutoffs['6hr']: num_pred_15_above['6hr'] += 1\n",
    "        if pred_20[2] >= cutoffs['6hr']: num_pred_20_above['6hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[2] >= 0: num_pred_5_pos['6hr'] += 1\n",
    "        if pred_10[2] >= 0: num_pred_10_pos['6hr'] += 1\n",
    "        if pred_15[2] >= 0: num_pred_15_pos['6hr'] += 1\n",
    "        if pred_20[2] >= 0: num_pred_20_pos['6hr'] += 1\n",
    "            \n",
    "    ##################################\n",
    "    # 12 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['12hr']] >= cutoffs['12hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['12hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['12hr']], \\\n",
    "            pred_5[3], pred_10[3], pred_15[3], pred_20[3])\n",
    "        titles_pos['12hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[3] >= cutoffs['12hr']: num_pred_5_above['12hr'] += 1\n",
    "        if pred_10[3] >= cutoffs['12hr']: num_pred_10_above['12hr'] += 1\n",
    "        if pred_15[3] >= cutoffs['12hr']: num_pred_15_above['12hr'] += 1\n",
    "        if pred_20[3] >= cutoffs['12hr']: num_pred_20_above['12hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[3] >= 0: num_pred_5_pos['12hr'] += 1\n",
    "        if pred_10[3] >= 0: num_pred_10_pos['12hr'] += 1\n",
    "        if pred_15[3] >= 0: num_pred_15_pos['12hr'] += 1\n",
    "        if pred_20[3] >= 0: num_pred_20_pos['12hr'] += 1\n",
    "\n",
    "    ##################################\n",
    "    # 24 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['24hr']] >= cutoffs['24hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['24hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['24hr']], \\\n",
    "            pred_5[4], pred_10[4], pred_15[4], pred_20[4])\n",
    "        titles_pos['24hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[4] >= cutoffs['24hr']: num_pred_5_above['24hr'] += 1\n",
    "        if pred_10[4] >= cutoffs['24hr']: num_pred_10_above['24hr'] += 1\n",
    "        if pred_15[4] >= cutoffs['24hr']: num_pred_15_above['24hr'] += 1\n",
    "        if pred_20[4] >= cutoffs['24hr']: num_pred_20_above['24hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[4] >= 0: num_pred_5_pos['24hr'] += 1\n",
    "        if pred_10[4] >= 0: num_pred_10_pos['24hr'] += 1\n",
    "        if pred_15[4] >= 0: num_pred_15_pos['24hr'] += 1\n",
    "        if pred_20[4] >= 0: num_pred_20_pos['24hr'] += 1 \n",
    "        \n",
    "# Calculate percentage of correct predictions\n",
    "percent_pred_5_above = {'1hr' : (num_pred_5_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_5_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_5_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_5_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_5_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_10_above = {'1hr' : (num_pred_10_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_10_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_10_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_10_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_10_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_15_above = {'1hr' : (num_pred_15_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_15_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_15_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_15_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_15_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_20_above = {'1hr' : (num_pred_20_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_20_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_20_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_20_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_20_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_5_pos = {'1hr' : (num_pred_5_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_5_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_5_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_5_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_5_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_10_pos = {'1hr' : (num_pred_10_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_10_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_10_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_10_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_10_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_15_pos = {'1hr' : (num_pred_15_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_15_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_15_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_15_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_15_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_20_pos = {'1hr' : (num_pred_20_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_20_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_20_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_20_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_20_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "# Print results\n",
    "print ('PREDICTIONS +1 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in top %d%% (change >= %.2f%%): %d' % (100-int(pos_percent*100), cutoffs['1hr'], num_actual_above['1hr']))           \n",
    "print ('[05 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['1hr'], percent_pred_5_above['1hr'], num_pred_5_pos['1hr'], percent_pred_5_pos['1hr']))\n",
    "print ('[10 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['1hr'], percent_pred_10_above['1hr'], num_pred_10_pos['1hr'], percent_pred_10_pos['1hr']))\n",
    "print ('[15 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['1hr'], percent_pred_15_above['1hr'], num_pred_15_pos['1hr'], percent_pred_15_pos['1hr']))\n",
    "print ('[20 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['1hr'], percent_pred_20_above['1hr'], num_pred_20_pos['1hr'], percent_pred_20_pos['1hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +2 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in top %d%% (change >= %.2f%%): %d' % (100-int(pos_percent*100), cutoffs['2hr'], num_actual_above['2hr']))           \n",
    "print ('[05 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['2hr'], percent_pred_5_above['2hr'], num_pred_5_pos['2hr'], percent_pred_5_pos['2hr']))\n",
    "print ('[10 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['2hr'], percent_pred_10_above['2hr'], num_pred_10_pos['2hr'], percent_pred_10_pos['2hr']))\n",
    "print ('[15 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['2hr'], percent_pred_15_above['2hr'], num_pred_15_pos['2hr'], percent_pred_15_pos['2hr']))\n",
    "print ('[20 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['2hr'], percent_pred_20_above['2hr'], num_pred_20_pos['2hr'], percent_pred_20_pos['2hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +6 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in top %d%% (change >= %.2f%%): %d' % (100-int(pos_percent*100), cutoffs['6hr'], num_actual_above['6hr']))           \n",
    "print ('[05 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['6hr'], percent_pred_5_above['6hr'], num_pred_5_pos['6hr'], percent_pred_5_pos['6hr']))\n",
    "print ('[10 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['6hr'], percent_pred_10_above['6hr'], num_pred_10_pos['6hr'], percent_pred_10_pos['6hr']))\n",
    "print ('[15 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['6hr'], percent_pred_15_above['6hr'], num_pred_15_pos['6hr'], percent_pred_15_pos['6hr']))\n",
    "print ('[20 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['6hr'], percent_pred_20_above['6hr'], num_pred_20_pos['6hr'], percent_pred_20_pos['6hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +12 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in top %d%% (change >= %.2f%%): %d' % (100-int(pos_percent*100), cutoffs['12hr'], num_actual_above['12hr']))           \n",
    "print ('[05 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['12hr'], percent_pred_5_above['12hr'], num_pred_5_pos['12hr'], percent_pred_5_pos['12hr']))\n",
    "print ('[10 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['12hr'], percent_pred_10_above['12hr'], num_pred_10_pos['12hr'], percent_pred_10_pos['12hr']))\n",
    "print ('[15 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['12hr'], percent_pred_15_above['12hr'], num_pred_15_pos['12hr'], percent_pred_15_pos['12hr']))\n",
    "print ('[20 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['12hr'], percent_pred_20_above['12hr'], num_pred_20_pos['12hr'], percent_pred_20_pos['12hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +24 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in top %d%% (change >= %.2f%%): %d' % (100-int(pos_percent*100), cutoffs['24hr'], num_actual_above['24hr']))           \n",
    "print ('[05 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['24hr'], percent_pred_5_above['24hr'], num_pred_5_pos['24hr'], percent_pred_5_pos['24hr']))\n",
    "print ('[10 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['24hr'], percent_pred_10_above['24hr'], num_pred_10_pos['24hr'], percent_pred_10_pos['24hr']))\n",
    "print ('[15 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['24hr'], percent_pred_15_above['24hr'], num_pred_15_pos['24hr'], percent_pred_15_pos['24hr']))\n",
    "print ('[20 epoch train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['24hr'], percent_pred_20_above['24hr'], num_pred_20_pos['24hr'], percent_pred_20_pos['24hr']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First check - how many ACTUAL price changes SMALLER than cutoff did we PREDICT correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS +1 HOUR IN FUTURE:\n",
      "Num ACTUAL in bottom 20% (change <= -0.76%): 1881\n",
      "[05 epoch train] Below cutoff: 0 (0.00%), Negative: 776 (41.25%)\n",
      "[10 epoch train] Below cutoff: 11 (0.58%), Negative: 889 (47.26%)\n",
      "[15 epoch train] Below cutoff: 15 (0.80%), Negative: 908 (48.27%)\n",
      "[20 epoch train] Below cutoff: 46 (2.45%), Negative: 972 (51.67%)\n",
      "\n",
      "PREDICTIONS +2 HOUR IN FUTURE:\n",
      "Num ACTUAL in bottom 20% (change <= -1.14%): 1875\n",
      "[05 epoch train] Below cutoff: 3 (0.16%), Negative: 827 (44.11%)\n",
      "[10 epoch train] Below cutoff: 37 (1.97%), Negative: 838 (44.69%)\n",
      "[15 epoch train] Below cutoff: 62 (3.31%), Negative: 848 (45.23%)\n",
      "[20 epoch train] Below cutoff: 114 (6.08%), Negative: 890 (47.47%)\n",
      "\n",
      "PREDICTIONS +6 HOUR IN FUTURE:\n",
      "Num ACTUAL in bottom 20% (change <= -1.65%): 1881\n",
      "[05 epoch train] Below cutoff: 23 (1.22%), Negative: 768 (40.83%)\n",
      "[10 epoch train] Below cutoff: 136 (7.23%), Negative: 843 (44.82%)\n",
      "[15 epoch train] Below cutoff: 255 (13.56%), Negative: 901 (47.90%)\n",
      "[20 epoch train] Below cutoff: 308 (16.37%), Negative: 927 (49.28%)\n",
      "\n",
      "PREDICTIONS +12 HOUR IN FUTURE:\n",
      "Num ACTUAL in bottom 20% (change <= -2.47%): 1876\n",
      "[05 epoch train] Below cutoff: 12 (0.64%), Negative: 709 (37.79%)\n",
      "[10 epoch train] Below cutoff: 124 (6.61%), Negative: 777 (41.42%)\n",
      "[15 epoch train] Below cutoff: 256 (13.65%), Negative: 869 (46.32%)\n",
      "[20 epoch train] Below cutoff: 317 (16.90%), Negative: 895 (47.71%)\n",
      "\n",
      "PREDICTIONS +24 HOUR IN FUTURE:\n",
      "Num ACTUAL in bottom 20% (change <= -2.89%): 1875\n",
      "[05 epoch train] Below cutoff: 20 (1.07%), Negative: 649 (34.61%)\n",
      "[10 epoch train] Below cutoff: 187 (9.97%), Negative: 751 (40.05%)\n",
      "[15 epoch train] Below cutoff: 350 (18.67%), Negative: 856 (45.65%)\n",
      "[20 epoch train] Below cutoff: 409 (21.81%), Negative: 864 (46.08%)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "actual_columns = {'title' : 4, '1hr' : 5, '2hr' : 6, '6hr' : 7, '12hr' : 8, '24hr' : 9}\n",
    "\n",
    "num_actual_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "\n",
    "titles_neg = {'1hr' : [], '2hr' : [], '6hr' : [], '12hr' : [], '24hr' : []} \n",
    "\n",
    "num_pred_5_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_10_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_15_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_20_above = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "\n",
    "num_pred_5_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_10_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_15_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "num_pred_20_pos = {'1hr' : 0, '2hr' : 0, '6hr' : 0, '12hr' : 0, '24hr' : 0} \n",
    "\n",
    "# Determine cutoffs to only consider smallest 20% of price changes\n",
    "neg_percent = 0.2\n",
    "neg_1hr = pd.Series(np.squeeze(reddit_test_df['1hr_change'])).quantile(neg_percent)\n",
    "neg_2hr = pd.Series(np.squeeze(reddit_test_df['2hr_change'])).quantile(neg_percent)\n",
    "neg_6hr = pd.Series(np.squeeze(reddit_test_df['6hr_change'])).quantile(neg_percent)\n",
    "neg_12hr = pd.Series(np.squeeze(reddit_test_df['12hr_change'])).quantile(neg_percent)\n",
    "neg_24hr = pd.Series(np.squeeze(reddit_test_df['24hr_change'])).quantile(neg_percent)\n",
    "cutoffs = {'1hr' : neg_1hr, '2hr' : neg_2hr, '6hr' : neg_6hr, '12hr' : neg_12hr, '24hr' : neg_24hr} \n",
    "       \n",
    "# Loop through each row in actual test df and prediction dfs\n",
    "for actual, pred_5, pred_10, pred_15, pred_20 in \\\n",
    "    zip(reddit_test_df.values, predictions_5, predictions_10, predictions_15, predictions_20):\n",
    "    \n",
    "    ##################################\n",
    "    # 1 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['1hr']] <= cutoffs['1hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['1hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['1hr']], \\\n",
    "            pred_5[0], pred_10[0], pred_15[0], pred_20[0])\n",
    "        titles_neg['1hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[0] <= cutoffs['1hr']: num_pred_5_above['1hr'] += 1\n",
    "        if pred_10[0] <= cutoffs['1hr']: num_pred_10_above['1hr'] += 1\n",
    "        if pred_15[0] <= cutoffs['1hr']: num_pred_15_above['1hr'] += 1\n",
    "        if pred_20[0] <= cutoffs['1hr']: num_pred_20_above['1hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[0] <= 0: num_pred_5_pos['1hr'] += 1\n",
    "        if pred_10[0] <= 0: num_pred_10_pos['1hr'] += 1\n",
    "        if pred_15[0] <= 0: num_pred_15_pos['1hr'] += 1\n",
    "        if pred_20[0] <= 0: num_pred_20_pos['1hr'] += 1\n",
    "            \n",
    "    ##################################\n",
    "    # 2 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['2hr']] <= cutoffs['2hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['2hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['2hr']], \\\n",
    "            pred_5[1], pred_10[1], pred_15[1], pred_20[1])\n",
    "        titles_neg['2hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[1] <= cutoffs['2hr']: num_pred_5_above['2hr'] += 1\n",
    "        if pred_10[1] <= cutoffs['2hr']: num_pred_10_above['2hr'] += 1\n",
    "        if pred_15[1] <= cutoffs['2hr']: num_pred_15_above['2hr'] += 1\n",
    "        if pred_20[1] <= cutoffs['2hr']: num_pred_20_above['2hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[1] <= 0: num_pred_5_pos['2hr'] += 1\n",
    "        if pred_10[1] <= 0: num_pred_10_pos['2hr'] += 1\n",
    "        if pred_15[1] <= 0: num_pred_15_pos['2hr'] += 1\n",
    "        if pred_20[1] <= 0: num_pred_20_pos['2hr'] += 1\n",
    "            \n",
    "    ##################################\n",
    "    # 6 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['6hr']] <= cutoffs['6hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['6hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['6hr']], \\\n",
    "            pred_5[2], pred_10[2], pred_15[2], pred_20[2])\n",
    "        titles_neg['6hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[2] <= cutoffs['6hr']: num_pred_5_above['6hr'] += 1\n",
    "        if pred_10[2] <= cutoffs['6hr']: num_pred_10_above['6hr'] += 1\n",
    "        if pred_15[2] <= cutoffs['6hr']: num_pred_15_above['6hr'] += 1\n",
    "        if pred_20[2] <= cutoffs['6hr']: num_pred_20_above['6hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[2] <= 0: num_pred_5_pos['6hr'] += 1\n",
    "        if pred_10[2] <= 0: num_pred_10_pos['6hr'] += 1\n",
    "        if pred_15[2] <= 0: num_pred_15_pos['6hr'] += 1\n",
    "        if pred_20[2] <= 0: num_pred_20_pos['6hr'] += 1\n",
    "            \n",
    "    ##################################\n",
    "    # 12 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['12hr']] <= cutoffs['12hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['12hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['12hr']], \\\n",
    "            pred_5[3], pred_10[3], pred_15[3], pred_20[3])\n",
    "        titles_neg['12hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[3] <= cutoffs['12hr']: num_pred_5_above['12hr'] += 1\n",
    "        if pred_10[3] <= cutoffs['12hr']: num_pred_10_above['12hr'] += 1\n",
    "        if pred_15[3] <= cutoffs['12hr']: num_pred_15_above['12hr'] += 1\n",
    "        if pred_20[3] <= cutoffs['12hr']: num_pred_20_above['12hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[3] <= 0: num_pred_5_pos['12hr'] += 1\n",
    "        if pred_10[3] <= 0: num_pred_10_pos['12hr'] += 1\n",
    "        if pred_15[3] <= 0: num_pred_15_pos['12hr'] += 1\n",
    "        if pred_20[3] <= 0: num_pred_20_pos['12hr'] += 1\n",
    "\n",
    "    ##################################\n",
    "    # 24 hr\n",
    "    ##################################\n",
    "    if actual[actual_columns['24hr']] <= cutoffs['24hr']:\n",
    "        # Increment actual count\n",
    "        num_actual_above['24hr'] += 1\n",
    "        \n",
    "        # Save title and corresponding predictions\n",
    "        to_add = (actual[actual_columns['title']], actual[actual_columns['24hr']], \\\n",
    "            pred_5[4], pred_10[4], pred_15[4], pred_20[4])\n",
    "        titles_neg['24hr'].append(to_add)\n",
    "\n",
    "        # Increment prediction counts (if prediction >= cutoff)    \n",
    "        if pred_5[4] <= cutoffs['24hr']: num_pred_5_above['24hr'] += 1\n",
    "        if pred_10[4] <= cutoffs['24hr']: num_pred_10_above['24hr'] += 1\n",
    "        if pred_15[4] <= cutoffs['24hr']: num_pred_15_above['24hr'] += 1\n",
    "        if pred_20[4] <= cutoffs['24hr']: num_pred_20_above['24hr'] += 1\n",
    "\n",
    "        # Increment prediction counts (if prediction positive)    \n",
    "        if pred_5[4] <= 0: num_pred_5_pos['24hr'] += 1\n",
    "        if pred_10[4] <= 0: num_pred_10_pos['24hr'] += 1\n",
    "        if pred_15[4] <= 0: num_pred_15_pos['24hr'] += 1\n",
    "        if pred_20[4] <= 0: num_pred_20_pos['24hr'] += 1 \n",
    "        \n",
    "# Calculate percentage of correct predictions\n",
    "percent_pred_5_above = {'1hr' : (num_pred_5_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_5_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_5_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_5_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_5_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_10_above = {'1hr' : (num_pred_10_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_10_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_10_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_10_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_10_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_15_above = {'1hr' : (num_pred_15_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_15_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_15_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_15_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_15_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_20_above = {'1hr' : (num_pred_20_above['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_20_above['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_20_above['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_20_above['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_20_above['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_5_pos = {'1hr' : (num_pred_5_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_5_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_5_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_5_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_5_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_10_pos = {'1hr' : (num_pred_10_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_10_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_10_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_10_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_10_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_15_pos = {'1hr' : (num_pred_15_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_15_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_15_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_15_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_15_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "percent_pred_20_pos = {'1hr' : (num_pred_20_pos['1hr'] / num_actual_above['1hr'])*100, \\\n",
    "                      '2hr' : (num_pred_20_pos['2hr'] / num_actual_above['2hr'])*100, \\\n",
    "                      '6hr' : (num_pred_20_pos['6hr'] / num_actual_above['6hr'])*100, \\\n",
    "                      '12hr' : (num_pred_20_pos['12hr'] / num_actual_above['12hr'])*100, \\\n",
    "                      '24hr' : (num_pred_20_pos['24hr'] / num_actual_above['24hr'])*100 } \n",
    "\n",
    "# Print results\n",
    "print ('PREDICTIONS +1 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in bottom %d%% (change <= %.2f%%): %d' % (int(neg_percent*100), cutoffs['1hr'], num_actual_above['1hr']))           \n",
    "print ('[05 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['1hr'], percent_pred_5_above['1hr'], num_pred_5_pos['1hr'], percent_pred_5_pos['1hr']))\n",
    "print ('[10 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['1hr'], percent_pred_10_above['1hr'], num_pred_10_pos['1hr'], percent_pred_10_pos['1hr']))\n",
    "print ('[15 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['1hr'], percent_pred_15_above['1hr'], num_pred_15_pos['1hr'], percent_pred_15_pos['1hr']))\n",
    "print ('[20 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['1hr'], percent_pred_20_above['1hr'], num_pred_20_pos['1hr'], percent_pred_20_pos['1hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +2 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in bottom %d%% (change <= %.2f%%): %d' % (int(neg_percent*100), cutoffs['2hr'], num_actual_above['2hr']))           \n",
    "print ('[05 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['2hr'], percent_pred_5_above['2hr'], num_pred_5_pos['2hr'], percent_pred_5_pos['2hr']))\n",
    "print ('[10 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['2hr'], percent_pred_10_above['2hr'], num_pred_10_pos['2hr'], percent_pred_10_pos['2hr']))\n",
    "print ('[15 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['2hr'], percent_pred_15_above['2hr'], num_pred_15_pos['2hr'], percent_pred_15_pos['2hr']))\n",
    "print ('[20 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['2hr'], percent_pred_20_above['2hr'], num_pred_20_pos['2hr'], percent_pred_20_pos['2hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +6 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in bottom %d%% (change <= %.2f%%): %d' % (int(neg_percent*100), cutoffs['6hr'], num_actual_above['6hr']))           \n",
    "print ('[05 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['6hr'], percent_pred_5_above['6hr'], num_pred_5_pos['6hr'], percent_pred_5_pos['6hr']))\n",
    "print ('[10 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['6hr'], percent_pred_10_above['6hr'], num_pred_10_pos['6hr'], percent_pred_10_pos['6hr']))\n",
    "print ('[15 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['6hr'], percent_pred_15_above['6hr'], num_pred_15_pos['6hr'], percent_pred_15_pos['6hr']))\n",
    "print ('[20 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['6hr'], percent_pred_20_above['6hr'], num_pred_20_pos['6hr'], percent_pred_20_pos['6hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +12 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in bottom %d%% (change <= %.2f%%): %d' % (int(neg_percent*100), cutoffs['12hr'], num_actual_above['12hr']))           \n",
    "print ('[05 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['12hr'], percent_pred_5_above['12hr'], num_pred_5_pos['12hr'], percent_pred_5_pos['12hr']))\n",
    "print ('[10 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['12hr'], percent_pred_10_above['12hr'], num_pred_10_pos['12hr'], percent_pred_10_pos['12hr']))\n",
    "print ('[15 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['12hr'], percent_pred_15_above['12hr'], num_pred_15_pos['12hr'], percent_pred_15_pos['12hr']))\n",
    "print ('[20 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['12hr'], percent_pred_20_above['12hr'], num_pred_20_pos['12hr'], percent_pred_20_pos['12hr']))\n",
    "\n",
    "print ('\\nPREDICTIONS +24 HOUR IN FUTURE:')\n",
    "print ('Num ACTUAL in bottom %d%% (change <= %.2f%%): %d' % (int(neg_percent*100), cutoffs['24hr'], num_actual_above['24hr']))           \n",
    "print ('[05 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_5_above['24hr'], percent_pred_5_above['24hr'], num_pred_5_pos['24hr'], percent_pred_5_pos['24hr']))\n",
    "print ('[10 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_10_above['24hr'], percent_pred_10_above['24hr'], num_pred_10_pos['24hr'], percent_pred_10_pos['24hr']))\n",
    "print ('[15 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_15_above['24hr'], percent_pred_15_above['24hr'], num_pred_15_pos['24hr'], percent_pred_15_pos['24hr']))\n",
    "print ('[20 epoch train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "       (num_pred_20_above['24hr'], percent_pred_20_above['24hr'], num_pred_20_pos['24hr'], percent_pred_20_pos['24hr']))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
