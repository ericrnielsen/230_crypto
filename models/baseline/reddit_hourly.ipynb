{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Input, LSTM, Dropout\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (18,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distribution(df, labels_column_name):\n",
    "    n = df.shape[0]\n",
    "    print(\"{} labels frequency:\".format(labels_column_name))\n",
    "    print(\"Value\\tCount\\tPercent\")\n",
    "    indeces = df[labels_column_name].value_counts().index.tolist()\n",
    "    counts = df[labels_column_name].value_counts().tolist()\n",
    "    for val, count in zip(indeces, counts):\n",
    "        print(\"{}\\t{}\\t{}%\".format(val, count, (count / float(n)) * 100))\n",
    "    \n",
    "def get_max_words(text_arr):\n",
    "    max_words = 0\n",
    "    for line in text_arr:\n",
    "        num_words = len(line.split())\n",
    "        if num_words > max_words:\n",
    "            max_words = num_words\n",
    "    return max_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the csv data\n",
    "reddit_train_df = pd.read_csv(\"../../data/reddit/labeled/score10_all_sub_labeled_train.csv\", index_col=0)\n",
    "reddit_test_df = pd.read_csv(\"../../data/reddit/labeled/score10_all_sub_labeled_dev.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of words per post: 78\n",
      "\n",
      "Getting x_train, y_train, x_test, and y_test...\n",
      "102991 train sequences\n",
      "9353 test sequences\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11a2e4da0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111f0c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine max post length\n",
    "max_words_train = get_max_words(reddit_train_df.title.values)\n",
    "max_words_test = get_max_words(reddit_test_df.title.values)\n",
    "max_words = max(max_words_train, max_words_test)\n",
    "print(\"Max number of words per post: {}\".format(max_words))\n",
    "\n",
    "# Label and title columns in datasets\n",
    "LABEL_1HR, LABEL_2HR, LABEL_6HR, LABEL_12HR, LABEL_24HR = \\\n",
    "    '1hr_change', '2hr_change', '6hr_change', '12hr_change', '24hr_change'\n",
    "TEXT_COL = 'title'\n",
    "\n",
    "# Split into x_train and y_train\n",
    "print('\\nGetting x_train, y_train, x_test, and y_test...')\n",
    "(x_train, y_train_1hr, y_train_2hr, y_train_6hr, y_train_12hr, y_train_24hr) = \\\n",
    "    reddit_train_df[TEXT_COL].values, reddit_train_df[LABEL_1HR], reddit_train_df[LABEL_2HR], \\\n",
    "    reddit_train_df[LABEL_6HR], reddit_train_df[LABEL_12HR], reddit_train_df[LABEL_24HR]\n",
    "\n",
    "m_train = x_train.shape[0]\n",
    "y_train_1hr = y_train_1hr.values.reshape((m_train, 1))\n",
    "y_train_2hr = y_train_2hr.values.reshape((m_train, 1))\n",
    "y_train_6hr = y_train_6hr.values.reshape((m_train, 1))\n",
    "y_train_12hr = y_train_12hr.values.reshape((m_train, 1))\n",
    "y_train_24hr = y_train_24hr.values.reshape((m_train, 1))\n",
    "    \n",
    "(x_test, y_test_1hr, y_test_2hr, y_test_6hr, y_test_12hr, y_test_24hr) = \\\n",
    "    reddit_test_df[TEXT_COL].values, reddit_test_df[LABEL_1HR], reddit_test_df[LABEL_2HR], \\\n",
    "    reddit_test_df[LABEL_6HR], reddit_test_df[LABEL_12HR], reddit_test_df[LABEL_24HR]\n",
    "\n",
    "m_test = x_test.shape[0]\n",
    "y_test_1hr = y_test_1hr.values.reshape((m_test, 1))\n",
    "y_test_2hr = y_test_2hr.values.reshape((m_test, 1))\n",
    "y_test_6hr = y_test_6hr.values.reshape((m_test, 1))\n",
    "y_test_12hr = y_test_12hr.values.reshape((m_test, 1))\n",
    "y_test_24hr = y_test_24hr.values.reshape((m_test, 1)) \n",
    "\n",
    "# Print info about train and test\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# Plot distributions of labels\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.distplot(reddit_train_df[LABEL_1HR].values, label='Train')\n",
    "sns.distplot(reddit_test_df[LABEL_1HR].values, label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (102991, 78)\n",
      "x_test shape: (9353, 78)\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "max_features = 200000 # Num words in our vocabulary \n",
    "maxlen = max_words  # cut texts after this number of words\n",
    "batch_size = 32  # Mini-batch size\n",
    "num_epochs = 5 \n",
    "\n",
    "# Train tokenizer to create a vocabulary of words\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Vectorize each headline\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Update x_train and x_test to be 'sequences' of data\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(test_sequences, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding layer using word2vec\n",
    "EMBEDDING_FILE = \"../../data/embeddings/GoogleNews-vectors-negative300.bin\"\n",
    "EMBEDDING_DIM = 300\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "        \n",
    "embedding_layer = Embedding(nb_words,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=maxlen,\n",
    "        trainable=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 3/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual embeddings\n",
    "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "embeddings = embedding_layer(sequence_input)\n",
    "\n",
    "# Construct the model (attempt 1 - didn't work)\n",
    "#X = LSTM(128, return_sequences=True)(embeddings)\n",
    "#X = Dropout(0.5)(X)\n",
    "#X = LSTM(128, return_sequences=False)(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "#X = Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "# Construct the model (attempt 1 - didn't work)\n",
    "X = Bidirectional(LSTM(128, return_sequences=False))(embeddings)\n",
    "X = Dense(5)(X)\n",
    "\n",
    "# Select y labels\n",
    "y_train = np.concatenate((y_train_1hr, y_train_2hr, y_train_6hr, y_train_12hr, y_train_24hr), axis=1)\n",
    "y_test = np.concatenate((y_test_1hr, y_test_2hr, y_test_6hr, y_test_12hr, y_test_24hr), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the BTC model\n",
    "model = Model(inputs=sequence_input, outputs=X)\n",
    "\n",
    "# Compile the BTC model\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error', \n",
    "                    optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Setup model checkpoint\n",
    "checkpoint_5 = ModelCheckpoint(\"checkpoints/reddit-5epochs.hdf5\")\n",
    "\n",
    "# Run the BTC model\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_5])\n",
    "\n",
    "score, acc = model_btc.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC model for 15 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9353/9353 [==============================] - 8s 892us/step\n",
      "Test score: 2.0105437362759964\n",
      "Test accuracy: 0.000748422985011647\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/10\n",
      "102991/102991 [==============================] - 286s 3ms/step - loss: 1.3101 - acc: 0.0011 - val_loss: 2.0688 - val_acc: 6.4151e-04\n",
      "Epoch 2/10\n",
      "102991/102991 [==============================] - 289s 3ms/step - loss: 1.1804 - acc: 0.0011 - val_loss: 2.1797 - val_acc: 5.3459e-04\n",
      "Epoch 3/10\n",
      "102991/102991 [==============================] - 291s 3ms/step - loss: 1.0664 - acc: 0.0011 - val_loss: 2.1731 - val_acc: 5.3459e-04\n",
      "Epoch 4/10\n",
      "102991/102991 [==============================] - 290s 3ms/step - loss: 0.9696 - acc: 0.0011 - val_loss: 2.2821 - val_acc: 4.2767e-04\n",
      "Epoch 5/10\n",
      "102991/102991 [==============================] - 291s 3ms/step - loss: 0.8832 - acc: 0.0011 - val_loss: 2.4185 - val_acc: 6.4151e-04\n",
      "Epoch 6/10\n",
      "102991/102991 [==============================] - 292s 3ms/step - loss: 0.8066 - acc: 0.0011 - val_loss: 2.4223 - val_acc: 2.1384e-04\n",
      "Epoch 7/10\n",
      "102991/102991 [==============================] - 298s 3ms/step - loss: 0.7424 - acc: 0.0011 - val_loss: 2.4710 - val_acc: 4.2767e-04\n",
      "Epoch 8/10\n",
      "102991/102991 [==============================] - 297s 3ms/step - loss: 0.6881 - acc: 0.0011 - val_loss: 2.5580 - val_acc: 2.1384e-04\n",
      "Epoch 9/10\n",
      "102991/102991 [==============================] - 294s 3ms/step - loss: 0.6427 - acc: 0.0011 - val_loss: 2.5826 - val_acc: 2.1384e-04\n",
      "Epoch 10/10\n",
      "102991/102991 [==============================] - 297s 3ms/step - loss: 0.5956 - acc: 0.0012 - val_loss: 2.5865 - val_acc: 3.2075e-04\n",
      "9353/9353 [==============================] - 9s 950us/step\n",
      "Test score: 2.5864633018545042\n",
      "Test accuracy: 0.0003207527092277309\n"
     ]
    }
   ],
   "source": [
    "# Setup model checkpoints\\n\",\n",
    "checkpoint_10 = ModelCheckpoint(\"checkpoints/reddit-10epochs.hdf5\")\n",
    "checkpoint_15 = ModelCheckpoint(\"checkpoints/reddit-15epochs.hdf5\")\n",
    "checkpoint_20 = ModelCheckpoint(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "\n",
    "# Run the BTC model 5 more epochs\\n\",\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_10])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the BTC model 5 more epochs\\n\",\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_15])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the BTC model 5 more epochs\\n\",\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_20])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9353/9353 [==============================] - 9s 966us/step\n",
      "Test score: 11.454025297308688\n",
      "Test accuracy: 0.32535015505596265\n",
      "9353/9353 [==============================] - 9s 961us/step\n",
      "Test score: 14.112859787844622\n",
      "Test accuracy: 0.3053565700860581\n",
      "9353/9353 [==============================] - 9s 957us/step\n",
      "Test score: 16.574149997453823\n",
      "Test accuracy: 0.28931893511059625\n",
      "9353/9353 [==============================] - 9s 938us/step\n",
      "Test score: 18.188835654783336\n",
      "Test accuracy: 0.29338180263176533\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# After 5 epochs\n",
    "###################################################################\n",
    "model_5 = Model(inputs=sequence_input, outputs=X)\n",
    "model_5.load_weights(\"checkpoints/reddit-5epochs.hdf5\")\n",
    "model_5.compile(loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "score_5, acc_5 = model_5.evaluate(x_test,\n",
    "                                  y_test,\n",
    "                                  batch_size=batch_size)\n",
    "predictions_5 = model_5.predict(x_test)\n",
    "print('Test score:', score_5)\n",
    "print('Test accuracy:', acc_5)\n",
    "                     \n",
    "###################################################################\n",
    "# After 10 epochs\n",
    "###################################################################\n",
    "model_10 = Model(inputs=sequence_input, outputs=X)\n",
    "model_10.load_weights(\"checkpoints/reddit-10epochs.hdf5\")\n",
    "model_10.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_10, acc_10 = model_10.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_10 = model_10.predict(x_test)\n",
    "print('Test score:', score_10)\n",
    "print('Test accuracy:', acc_10)\n",
    "\n",
    "###################################################################\n",
    "# After 15 epochs\n",
    "###################################################################\n",
    "model_15 = Model(inputs=sequence_input, outputs=X)\n",
    "model_15.load_weights(\"checkpoints/reddit-15epochs.hdf5\")\n",
    "model_15.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_15, acc_15 = model_15.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_15 = model_15.predict(x_test)\n",
    "print('Test score:', score_15)\n",
    "print('Test accuracy:', acc_15)\n",
    "\n",
    "###################################################################\n",
    "# After 20 epochs\n",
    "###################################################################\n",
    "model_20 = Model(inputs=sequence_input, outputs=X)\n",
    "model_20.load_weights(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "model_20.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_20, acc_20 = model_20.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_20 = model_20.predict(x_test)\n",
    "print('Test score:', score_20)\n",
    "print('Test accuracy:', acc_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC model for 10 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 292s 3ms/step - loss: 6.5828 - acc: 0.4546 - val_loss: 17.9481 - val_acc: 0.2896\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 296s 3ms/step - loss: 6.3696 - acc: 0.4584 - val_loss: 18.6649 - val_acc: 0.2952\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 295s 3ms/step - loss: 6.2003 - acc: 0.4616 - val_loss: 18.9551 - val_acc: 0.2808\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 296s 3ms/step - loss: 6.0739 - acc: 0.4632 - val_loss: 18.3648 - val_acc: 0.2976\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 296s 3ms/step - loss: 5.9542 - acc: 0.4638 - val_loss: 18.8626 - val_acc: 0.2853\n",
      "9353/9353 [==============================] - 9s 993us/step\n",
      "Test score: 18.862592671652422\n",
      "Test accuracy: 0.2852560675814612\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 295s 3ms/step - loss: 5.8420 - acc: 0.4673 - val_loss: 18.6201 - val_acc: 0.2964\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 297s 3ms/step - loss: 5.7438 - acc: 0.4683 - val_loss: 19.4797 - val_acc: 0.2886\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 319s 3ms/step - loss: 5.6798 - acc: 0.4696 - val_loss: 18.7411 - val_acc: 0.2963\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 323s 3ms/step - loss: 5.5797 - acc: 0.4703 - val_loss: 18.9759 - val_acc: 0.2911\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 308s 3ms/step - loss: 5.5036 - acc: 0.4728 - val_loss: 19.2355 - val_acc: 0.2865\n",
      "9353/9353 [==============================] - 9s 1ms/step\n",
      "Test score: 19.235495849661582\n",
      "Test accuracy: 0.28653907837216946\n"
     ]
    }
   ],
   "source": [
    "# Setup model checkpoints\n",
    "checkpoint_25 = ModelCheckpoint(\"checkpoints/reddit-25epochs.hdf5\")\n",
    "checkpoint_30 = ModelCheckpoint(\"checkpoints/reddit-30epochs.hdf5\")\n",
    "\n",
    "# Load model trained for 20 epochs\n",
    "model_new = Model(inputs=sequence_input, outputs=X)\n",
    "model_new.load_weights(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "model_new.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model_new.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_25])\n",
    "score, acc = model_new.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model_new.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_30])\n",
    "score, acc = model_new.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC model for 20 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 339s 3ms/step - loss: 5.4687 - acc: 0.4725 - val_loss: 19.2884 - val_acc: 0.2887\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 315s 3ms/step - loss: 5.3882 - acc: 0.4741 - val_loss: 19.1244 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 376s 4ms/step - loss: 5.3073 - acc: 0.4759 - val_loss: 19.1210 - val_acc: 0.2875\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 318s 3ms/step - loss: 5.2593 - acc: 0.4770 - val_loss: 19.3124 - val_acc: 0.2851\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 294s 3ms/step - loss: 5.2170 - acc: 0.4778 - val_loss: 19.1995 - val_acc: 0.2832\n",
      "9353/9353 [==============================] - 9s 990us/step\n",
      "Test score: 19.199506615057842\n",
      "Test accuracy: 0.28322463380892776\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 293s 3ms/step - loss: 5.1585 - acc: 0.4796 - val_loss: 19.2978 - val_acc: 0.2877\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 299s 3ms/step - loss: 5.1072 - acc: 0.4801 - val_loss: 19.3708 - val_acc: 0.2875\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 298s 3ms/step - loss: 5.0644 - acc: 0.4803 - val_loss: 19.4919 - val_acc: 0.2842\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 299s 3ms/step - loss: 5.0245 - acc: 0.4807 - val_loss: 19.3272 - val_acc: 0.2873\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 301s 3ms/step - loss: 4.9886 - acc: 0.4820 - val_loss: 19.7179 - val_acc: 0.2781\n",
      "9353/9353 [==============================] - 10s 1ms/step\n",
      "Test score: 19.717947026414564\n",
      "Test accuracy: 0.2780925906221968\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 303s 3ms/step - loss: 4.9575 - acc: 0.4817 - val_loss: 19.4542 - val_acc: 0.2885\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 304s 3ms/step - loss: 4.9150 - acc: 0.4835 - val_loss: 19.5900 - val_acc: 0.2833\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 307s 3ms/step - loss: 4.8787 - acc: 0.4835 - val_loss: 19.4779 - val_acc: 0.2832\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 305s 3ms/step - loss: 4.8420 - acc: 0.4848 - val_loss: 19.6072 - val_acc: 0.2817\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 307s 3ms/step - loss: 4.8141 - acc: 0.4855 - val_loss: 19.9487 - val_acc: 0.2792\n",
      "9353/9353 [==============================] - 10s 1ms/step\n",
      "Test score: 19.948669520467536\n",
      "Test accuracy: 0.2791617662877587\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 307s 3ms/step - loss: 4.7808 - acc: 0.4862 - val_loss: 19.5814 - val_acc: 0.2835\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 307s 3ms/step - loss: 4.7404 - acc: 0.4875 - val_loss: 19.6677 - val_acc: 0.2822\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 308s 3ms/step - loss: 4.7174 - acc: 0.4884 - val_loss: 19.5875 - val_acc: 0.2835\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 308s 3ms/step - loss: 4.6843 - acc: 0.4892 - val_loss: 19.5841 - val_acc: 0.2814\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 308s 3ms/step - loss: 4.6526 - acc: 0.4893 - val_loss: 19.7204 - val_acc: 0.2783\n",
      "9353/9353 [==============================] - 10s 1ms/step\n",
      "Test score: 19.720371447717852\n",
      "Test accuracy: 0.27830642575530923\n"
     ]
    }
   ],
   "source": [
    "# Setup model checkpoints\n",
    "checkpoint_35 = ModelCheckpoint(\"checkpoints/reddit-35epochs.hdf5\")\n",
    "checkpoint_40 = ModelCheckpoint(\"checkpoints/reddit-40epochs.hdf5\")\n",
    "checkpoint_45 = ModelCheckpoint(\"checkpoints/reddit-45epochs.hdf5\")\n",
    "checkpoint_50 = ModelCheckpoint(\"checkpoints/reddit-50epochs.hdf5\")\n",
    "\n",
    "# Load model trained for 30 epochs\n",
    "model_new2 = Model(inputs=sequence_input, outputs=X)\n",
    "model_new2.load_weights(\"checkpoints/reddit-30epochs.hdf5\")\n",
    "model_new2.compile(loss='mean_squared_error',\n",
    "                   optimizer='adam',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model_new2.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_35])\n",
    "score, acc = model_new2.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model_new2.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_40])\n",
    "score, acc = model_new2.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model_new2.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_45])\n",
    "score, acc = model_new2.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model_new2.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_50])\n",
    "score, acc = model_new2.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9353/9353 [==============================] - 9s 920us/step\n",
      "Test score: 18.862592671652422\n",
      "Test accuracy: 0.2852560675814612\n",
      "9353/9353 [==============================] - 9s 927us/step\n",
      "Test score: 19.235495849661582\n",
      "Test accuracy: 0.28653907837216946\n",
      "9353/9353 [==============================] - 9s 937us/step\n",
      "Test score: 19.199506615057842\n",
      "Test accuracy: 0.28322463380892776\n",
      "9353/9353 [==============================] - 9s 944us/step\n",
      "Test score: 19.717947026414564\n",
      "Test accuracy: 0.2780925906221968\n",
      "9353/9353 [==============================] - 9s 925us/step\n",
      "Test score: 19.948669520467536\n",
      "Test accuracy: 0.2791617662877587\n",
      "9353/9353 [==============================] - 8s 903us/step\n",
      "Test score: 19.720371447717852\n",
      "Test accuracy: 0.27830642575530923\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# After 25 epochs\n",
    "###################################################################\n",
    "model_25 = Model(inputs=sequence_input, outputs=X)\n",
    "model_25.load_weights(\"checkpoints/reddit-25epochs.hdf5\")\n",
    "model_25.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_25, acc_25 = model_25.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_25 = model_25.predict(x_test)\n",
    "print('Test score:', score_25)\n",
    "print('Test accuracy:', acc_25)\n",
    "                     \n",
    "###################################################################\n",
    "# After 30 epochs\n",
    "###################################################################\n",
    "model_30 = Model(inputs=sequence_input, outputs=X)\n",
    "model_30.load_weights(\"checkpoints/reddit-30epochs.hdf5\")\n",
    "model_30.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_30, acc_30 = model_30.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_30 = model_30.predict(x_test)\n",
    "print('Test score:', score_30)\n",
    "print('Test accuracy:', acc_30)\n",
    "\n",
    "###################################################################\n",
    "# After 35 epochs\n",
    "###################################################################\n",
    "model_35 = Model(inputs=sequence_input, outputs=X)\n",
    "model_35.load_weights(\"checkpoints/reddit-35epochs.hdf5\")\n",
    "model_35.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_35, acc_35 = model_35.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_35 = model_35.predict(x_test)\n",
    "print('Test score:', score_35)\n",
    "print('Test accuracy:', acc_35)\n",
    "\n",
    "###################################################################\n",
    "# After 40 epochs\n",
    "###################################################################\n",
    "model_40 = Model(inputs=sequence_input, outputs=X)\n",
    "model_40.load_weights(\"checkpoints/reddit-40epochs.hdf5\")\n",
    "model_40.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_40, acc_40 = model_40.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_40 = model_40.predict(x_test)\n",
    "print('Test score:', score_40)\n",
    "print('Test accuracy:', acc_40)\n",
    "\n",
    "###################################################################\n",
    "# After 45 epochs\n",
    "###################################################################\n",
    "model_45 = Model(inputs=sequence_input, outputs=X)\n",
    "model_45.load_weights(\"checkpoints/reddit-45epochs.hdf5\")\n",
    "model_45.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_45, acc_45 = model_45.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_45 = model_45.predict(x_test)\n",
    "print('Test score:', score_45)\n",
    "print('Test accuracy:', acc_45)\n",
    "\n",
    "###################################################################\n",
    "# After 50 epochs\n",
    "###################################################################\n",
    "model_50 = Model(inputs=sequence_input, outputs=X)\n",
    "model_50.load_weights(\"checkpoints/reddit-50epochs.hdf5\")\n",
    "model_50.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_50, acc_50 = model_50.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_50 = model_50.predict(x_test)\n",
    "print('Test score:', score_50)\n",
    "print('Test accuracy:', acc_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, organize predictions from each number of epochs trained and print summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER 5 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0228\tMin: -0.9305\t25%: -0.0631\t75%: 0.1112\tMax: 0.9399\n",
      "[+02 hr]\tMean: 0.0195\tMin: -1.5050\t25%: -0.1222\t75%: 0.1651\tMax: 1.8022\n",
      "[+06 hr]\tMean: 0.1159\tMin: -4.7486\t25%: -0.2228\t75%: 0.4615\tMax: 4.9317\n",
      "[+12 hr]\tMean: 0.2400\tMin: -6.5284\t25%: -0.2652\t75%: 0.7602\tMax: 7.4593\n",
      "[+24 hr]\tMean: 0.4623\tMin: -8.7002\t25%: -0.3023\t75%: 1.2281\tMax: 9.2941\n",
      "\n",
      "AFTER 10 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0260\tMin: -1.4070\t25%: -0.1506\t75%: 0.1927\tMax: 2.6116\n",
      "[+02 hr]\tMean: 0.0589\tMin: -2.6301\t25%: -0.2617\t75%: 0.3645\tMax: 5.1058\n",
      "[+06 hr]\tMean: 0.1841\tMin: -8.5745\t25%: -0.6412\t75%: 0.9734\tMax: 13.4106\n",
      "[+12 hr]\tMean: 0.4062\tMin: -12.1255\t25%: -0.8545\t75%: 1.6208\tMax: 20.2075\n",
      "[+24 hr]\tMean: 0.6845\tMin: -15.7347\t25%: -1.2130\t75%: 2.5223\tMax: 28.2422\n",
      "\n",
      "AFTER 15 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0273\tMin: -1.6031\t25%: -0.1787\t75%: 0.2236\tMax: 1.9438\n",
      "[+02 hr]\tMean: 0.0665\tMin: -3.1627\t25%: -0.3402\t75%: 0.4541\tMax: 4.4016\n",
      "[+06 hr]\tMean: 0.1248\tMin: -9.1286\t25%: -0.9506\t75%: 1.1505\tMax: 11.5388\n",
      "[+12 hr]\tMean: 0.2658\tMin: -13.7218\t25%: -1.3889\t75%: 1.8541\tMax: 17.5045\n",
      "[+24 hr]\tMean: 0.4352\tMin: -18.7471\t25%: -2.0951\t75%: 2.9027\tMax: 24.8039\n",
      "\n",
      "AFTER 20 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0131\tMin: -1.6869\t25%: -0.2503\t75%: 0.2130\tMax: 1.8026\n",
      "[+02 hr]\tMean: 0.0049\tMin: -3.2077\t25%: -0.4664\t75%: 0.4484\tMax: 3.9174\n",
      "[+06 hr]\tMean: 0.0861\tMin: -9.8513\t25%: -1.1402\t75%: 1.2496\tMax: 10.1864\n",
      "[+12 hr]\tMean: 0.2396\tMin: -14.6935\t25%: -1.6946\t75%: 2.0798\tMax: 15.8838\n",
      "[+24 hr]\tMean: 0.4763\tMin: -20.3679\t25%: -2.4743\t75%: 3.3964\tMax: 23.5398\n",
      "\n",
      "AFTER 25 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0020\tMin: -1.7840\t25%: -0.2593\t75%: 0.2516\tMax: 1.8451\n",
      "[+02 hr]\tMean: 0.0117\tMin: -3.2145\t25%: -0.4692\t75%: 0.4860\tMax: 3.6222\n",
      "[+06 hr]\tMean: 0.0467\tMin: -8.8221\t25%: -1.2364\t75%: 1.3110\tMax: 9.8993\n",
      "[+12 hr]\tMean: 0.1945\tMin: -13.5869\t25%: -1.8147\t75%: 2.1161\tMax: 15.9502\n",
      "[+24 hr]\tMean: 0.3440\tMin: -22.0818\t25%: -2.7472\t75%: 3.4057\tMax: 25.3886\n",
      "\n",
      "AFTER 30 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0038\tMin: -1.7354\t25%: -0.2701\t75%: 0.2553\tMax: 1.9791\n",
      "[+02 hr]\tMean: 0.0254\tMin: -3.4255\t25%: -0.4944\t75%: 0.5347\tMax: 4.3911\n",
      "[+06 hr]\tMean: 0.1050\tMin: -9.4549\t25%: -1.2379\t75%: 1.3975\tMax: 12.2267\n",
      "[+12 hr]\tMean: 0.2805\tMin: -13.9080\t25%: -1.7933\t75%: 2.2822\tMax: 19.6463\n",
      "[+24 hr]\tMean: 0.5013\tMin: -22.7783\t25%: -2.6817\t75%: 3.7071\tMax: 29.4548\n",
      "\n",
      "AFTER 35 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0238\tMin: -1.8978\t25%: -0.2499\t75%: 0.2887\tMax: 2.0001\n",
      "[+02 hr]\tMean: 0.0426\tMin: -3.5346\t25%: -0.4698\t75%: 0.5432\tMax: 4.1256\n",
      "[+06 hr]\tMean: 0.1034\tMin: -9.3706\t25%: -1.2455\t75%: 1.4042\tMax: 11.0425\n",
      "[+12 hr]\tMean: 0.2458\tMin: -14.9555\t25%: -1.8320\t75%: 2.2783\tMax: 17.9006\n",
      "[+24 hr]\tMean: 0.4437\tMin: -25.6936\t25%: -2.7169\t75%: 3.6462\tMax: 26.5857\n",
      "\n",
      "AFTER 40 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0045\tMin: -2.1616\t25%: -0.2735\t75%: 0.2772\tMax: 1.8943\n",
      "[+02 hr]\tMean: 0.0106\tMin: -3.9693\t25%: -0.4993\t75%: 0.5153\tMax: 3.6817\n",
      "[+06 hr]\tMean: 0.0355\tMin: -9.4010\t25%: -1.2960\t75%: 1.3580\tMax: 9.8098\n",
      "[+12 hr]\tMean: 0.1487\tMin: -15.8664\t25%: -1.8955\t75%: 2.2223\tMax: 15.1133\n",
      "[+24 hr]\tMean: 0.2656\tMin: -28.7185\t25%: -2.9308\t75%: 3.4999\tMax: 22.6573\n",
      "\n",
      "AFTER 45 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0039\tMin: -2.2741\t25%: -0.2893\t75%: 0.2730\tMax: 1.8287\n",
      "[+02 hr]\tMean: 0.0209\tMin: -4.2270\t25%: -0.5157\t75%: 0.5404\tMax: 3.7099\n",
      "[+06 hr]\tMean: 0.0542\tMin: -10.4175\t25%: -1.3315\t75%: 1.4047\tMax: 10.7319\n",
      "[+12 hr]\tMean: 0.2196\tMin: -15.2335\t25%: -1.8931\t75%: 2.3411\tMax: 17.5209\n",
      "[+24 hr]\tMean: 0.4256\tMin: -26.8946\t25%: -2.8170\t75%: 3.7044\tMax: 25.2858\n",
      "\n",
      "AFTER 50 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0132\tMin: -2.1063\t25%: -0.2763\t75%: 0.2962\tMax: 2.0144\n",
      "[+02 hr]\tMean: 0.0310\tMin: -3.8980\t25%: -0.5230\t75%: 0.5756\tMax: 4.0836\n",
      "[+06 hr]\tMean: 0.0681\tMin: -9.5167\t25%: -1.3445\t75%: 1.4453\tMax: 10.2573\n",
      "[+12 hr]\tMean: 0.2078\tMin: -16.8883\t25%: -1.9181\t75%: 2.3142\tMax: 14.8201\n",
      "[+24 hr]\tMean: 0.4097\tMin: -30.5803\t25%: -2.8945\t75%: 3.6582\tMax: 22.4859\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# 1/2: CHANGE if more epochs added\n",
    "###############################################################\n",
    "\n",
    "# To iterate through training epochs\n",
    "epochs = ['05 epochs', '10 epochs', '15 epochs', '20 epochs', \\\n",
    "          '25 epochs', '30 epochs', '35 epochs', '40 epochs', \\\n",
    "          '45 epochs', '50 epochs']\n",
    "\n",
    "# Object 1: To zip all dfs together later\n",
    "all_dfs = (reddit_test_df.values, \\\n",
    "           predictions_5, \\\n",
    "           predictions_10, \\\n",
    "           predictions_15, \\\n",
    "           predictions_20, \\\n",
    "           predictions_25, \\\n",
    "           predictions_30, \\\n",
    "           predictions_35, \\\n",
    "           predictions_40, \\\n",
    "           predictions_45, \\\n",
    "           predictions_50)\n",
    "\n",
    "# Object 2: To print below\n",
    "all_predictions = [('AFTER 5 EPOCHS TRAINING', predictions_5),\n",
    "                   ('AFTER 10 EPOCHS TRAINING', predictions_10),\n",
    "                   ('AFTER 15 EPOCHS TRAINING', predictions_15),\n",
    "                   ('AFTER 20 EPOCHS TRAINING', predictions_20),\n",
    "                   ('AFTER 25 EPOCHS TRAINING', predictions_25),\n",
    "                   ('AFTER 30 EPOCHS TRAINING', predictions_30), \n",
    "                   ('AFTER 35 EPOCHS TRAINING', predictions_35), \n",
    "                   ('AFTER 40 EPOCHS TRAINING', predictions_40), \n",
    "                   ('AFTER 45 EPOCHS TRAINING', predictions_45), \n",
    "                   ('AFTER 50 EPOCHS TRAINING', predictions_50)]\n",
    "\n",
    "###############################################################\n",
    "# 2/2: DON'T CHANGE if more epochs added\n",
    "###############################################################\n",
    "\n",
    "# Loop through each set and print summary\\n\",\n",
    "for description, prediction in all_predictions:\n",
    "    pred_1hr, summary_1hr = prediction[:,0], pd.Series(np.squeeze(prediction[:,0])).describe()\n",
    "    pred_2hr, summary_2hr = prediction[:,1], pd.Series(np.squeeze(prediction[:,1])).describe()\n",
    "    pred_6hr, summary_6hr = prediction[:,2], pd.Series(np.squeeze(prediction[:,2])).describe()\n",
    "    pred_12hr, summary_12hr = prediction[:,3], pd.Series(np.squeeze(prediction[:,3])).describe()\n",
    "    pred_24hr, summary_24hr = prediction[:,4], pd.Series(np.squeeze(prediction[:,4])).describe()\n",
    "\n",
    "    print('\\n%s' % description)\n",
    "    print('[+01 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_1hr['mean'], summary_1hr['min'], summary_1hr['25%'], summary_1hr['75%'], summary_1hr['max']))\n",
    "    print('[+02 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_2hr['mean'], summary_2hr['min'], summary_2hr['25%'], summary_2hr['75%'], summary_2hr['max']))\n",
    "    print('[+06 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_6hr['mean'], summary_6hr['min'], summary_6hr['25%'], summary_6hr['75%'], summary_6hr['max']))\n",
    "    print('[+12 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_12hr['mean'], summary_12hr['min'], summary_12hr['25%'], summary_12hr['75%'], summary_12hr['max']))\n",
    "    print('[+24 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_24hr['mean'], summary_24hr['min'], summary_24hr['25%'], summary_24hr['75%'], summary_24hr['max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, check prediction performance:\n",
    "- How many of the largest (positive) ACTUAL price changes did we PREDICT correctly\n",
    "- How many of the largest (negative) ACTUAL price changes did we PREDICT correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1hr] Top cutoff: 0.9864, Bottom cutoff: -0.7630\n",
      "[2hr] Top cutoff: 1.3951, Bottom cutoff: -1.1409\n",
      "[6hr] Top cutoff: 2.5950, Bottom cutoff: -1.6548\n",
      "[12hr] Top cutoff: 3.8299, Bottom cutoff: -2.4704\n",
      "[24hr] Top cutoff: 6.0746, Bottom cutoff: -2.8883\n"
     ]
    }
   ],
   "source": [
    "# Prediction times\n",
    "prediction_times = ['1hr', '2hr', '6hr', '12hr', '24hr']\n",
    "\n",
    "# Indices of columns in test df and prediction dfs\n",
    "actual_columns = {'date' : 0, 'title' : 4, '1hr' : 5, '2hr' : 6, '6hr' : 7, '12hr' : 8, '24hr' : 9}\n",
    "pred_columns = {'1hr' : 0, '2hr' : 1, '6hr' : 2, '12hr' : 3, '24hr' : 4}\n",
    "\n",
    "# Set cutoffs to only consider largest (positive) price changes\n",
    "pos_percent = 0.80 # Means will consider top 20%\n",
    "pos_1hr = pd.Series(np.squeeze(reddit_test_df['1hr_change'])).quantile(pos_percent)\n",
    "pos_2hr = pd.Series(np.squeeze(reddit_test_df['2hr_change'])).quantile(pos_percent)\n",
    "pos_6hr = pd.Series(np.squeeze(reddit_test_df['6hr_change'])).quantile(pos_percent)\n",
    "pos_12hr = pd.Series(np.squeeze(reddit_test_df['12hr_change'])).quantile(pos_percent)\n",
    "pos_24hr = pd.Series(np.squeeze(reddit_test_df['24hr_change'])).quantile(pos_percent)\n",
    "pos_cutoffs = {'1hr' : pos_1hr, '2hr' : pos_2hr, '6hr' : pos_6hr, '12hr' : pos_12hr, '24hr' : pos_24hr} \n",
    "\n",
    "# Set cutoffs to only consider largest (negative) price changes\n",
    "neg_percent = 0.20 # Means will consider bottom 20%\n",
    "neg_1hr = pd.Series(np.squeeze(reddit_test_df['1hr_change'])).quantile(neg_percent)\n",
    "neg_2hr = pd.Series(np.squeeze(reddit_test_df['2hr_change'])).quantile(neg_percent)\n",
    "neg_6hr = pd.Series(np.squeeze(reddit_test_df['6hr_change'])).quantile(neg_percent)\n",
    "neg_12hr = pd.Series(np.squeeze(reddit_test_df['12hr_change'])).quantile(neg_percent)\n",
    "neg_24hr = pd.Series(np.squeeze(reddit_test_df['24hr_change'])).quantile(neg_percent)\n",
    "neg_cutoffs = {'1hr' : neg_1hr, '2hr' : neg_2hr, '6hr' : neg_6hr, '12hr' : neg_12hr, '24hr' : neg_24hr} \n",
    "\n",
    "# Print\n",
    "for time in prediction_times:\n",
    "    print ('[%s] Top cutoff: %.4f, Bottom cutoff: %.4f' % (time, pos_cutoffs[time], neg_cutoffs[time]))\n",
    "\n",
    "# Initial state of prediction counts\n",
    "initial_pred_counts = {}\n",
    "for epoch in epochs:\n",
    "    initial_pred_counts[epoch] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** PREDICTIONS +1hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 0.99%): 1881\n",
      "[05 epochs train] Above cutoff: 0 (0.00%), Positive: 1069 (56.83%)\n",
      "[10 epochs train] Above cutoff: 8 (0.43%), Positive: 1015 (53.96%)\n",
      "[15 epochs train] Above cutoff: 15 (0.80%), Positive: 974 (51.78%)\n",
      "[20 epochs train] Above cutoff: 11 (0.58%), Positive: 879 (46.73%)\n",
      "[25 epochs train] Above cutoff: 20 (1.06%), Positive: 911 (48.43%)\n",
      "[30 epochs train] Above cutoff: 16 (0.85%), Positive: 899 (47.79%)\n",
      "[35 epochs train] Above cutoff: 29 (1.54%), Positive: 940 (49.97%)\n",
      "[40 epochs train] Above cutoff: 28 (1.49%), Positive: 925 (49.18%)\n",
      "[45 epochs train] Above cutoff: 35 (1.86%), Positive: 895 (47.58%)\n",
      "[50 epochs train] Above cutoff: 36 (1.91%), Positive: 930 (49.44%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -0.76%): 1881\n",
      "[05 epochs train] Below cutoff: 0 (0.00%), Negative: 776 (41.25%)\n",
      "[10 epochs train] Below cutoff: 11 (0.58%), Negative: 889 (47.26%)\n",
      "[15 epochs train] Below cutoff: 15 (0.80%), Negative: 908 (48.27%)\n",
      "[20 epochs train] Below cutoff: 46 (2.45%), Negative: 972 (51.67%)\n",
      "[25 epochs train] Below cutoff: 52 (2.76%), Negative: 944 (50.19%)\n",
      "[30 epochs train] Below cutoff: 54 (2.87%), Negative: 959 (50.98%)\n",
      "[35 epochs train] Below cutoff: 60 (3.19%), Negative: 919 (48.86%)\n",
      "[40 epochs train] Below cutoff: 75 (3.99%), Negative: 932 (49.55%)\n",
      "[45 epochs train] Below cutoff: 79 (4.20%), Negative: 962 (51.14%)\n",
      "[50 epochs train] Below cutoff: 67 (3.56%), Negative: 943 (50.13%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 11 days (39.29%)\n",
      "[10 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[15 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[20 epochs train] Correct aggregated predictions: 10 days (35.71%)\n",
      "[25 epochs train] Correct aggregated predictions: 14 days (50.00%)\n",
      "[30 epochs train] Correct aggregated predictions: 12 days (42.86%)\n",
      "[35 epochs train] Correct aggregated predictions: 14 days (50.00%)\n",
      "[40 epochs train] Correct aggregated predictions: 8 days (28.57%)\n",
      "[45 epochs train] Correct aggregated predictions: 11 days (39.29%)\n",
      "[50 epochs train] Correct aggregated predictions: 10 days (35.71%)\n",
      "\n",
      "***** PREDICTIONS +2hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 1.40%): 1871\n",
      "[05 epochs train] Above cutoff: 0 (0.00%), Positive: 1000 (53.45%)\n",
      "[10 epochs train] Above cutoff: 34 (1.82%), Positive: 998 (53.34%)\n",
      "[15 epochs train] Above cutoff: 52 (2.78%), Positive: 996 (53.23%)\n",
      "[20 epochs train] Above cutoff: 64 (3.42%), Positive: 908 (48.53%)\n",
      "[25 epochs train] Above cutoff: 78 (4.17%), Positive: 919 (49.12%)\n",
      "[30 epochs train] Above cutoff: 87 (4.65%), Positive: 931 (49.76%)\n",
      "[35 epochs train] Above cutoff: 89 (4.76%), Positive: 961 (51.36%)\n",
      "[40 epochs train] Above cutoff: 74 (3.96%), Positive: 921 (49.23%)\n",
      "[45 epochs train] Above cutoff: 100 (5.34%), Positive: 937 (50.08%)\n",
      "[50 epochs train] Above cutoff: 107 (5.72%), Positive: 939 (50.19%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -1.14%): 1875\n",
      "[05 epochs train] Below cutoff: 3 (0.16%), Negative: 827 (44.11%)\n",
      "[10 epochs train] Below cutoff: 37 (1.97%), Negative: 838 (44.69%)\n",
      "[15 epochs train] Below cutoff: 62 (3.31%), Negative: 848 (45.23%)\n",
      "[20 epochs train] Below cutoff: 114 (6.08%), Negative: 890 (47.47%)\n",
      "[25 epochs train] Below cutoff: 121 (6.45%), Negative: 903 (48.16%)\n",
      "[30 epochs train] Below cutoff: 135 (7.20%), Negative: 901 (48.05%)\n",
      "[35 epochs train] Below cutoff: 130 (6.93%), Negative: 889 (47.41%)\n",
      "[40 epochs train] Below cutoff: 141 (7.52%), Negative: 937 (49.97%)\n",
      "[45 epochs train] Below cutoff: 144 (7.68%), Negative: 920 (49.07%)\n",
      "[50 epochs train] Below cutoff: 154 (8.21%), Negative: 920 (49.07%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[10 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[15 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[20 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[25 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[30 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[35 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[40 epochs train] Correct aggregated predictions: 13 days (46.43%)\n",
      "[45 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[50 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "\n",
      "***** PREDICTIONS +6hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 2.60%): 1875\n",
      "[05 epochs train] Above cutoff: 1 (0.05%), Positive: 1138 (60.69%)\n",
      "[10 epochs train] Above cutoff: 107 (5.71%), Positive: 1075 (57.33%)\n",
      "[15 epochs train] Above cutoff: 157 (8.37%), Positive: 1011 (53.92%)\n",
      "[20 epochs train] Above cutoff: 188 (10.03%), Positive: 984 (52.48%)\n",
      "[25 epochs train] Above cutoff: 194 (10.35%), Positive: 947 (50.51%)\n",
      "[30 epochs train] Above cutoff: 218 (11.63%), Positive: 946 (50.45%)\n",
      "[35 epochs train] Above cutoff: 224 (11.95%), Positive: 954 (50.88%)\n",
      "[40 epochs train] Above cutoff: 211 (11.25%), Positive: 938 (50.03%)\n",
      "[45 epochs train] Above cutoff: 229 (12.21%), Positive: 941 (50.19%)\n",
      "[50 epochs train] Above cutoff: 229 (12.21%), Positive: 952 (50.77%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -1.65%): 1881\n",
      "[05 epochs train] Below cutoff: 23 (1.22%), Negative: 768 (40.83%)\n",
      "[10 epochs train] Below cutoff: 136 (7.23%), Negative: 843 (44.82%)\n",
      "[15 epochs train] Below cutoff: 255 (13.56%), Negative: 901 (47.90%)\n",
      "[20 epochs train] Below cutoff: 308 (16.37%), Negative: 927 (49.28%)\n",
      "[25 epochs train] Below cutoff: 345 (18.34%), Negative: 952 (50.61%)\n",
      "[30 epochs train] Below cutoff: 352 (18.71%), Negative: 939 (49.92%)\n",
      "[35 epochs train] Below cutoff: 340 (18.08%), Negative: 932 (49.55%)\n",
      "[40 epochs train] Below cutoff: 377 (20.04%), Negative: 950 (50.51%)\n",
      "[45 epochs train] Below cutoff: 386 (20.52%), Negative: 941 (50.03%)\n",
      "[50 epochs train] Below cutoff: 403 (21.42%), Negative: 936 (49.76%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[10 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[15 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[20 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[25 epochs train] Correct aggregated predictions: 13 days (46.43%)\n",
      "[30 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[35 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[40 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[45 epochs train] Correct aggregated predictions: 13 days (46.43%)\n",
      "[50 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "\n",
      "***** PREDICTIONS +12hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 3.83%): 1883\n",
      "[05 epochs train] Above cutoff: 3 (0.16%), Positive: 1170 (62.13%)\n",
      "[10 epochs train] Above cutoff: 113 (6.00%), Positive: 1070 (56.82%)\n",
      "[15 epochs train] Above cutoff: 163 (8.66%), Positive: 977 (51.89%)\n",
      "[20 epochs train] Above cutoff: 197 (10.46%), Positive: 959 (50.93%)\n",
      "[25 epochs train] Above cutoff: 223 (11.84%), Positive: 950 (50.45%)\n",
      "[30 epochs train] Above cutoff: 258 (13.70%), Positive: 974 (51.73%)\n",
      "[35 epochs train] Above cutoff: 249 (13.22%), Positive: 962 (51.09%)\n",
      "[40 epochs train] Above cutoff: 243 (12.90%), Positive: 946 (50.24%)\n",
      "[45 epochs train] Above cutoff: 252 (13.38%), Positive: 946 (50.24%)\n",
      "[50 epochs train] Above cutoff: 244 (12.96%), Positive: 972 (51.62%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -2.47%): 1876\n",
      "[05 epochs train] Below cutoff: 12 (0.64%), Negative: 709 (37.79%)\n",
      "[10 epochs train] Below cutoff: 124 (6.61%), Negative: 777 (41.42%)\n",
      "[15 epochs train] Below cutoff: 256 (13.65%), Negative: 869 (46.32%)\n",
      "[20 epochs train] Below cutoff: 317 (16.90%), Negative: 895 (47.71%)\n",
      "[25 epochs train] Below cutoff: 324 (17.27%), Negative: 897 (47.81%)\n",
      "[30 epochs train] Below cutoff: 360 (19.19%), Negative: 858 (45.74%)\n",
      "[35 epochs train] Below cutoff: 363 (19.35%), Negative: 883 (47.07%)\n",
      "[40 epochs train] Below cutoff: 356 (18.98%), Negative: 916 (48.83%)\n",
      "[45 epochs train] Below cutoff: 380 (20.26%), Negative: 889 (47.39%)\n",
      "[50 epochs train] Below cutoff: 379 (20.20%), Negative: 883 (47.07%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[10 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[15 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[20 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[25 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[30 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[35 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[40 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[45 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[50 epochs train] Correct aggregated predictions: 14 days (50.00%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** PREDICTIONS +24hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 6.07%): 1877\n",
      "[05 epochs train] Above cutoff: 2 (0.11%), Positive: 1267 (67.50%)\n",
      "[10 epochs train] Above cutoff: 104 (5.54%), Positive: 1095 (58.34%)\n",
      "[15 epochs train] Above cutoff: 150 (7.99%), Positive: 976 (52.00%)\n",
      "[20 epochs train] Above cutoff: 199 (10.60%), Positive: 976 (52.00%)\n",
      "[25 epochs train] Above cutoff: 218 (11.61%), Positive: 948 (50.51%)\n",
      "[30 epochs train] Above cutoff: 253 (13.48%), Positive: 976 (52.00%)\n",
      "[35 epochs train] Above cutoff: 253 (13.48%), Positive: 962 (51.25%)\n",
      "[40 epochs train] Above cutoff: 240 (12.79%), Positive: 948 (50.51%)\n",
      "[45 epochs train] Above cutoff: 269 (14.33%), Positive: 962 (51.25%)\n",
      "[50 epochs train] Above cutoff: 241 (12.84%), Positive: 990 (52.74%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -2.89%): 1875\n",
      "[05 epochs train] Below cutoff: 20 (1.07%), Negative: 649 (34.61%)\n",
      "[10 epochs train] Below cutoff: 187 (9.97%), Negative: 751 (40.05%)\n",
      "[15 epochs train] Below cutoff: 350 (18.67%), Negative: 856 (45.65%)\n",
      "[20 epochs train] Below cutoff: 409 (21.81%), Negative: 864 (46.08%)\n",
      "[25 epochs train] Below cutoff: 444 (23.68%), Negative: 870 (46.40%)\n",
      "[30 epochs train] Below cutoff: 455 (24.27%), Negative: 855 (45.60%)\n",
      "[35 epochs train] Below cutoff: 451 (24.05%), Negative: 874 (46.61%)\n",
      "[40 epochs train] Below cutoff: 470 (25.07%), Negative: 922 (49.17%)\n",
      "[45 epochs train] Below cutoff: 456 (24.32%), Negative: 852 (45.44%)\n",
      "[50 epochs train] Below cutoff: 474 (25.28%), Negative: 845 (45.07%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[10 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[15 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[20 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[25 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[30 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[35 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[40 epochs train] Correct aggregated predictions: 12 days (42.86%)\n",
      "[45 epochs train] Correct aggregated predictions: 14 days (50.00%)\n",
      "[50 epochs train] Correct aggregated predictions: 13 days (46.43%)\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# Loop through each prediction time\n",
    "###############################################################\n",
    "for time in prediction_times:\n",
    "       \n",
    "    # To keep track of (largest positive) counts\n",
    "    num_actual_above = 0\n",
    "    num_pred_above, num_pred_positive = initial_pred_counts.copy(), initial_pred_counts.copy()\n",
    "    per_pred_above, per_pred_positive = initial_pred_counts.copy(), initial_pred_counts.copy() \n",
    "    \n",
    "    # To keep track of (largest negative) counts\n",
    "    num_actual_below = 0\n",
    "    num_pred_below, num_pred_negative = initial_pred_counts.copy(), initial_pred_counts.copy()\n",
    "    per_pred_below, per_pred_negative = initial_pred_counts.copy(), initial_pred_counts.copy() \n",
    "    \n",
    "    # To keep track of cummulative daily predictions\n",
    "    total_days = 1\n",
    "    preds_tally, correct_days, per_correct_days = \\\n",
    "        initial_pred_counts.copy(), initial_pred_counts.copy(), initial_pred_counts.copy()\n",
    "    current_date = reddit_test_df.values[0][actual_columns['date']].split(' ')[0]\n",
    "    \n",
    "    #########################################\n",
    "    # Loop through each row in actual test df and prediction dfs\n",
    "    #########################################\n",
    "    for all_items in zip(*all_dfs):\n",
    "    \n",
    "        # Separate \n",
    "        i, preds = 0, {}\n",
    "        actual = all_items[i]\n",
    "        for epoch in epochs:\n",
    "            i += 1\n",
    "            preds[epoch] = all_items[i]\n",
    "        \n",
    "        # Check if actual value >= top cutoff\n",
    "        if actual[actual_columns[time]] >= pos_cutoffs[time]:\n",
    "            # Increment actual count\n",
    "            num_actual_above += 1\n",
    "            # Loop through each set of predictions\n",
    "            for epoch in epochs:\n",
    "                # If prediction >= cutoff   \n",
    "                if preds[epoch][pred_columns[time]] >= pos_cutoffs[time]: num_pred_above[epoch] += 1\n",
    "                # If prediction positive   \n",
    "                if preds[epoch][pred_columns[time]] >= 0: num_pred_positive[epoch] += 1\n",
    "    \n",
    "        # Check if actual value <= bottom cutoff\n",
    "        if actual[actual_columns[time]] <= neg_cutoffs[time]:\n",
    "            # Increment actual count\n",
    "            num_actual_below += 1\n",
    "            # Loop through each set of predictions\n",
    "            for epoch in epochs:\n",
    "                # If prediction >= cutoff   \n",
    "                if preds[epoch][pred_columns[time]] <= neg_cutoffs[time]: num_pred_below[epoch] += 1\n",
    "                # If prediction negative   \n",
    "                if preds[epoch][pred_columns[time]] <= 0: num_pred_negative[epoch] += 1\n",
    "    \n",
    "        # Isolate date of current row\n",
    "        new_date = actual[actual_columns['date']].split(' ')[0]\n",
    "     \n",
    "        # If moved to new date\n",
    "        if not new_date == current_date:\n",
    "            # Check prediction tallys vs actual price changes\n",
    "            for epoch in epochs:\n",
    "                if np.sign(preds_tally[epoch]) == np.sign(actual[actual_columns[time]]):\n",
    "                    correct_days[epoch] += 1\n",
    "            # Update total day count, reset tally, change current_day\n",
    "            total_days += 1\n",
    "            preds_tally = initial_pred_counts.copy()\n",
    "            current_date = new_date\n",
    "    \n",
    "        # Update prediction tallys\n",
    "        for epoch in epochs:\n",
    "            preds_tally[epoch] += preds[epoch][pred_columns[time]]\n",
    "    \n",
    "    #########################################          \n",
    "    # Calculate percentage of correct predictions\n",
    "    #########################################          \n",
    "    for epoch in epochs:\n",
    "        per_pred_above[epoch] = (num_pred_above[epoch] / num_actual_above) * 100\n",
    "        per_pred_positive[epoch] = (num_pred_positive[epoch] / num_actual_above) * 100   \n",
    "        per_pred_below[epoch] = (num_pred_below[epoch] / num_actual_below) * 100\n",
    "        per_pred_negative[epoch] = (num_pred_negative[epoch] / num_actual_below) * 100   \n",
    "        per_correct_days[epoch] = (correct_days[epoch] / total_days) * 100\n",
    "        \n",
    "    #########################################          \n",
    "    # Print results\n",
    "    #########################################   \n",
    "    print ('\\n***** PREDICTIONS +%s IN FUTURE *****' % time)\n",
    "    \n",
    "    print ('\\nNum ACTUAL in top %d%% (change >= %.2f%%): %d' % \\\n",
    "        (100-int(pos_percent*100), pos_cutoffs[time], num_actual_above))           \n",
    "    for epoch in epochs:\n",
    "        print ('[%s train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "            (epoch, num_pred_above[epoch], per_pred_above[epoch], num_pred_positive[epoch], per_pred_positive[epoch]))\n",
    "        \n",
    "    print ('\\nNum ACTUAL in bottom %d%% (change <= %.2f%%): %d' % \\\n",
    "        (int(neg_percent*100), neg_cutoffs[time], num_actual_below))           \n",
    "    for epoch in epochs:\n",
    "        print ('[%s train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "            (epoch, num_pred_below[epoch], per_pred_below[epoch], num_pred_negative[epoch], per_pred_negative[epoch]))\n",
    "    \n",
    "    print ('\\nTotal days in test set: %d' % (total_days))           \n",
    "    for epoch in epochs:\n",
    "        print ('[%s train] Correct aggregated predictions: %d days (%.2f%%)' % \\\n",
    "            (epoch, correct_days[epoch], per_correct_days[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
