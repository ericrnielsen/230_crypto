{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Input, LSTM, Dropout\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (18,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distribution(df, labels_column_name):\n",
    "    n = df.shape[0]\n",
    "    print(\"{} labels frequency:\".format(labels_column_name))\n",
    "    print(\"Value\\tCount\\tPercent\")\n",
    "    indeces = df[labels_column_name].value_counts().index.tolist()\n",
    "    counts = df[labels_column_name].value_counts().tolist()\n",
    "    for val, count in zip(indeces, counts):\n",
    "        print(\"{}\\t{}\\t{}%\".format(val, count, (count / float(n)) * 100))\n",
    "    \n",
    "def get_max_words(text_arr):\n",
    "    max_words = 0\n",
    "    for line in text_arr:\n",
    "        num_words = len(line.split())\n",
    "        if num_words > max_words:\n",
    "            max_words = num_words\n",
    "    return max_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the csv data\n",
    "reddit_train_df = pd.read_csv(\"../../data/reddit/labeled/score10_all_sub_labeled_train.csv\", index_col=0)\n",
    "reddit_test_df = pd.read_csv(\"../../data/reddit/labeled/score10_all_sub_labeled_dev.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of words per post: 78\n",
      "\n",
      "Getting x_train, y_train, x_test, and y_test...\n",
      "102991 train sequences\n",
      "9353 test sequences\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11fe1bcc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ef970b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine max post length\n",
    "max_words_train = get_max_words(reddit_train_df.title.values)\n",
    "max_words_test = get_max_words(reddit_test_df.title.values)\n",
    "max_words = max(max_words_train, max_words_test)\n",
    "print(\"Max number of words per post: {}\".format(max_words))\n",
    "\n",
    "# Label and title columns in datasets\n",
    "LABEL_1HR, LABEL_2HR, LABEL_6HR, LABEL_12HR, LABEL_24HR = \\\n",
    "    '1hr_change', '2hr_change', '6hr_change', '12hr_change', '24hr_change'\n",
    "TEXT_COL = 'title'\n",
    "\n",
    "# Split into x_train and y_train\n",
    "print('\\nGetting x_train, y_train, x_test, and y_test...')\n",
    "(x_train, y_train_1hr, y_train_2hr, y_train_6hr, y_train_12hr, y_train_24hr) = \\\n",
    "    reddit_train_df[TEXT_COL].values, reddit_train_df[LABEL_1HR], reddit_train_df[LABEL_2HR], \\\n",
    "    reddit_train_df[LABEL_6HR], reddit_train_df[LABEL_12HR], reddit_train_df[LABEL_24HR]\n",
    "\n",
    "m_train = x_train.shape[0]\n",
    "y_train_1hr = y_train_1hr.values.reshape((m_train, 1))\n",
    "y_train_2hr = y_train_2hr.values.reshape((m_train, 1))\n",
    "y_train_6hr = y_train_6hr.values.reshape((m_train, 1))\n",
    "y_train_12hr = y_train_12hr.values.reshape((m_train, 1))\n",
    "y_train_24hr = y_train_24hr.values.reshape((m_train, 1))\n",
    "    \n",
    "(x_test, y_test_1hr, y_test_2hr, y_test_6hr, y_test_12hr, y_test_24hr) = \\\n",
    "    reddit_test_df[TEXT_COL].values, reddit_test_df[LABEL_1HR], reddit_test_df[LABEL_2HR], \\\n",
    "    reddit_test_df[LABEL_6HR], reddit_test_df[LABEL_12HR], reddit_test_df[LABEL_24HR]\n",
    "\n",
    "m_test = x_test.shape[0]\n",
    "y_test_1hr = y_test_1hr.values.reshape((m_test, 1))\n",
    "y_test_2hr = y_test_2hr.values.reshape((m_test, 1))\n",
    "y_test_6hr = y_test_6hr.values.reshape((m_test, 1))\n",
    "y_test_12hr = y_test_12hr.values.reshape((m_test, 1))\n",
    "y_test_24hr = y_test_24hr.values.reshape((m_test, 1)) \n",
    "\n",
    "# Print info about train and test\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# Plot distributions of labels\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.distplot(reddit_train_df[LABEL_1HR].values, label='Train')\n",
    "sns.distplot(reddit_test_df[LABEL_1HR].values, label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (102991, 78)\n",
      "x_test shape: (9353, 78)\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "max_features = 200000 # Num words in our vocabulary \n",
    "maxlen = max_words  # cut texts after this number of words\n",
    "batch_size = 32  # Mini-batch size\n",
    "num_epochs = 5 \n",
    "\n",
    "# Train tokenizer to create a vocabulary of words\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Vectorize each headline\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Update x_train and x_test to be 'sequences' of data\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(test_sequences, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding layer using word2vec\n",
    "EMBEDDING_FILE = \"../word2vec/crypto-word2vec-all-200.bin\"\n",
    "EMBEDDING_DIM = 200\n",
    "#word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "word2vec = KeyedVectors.load(EMBEDDING_FILE)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "        \n",
    "embedding_layer = Embedding(nb_words,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=maxlen,\n",
    "        trainable=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup (part 3/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual embeddings\n",
    "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "embeddings = embedding_layer(sequence_input)\n",
    "\n",
    "# Construct the model (attempt 1 - didn't work)\n",
    "#X = LSTM(128, return_sequences=True)(embeddings)\n",
    "#X = Dropout(0.5)(X)\n",
    "#X = LSTM(128, return_sequences=False)(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "#X = Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "# Construct the model (attempt 1 - didn't work)\n",
    "X = Bidirectional(LSTM(128, return_sequences=False))(embeddings)\n",
    "X = Dense(5)(X)\n",
    "\n",
    "# Select y labels\n",
    "y_train = np.concatenate((y_train_1hr, y_train_2hr, y_train_6hr, y_train_12hr, y_train_24hr), axis=1)\n",
    "y_test = np.concatenate((y_test_1hr, y_test_2hr, y_test_6hr, y_test_12hr, y_test_24hr), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 78)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 78, 200)           7844000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               336896    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 8,182,181\n",
      "Trainable params: 338,181\n",
      "Non-trainable params: 7,844,000\n",
      "_________________________________________________________________\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 257s 2ms/step - loss: 15.8900 - acc: 0.3794 - val_loss: 11.0206 - val_acc: 0.4220\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 259s 3ms/step - loss: 15.8432 - acc: 0.3756 - val_loss: 10.8813 - val_acc: 0.4414\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 261s 3ms/step - loss: 15.7845 - acc: 0.3732 - val_loss: 10.8788 - val_acc: 0.4169\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 260s 3ms/step - loss: 15.7014 - acc: 0.3645 - val_loss: 11.0650 - val_acc: 0.3679\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 261s 3ms/step - loss: 15.5727 - acc: 0.3571 - val_loss: 11.4345 - val_acc: 0.3294\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_btc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-85fefd6cfa60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m           callbacks=[checkpoint_5])\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m score, acc = model_btc.evaluate(x_test, \n\u001b[0m\u001b[1;32m     22\u001b[0m                                 \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                 batch_size=batch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_btc' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the BTC model\n",
    "model = Model(inputs=sequence_input, outputs=X)\n",
    "\n",
    "# Compile the BTC model\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error', \n",
    "                    optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Setup model checkpoint\n",
    "checkpoint_5 = ModelCheckpoint(\"checkpoints/reddit-5epochs.hdf5\")\n",
    "\n",
    "# Run the BTC model\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_5])\n",
    "\n",
    "score, acc = model.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC model for 15 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 268s 3ms/step - loss: 15.4186 - acc: 0.3534 - val_loss: 11.2292 - val_acc: 0.3519\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 264s 3ms/step - loss: 15.1489 - acc: 0.3548 - val_loss: 11.4952 - val_acc: 0.3394\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 265s 3ms/step - loss: 14.8295 - acc: 0.3560 - val_loss: 12.0250 - val_acc: 0.3197\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 266s 3ms/step - loss: 14.4353 - acc: 0.3589 - val_loss: 12.0483 - val_acc: 0.3245\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 265s 3ms/step - loss: 14.0391 - acc: 0.3648 - val_loss: 12.2820 - val_acc: 0.3255\n",
      "9353/9353 [==============================] - 7s 739us/step\n",
      "Test score: 12.282048495659838\n",
      "Test accuracy: 0.3254570725986209\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 266s 3ms/step - loss: 13.6243 - acc: 0.3672 - val_loss: 12.8342 - val_acc: 0.3095\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 267s 3ms/step - loss: 13.2109 - acc: 0.3714 - val_loss: 13.2960 - val_acc: 0.2990\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 267s 3ms/step - loss: 12.8193 - acc: 0.3753 - val_loss: 13.6875 - val_acc: 0.3040\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 273s 3ms/step - loss: 12.4797 - acc: 0.3797 - val_loss: 14.0097 - val_acc: 0.3020\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 254s 2ms/step - loss: 12.1635 - acc: 0.3828 - val_loss: 14.0947 - val_acc: 0.3097\n",
      "9353/9353 [==============================] - 6s 685us/step\n",
      "Test score: 14.094672278415757\n",
      "Test accuracy: 0.3097401903164549\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 274s 3ms/step - loss: 11.8592 - acc: 0.3868 - val_loss: 14.7165 - val_acc: 0.2969\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 270s 3ms/step - loss: 11.6064 - acc: 0.3896 - val_loss: 14.7297 - val_acc: 0.2995\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 270s 3ms/step - loss: 11.3465 - acc: 0.3934 - val_loss: 14.4720 - val_acc: 0.3056\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 271s 3ms/step - loss: 11.1292 - acc: 0.3962 - val_loss: 15.0807 - val_acc: 0.3077\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 271s 3ms/step - loss: 10.8968 - acc: 0.3985 - val_loss: 15.1658 - val_acc: 0.3041\n",
      "9353/9353 [==============================] - 7s 763us/step\n",
      "Test score: 15.165809577867256\n",
      "Test accuracy: 0.30407355928897706\n"
     ]
    }
   ],
   "source": [
    "# Setup model checkpoints\n",
    "checkpoint_10 = ModelCheckpoint(\"checkpoints/reddit-10epochs.hdf5\")\n",
    "checkpoint_15 = ModelCheckpoint(\"checkpoints/reddit-15epochs.hdf5\")\n",
    "checkpoint_20 = ModelCheckpoint(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "\n",
    "# Run the BTC model 5 more epochs\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_10])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the BTC model 5 more epochs\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_15])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the BTC model 5 more epochs\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_20])\n",
    "\n",
    "score, acc = model.evaluate(x_test,\n",
    "                            y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9353/9353 [==============================] - 6s 680us/step\n",
      "Test score: 11.434544080341613\n",
      "Test accuracy: 0.3294130225691657\n",
      "9353/9353 [==============================] - 6s 683us/step\n",
      "Test score: 12.282048495659838\n",
      "Test accuracy: 0.3254570725986209\n",
      "9353/9353 [==============================] - 6s 675us/step\n",
      "Test score: 14.094672278415757\n",
      "Test accuracy: 0.3097401903164549\n",
      "9353/9353 [==============================] - 6s 674us/step\n",
      "Test score: 15.165809577867256\n",
      "Test accuracy: 0.30407355928897706\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# After 5 epochs\n",
    "###################################################################\n",
    "model_5 = Model(inputs=sequence_input, outputs=X)\n",
    "model_5.load_weights(\"checkpoints/reddit-5epochs.hdf5\")\n",
    "model_5.compile(loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "score_5, acc_5 = model_5.evaluate(x_test,\n",
    "                                  y_test,\n",
    "                                  batch_size=batch_size)\n",
    "predictions_5 = model_5.predict(x_test)\n",
    "print('Test score:', score_5)\n",
    "print('Test accuracy:', acc_5)\n",
    "                     \n",
    "###################################################################\n",
    "# After 10 epochs\n",
    "###################################################################\n",
    "model_10 = Model(inputs=sequence_input, outputs=X)\n",
    "model_10.load_weights(\"checkpoints/reddit-10epochs.hdf5\")\n",
    "model_10.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_10, acc_10 = model_10.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_10 = model_10.predict(x_test)\n",
    "print('Test score:', score_10)\n",
    "print('Test accuracy:', acc_10)\n",
    "\n",
    "###################################################################\n",
    "# After 15 epochs\n",
    "###################################################################\n",
    "model_15 = Model(inputs=sequence_input, outputs=X)\n",
    "model_15.load_weights(\"checkpoints/reddit-15epochs.hdf5\")\n",
    "model_15.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_15, acc_15 = model_15.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_15 = model_15.predict(x_test)\n",
    "print('Test score:', score_15)\n",
    "print('Test accuracy:', acc_15)\n",
    "\n",
    "###################################################################\n",
    "# After 20 epochs\n",
    "###################################################################\n",
    "model_20 = Model(inputs=sequence_input, outputs=X)\n",
    "model_20.load_weights(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "model_20.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_20, acc_20 = model_20.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_20 = model_20.predict(x_test)\n",
    "print('Test score:', score_20)\n",
    "print('Test accuracy:', acc_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC model for 10 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 258s 3ms/step - loss: 10.7843 - acc: 0.3994 - val_loss: 15.5255 - val_acc: 0.3112\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 260s 3ms/step - loss: 10.5545 - acc: 0.4034 - val_loss: 15.4346 - val_acc: 0.2926\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 262s 3ms/step - loss: 10.4172 - acc: 0.4030 - val_loss: 15.8021 - val_acc: 0.3018\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 261s 3ms/step - loss: 10.2889 - acc: 0.4058 - val_loss: 15.8548 - val_acc: 0.3009\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 262s 3ms/step - loss: 10.1375 - acc: 0.4079 - val_loss: 16.0703 - val_acc: 0.2946\n",
      "9353/9353 [==============================] - 7s 740us/step\n",
      "Test score: 16.070277795706996\n",
      "Test accuracy: 0.2945578958654766\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 262s 3ms/step - loss: 10.0432 - acc: 0.4078 - val_loss: 16.2740 - val_acc: 0.2979\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 263s 3ms/step - loss: 9.9644 - acc: 0.4093 - val_loss: 16.2772 - val_acc: 0.3052\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 265s 3ms/step - loss: 9.7673 - acc: 0.4122 - val_loss: 16.3029 - val_acc: 0.2982\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 267s 3ms/step - loss: 9.7096 - acc: 0.4132 - val_loss: 16.7514 - val_acc: 0.2900\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 268s 3ms/step - loss: 9.6108 - acc: 0.4131 - val_loss: 16.3723 - val_acc: 0.2997\n",
      "9353/9353 [==============================] - 7s 754us/step\n",
      "Test score: 16.372327475270957\n",
      "Test accuracy: 0.29968993906654623\n"
     ]
    }
   ],
   "source": [
    "# Setup model checkpoints\n",
    "checkpoint_25 = ModelCheckpoint(\"checkpoints/reddit-25epochs.hdf5\")\n",
    "checkpoint_30 = ModelCheckpoint(\"checkpoints/reddit-30epochs.hdf5\")\n",
    "\n",
    "# Load model trained for 20 epochs\n",
    "#model = Model(inputs=sequence_input, outputs=X)\n",
    "#model.load_weights(\"checkpoints/reddit-20epochs.hdf5\")\n",
    "#model.compile(loss='mean_squared_error',\n",
    "#                  optimizer='adam',\n",
    "#                  metrics=['accuracy'])\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_25])\n",
    "score, acc = model.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_30])\n",
    "score, acc = model.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BTC model for 20 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 258s 3ms/step - loss: 9.5338 - acc: 0.4146 - val_loss: 16.5894 - val_acc: 0.3029\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 260s 3ms/step - loss: 9.4329 - acc: 0.4164 - val_loss: 16.7659 - val_acc: 0.3044\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 260s 3ms/step - loss: 9.4456 - acc: 0.4147 - val_loss: 16.5283 - val_acc: 0.3018\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 260s 3ms/step - loss: 9.3380 - acc: 0.4162 - val_loss: 16.6256 - val_acc: 0.3016\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 260s 3ms/step - loss: 9.2834 - acc: 0.4175 - val_loss: 17.0145 - val_acc: 0.2974\n",
      "9353/9353 [==============================] - 7s 721us/step\n",
      "Test score: 17.014482662612252\n",
      "Test accuracy: 0.2974446701847983\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 261s 3ms/step - loss: 9.2679 - acc: 0.4166 - val_loss: 16.9603 - val_acc: 0.2909\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 264s 3ms/step - loss: 9.1952 - acc: 0.4196 - val_loss: 17.0461 - val_acc: 0.2988\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 263s 3ms/step - loss: 9.0835 - acc: 0.4200 - val_loss: 16.9945 - val_acc: 0.3061\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 263s 3ms/step - loss: 9.0658 - acc: 0.4202 - val_loss: 16.8847 - val_acc: 0.3046\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 266s 3ms/step - loss: 9.0037 - acc: 0.4220 - val_loss: 17.0742 - val_acc: 0.2978\n",
      "9353/9353 [==============================] - 7s 728us/step\n",
      "Test score: 17.074238077785886\n",
      "Test accuracy: 0.2977654228621621\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 265s 3ms/step - loss: 8.9560 - acc: 0.4222 - val_loss: 17.4050 - val_acc: 0.2997\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 267s 3ms/step - loss: 8.9625 - acc: 0.4218 - val_loss: 17.1576 - val_acc: 0.2959\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 266s 3ms/step - loss: 8.9964 - acc: 0.4215 - val_loss: 17.2422 - val_acc: 0.3010\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 273s 3ms/step - loss: 8.8643 - acc: 0.4235 - val_loss: 17.3221 - val_acc: 0.2942\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 273s 3ms/step - loss: 8.9414 - acc: 0.4224 - val_loss: 17.2882 - val_acc: 0.2979\n",
      "9353/9353 [==============================] - 8s 815us/step\n",
      "Test score: 17.288187443553657\n",
      "Test accuracy: 0.29787234045102307\n",
      "Train on 102991 samples, validate on 9353 samples\n",
      "Epoch 1/5\n",
      "102991/102991 [==============================] - 267s 3ms/step - loss: 8.9087 - acc: 0.4223 - val_loss: 17.3984 - val_acc: 0.3017\n",
      "Epoch 2/5\n",
      "102991/102991 [==============================] - 267s 3ms/step - loss: 8.7702 - acc: 0.4253 - val_loss: 17.5812 - val_acc: 0.2949\n",
      "Epoch 3/5\n",
      "102991/102991 [==============================] - 268s 3ms/step - loss: 8.8820 - acc: 0.4233 - val_loss: 17.2829 - val_acc: 0.3012\n",
      "Epoch 4/5\n",
      "102991/102991 [==============================] - 268s 3ms/step - loss: 8.9127 - acc: 0.4228 - val_loss: 17.6257 - val_acc: 0.2976\n",
      "Epoch 5/5\n",
      "102991/102991 [==============================] - 268s 3ms/step - loss: 8.8021 - acc: 0.4242 - val_loss: 17.6668 - val_acc: 0.2973\n",
      "9353/9353 [==============================] - 7s 750us/step\n",
      "Test score: 17.66684240506165\n",
      "Test accuracy: 0.29733775261186934\n"
     ]
    }
   ],
   "source": [
    "# Setup model checkpoints\n",
    "checkpoint_35 = ModelCheckpoint(\"checkpoints/reddit-35epochs.hdf5\")\n",
    "checkpoint_40 = ModelCheckpoint(\"checkpoints/reddit-40epochs.hdf5\")\n",
    "checkpoint_45 = ModelCheckpoint(\"checkpoints/reddit-45epochs.hdf5\")\n",
    "checkpoint_50 = ModelCheckpoint(\"checkpoints/reddit-50epochs.hdf5\")\n",
    "\n",
    "# Load model trained for 30 epochs\n",
    "#model = Model(inputs=sequence_input, outputs=X)\n",
    "#model.load_weights(\"checkpoints/reddit-30epochs.hdf5\")\n",
    "#model.compile(loss='mean_squared_error',\n",
    "#                   optimizer='adam',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_35])\n",
    "score, acc = model.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_40])\n",
    "score, acc = model.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_45])\n",
    "score, acc = model.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Run the model 5 more epochs\n",
    "model.fit(x_train, \n",
    "              y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[checkpoint_50])\n",
    "score, acc = model.evaluate(x_test, \n",
    "                                y_test,\n",
    "                                batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9353/9353 [==============================] - 6s 688us/step\n",
      "Test score: 16.070277795706996\n",
      "Test accuracy: 0.2945578958654766\n",
      "9353/9353 [==============================] - 6s 691us/step\n",
      "Test score: 16.372327475270957\n",
      "Test accuracy: 0.29968993906654623\n",
      "9353/9353 [==============================] - 6s 664us/step\n",
      "Test score: 17.014482662612252\n",
      "Test accuracy: 0.2974446701847983\n",
      "9353/9353 [==============================] - 6s 678us/step\n",
      "Test score: 17.074238077785886\n",
      "Test accuracy: 0.2977654228621621\n",
      "9353/9353 [==============================] - 6s 685us/step\n",
      "Test score: 17.288187443553657\n",
      "Test accuracy: 0.29787234045102307\n",
      "9353/9353 [==============================] - 6s 681us/step\n",
      "Test score: 17.66684240506165\n",
      "Test accuracy: 0.29733775261186934\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# After 25 epochs\n",
    "###################################################################\n",
    "model_25 = Model(inputs=sequence_input, outputs=X)\n",
    "model_25.load_weights(\"checkpoints/reddit-25epochs.hdf5\")\n",
    "model_25.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_25, acc_25 = model_25.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_25 = model_25.predict(x_test)\n",
    "print('Test score:', score_25)\n",
    "print('Test accuracy:', acc_25)\n",
    "                     \n",
    "###################################################################\n",
    "# After 30 epochs\n",
    "###################################################################\n",
    "model_30 = Model(inputs=sequence_input, outputs=X)\n",
    "model_30.load_weights(\"checkpoints/reddit-30epochs.hdf5\")\n",
    "model_30.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_30, acc_30 = model_30.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_30 = model_30.predict(x_test)\n",
    "print('Test score:', score_30)\n",
    "print('Test accuracy:', acc_30)\n",
    "\n",
    "###################################################################\n",
    "# After 35 epochs\n",
    "###################################################################\n",
    "model_35 = Model(inputs=sequence_input, outputs=X)\n",
    "model_35.load_weights(\"checkpoints/reddit-35epochs.hdf5\")\n",
    "model_35.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_35, acc_35 = model_35.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_35 = model_35.predict(x_test)\n",
    "print('Test score:', score_35)\n",
    "print('Test accuracy:', acc_35)\n",
    "\n",
    "###################################################################\n",
    "# After 40 epochs\n",
    "###################################################################\n",
    "model_40 = Model(inputs=sequence_input, outputs=X)\n",
    "model_40.load_weights(\"checkpoints/reddit-40epochs.hdf5\")\n",
    "model_40.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_40, acc_40 = model_40.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_40 = model_40.predict(x_test)\n",
    "print('Test score:', score_40)\n",
    "print('Test accuracy:', acc_40)\n",
    "\n",
    "###################################################################\n",
    "# After 45 epochs\n",
    "###################################################################\n",
    "model_45 = Model(inputs=sequence_input, outputs=X)\n",
    "model_45.load_weights(\"checkpoints/reddit-45epochs.hdf5\")\n",
    "model_45.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_45, acc_45 = model_45.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_45 = model_45.predict(x_test)\n",
    "print('Test score:', score_45)\n",
    "print('Test accuracy:', acc_45)\n",
    "\n",
    "###################################################################\n",
    "# After 50 epochs\n",
    "###################################################################\n",
    "model_50 = Model(inputs=sequence_input, outputs=X)\n",
    "model_50.load_weights(\"checkpoints/reddit-50epochs.hdf5\")\n",
    "model_50.compile(loss='mean_squared_error',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "score_50, acc_50 = model_50.evaluate(x_test,\n",
    "                                     y_test,\n",
    "                                     batch_size=batch_size)\n",
    "predictions_50 = model_50.predict(x_test)\n",
    "print('Test score:', score_50)\n",
    "print('Test accuracy:', acc_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, organize predictions from each number of epochs trained and print summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER 5 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0016\tMin: -0.5099\t25%: -0.0526\t75%: 0.0563\tMax: 0.4240\n",
      "[+02 hr]\tMean: -0.0169\tMin: -1.1717\t25%: -0.0967\t75%: 0.0857\tMax: 0.6935\n",
      "[+06 hr]\tMean: -0.0489\tMin: -3.5835\t25%: -0.2591\t75%: 0.2376\tMax: 2.0855\n",
      "[+12 hr]\tMean: 0.0731\tMin: -5.0648\t25%: -0.2217\t75%: 0.4868\tMax: 3.2930\n",
      "[+24 hr]\tMean: 0.2044\tMin: -6.6731\t25%: -0.2935\t75%: 0.8264\tMax: 5.0350\n",
      "\n",
      "AFTER 10 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0038\tMin: -1.0934\t25%: -0.1078\t75%: 0.1062\tMax: 1.2742\n",
      "[+02 hr]\tMean: 0.0006\tMin: -1.9020\t25%: -0.1836\t75%: 0.1935\tMax: 2.1993\n",
      "[+06 hr]\tMean: 0.1161\tMin: -5.1217\t25%: -0.3555\t75%: 0.6187\tMax: 7.1562\n",
      "[+12 hr]\tMean: 0.3042\tMin: -7.8008\t25%: -0.4166\t75%: 1.0788\tMax: 11.0008\n",
      "[+24 hr]\tMean: 0.5430\tMin: -11.6989\t25%: -0.5509\t75%: 1.6453\tMax: 16.8220\n",
      "\n",
      "AFTER 15 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0095\tMin: -1.0554\t25%: -0.1453\t75%: 0.1572\tMax: 2.0788\n",
      "[+02 hr]\tMean: 0.0240\tMin: -2.0851\t25%: -0.2614\t75%: 0.2964\tMax: 3.9714\n",
      "[+06 hr]\tMean: 0.1091\tMin: -5.7407\t25%: -0.6516\t75%: 0.8565\tMax: 12.8148\n",
      "[+12 hr]\tMean: 0.2379\tMin: -8.8841\t25%: -0.9618\t75%: 1.4154\tMax: 20.2545\n",
      "[+24 hr]\tMean: 0.4827\tMin: -12.7883\t25%: -1.3330\t75%: 2.2894\tMax: 31.2125\n",
      "\n",
      "AFTER 20 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0083\tMin: -1.7148\t25%: -0.1708\t75%: 0.1889\tMax: 2.0235\n",
      "[+02 hr]\tMean: 0.0247\tMin: -3.1579\t25%: -0.3116\t75%: 0.3677\tMax: 3.9479\n",
      "[+06 hr]\tMean: 0.0750\tMin: -8.4925\t25%: -0.8149\t75%: 0.9873\tMax: 10.6848\n",
      "[+12 hr]\tMean: 0.1943\tMin: -13.4585\t25%: -1.1814\t75%: 1.6063\tMax: 16.5318\n",
      "[+24 hr]\tMean: 0.3999\tMin: -20.8024\t25%: -1.7231\t75%: 2.5379\tMax: 24.2583\n",
      "\n",
      "AFTER 25 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0199\tMin: -1.6096\t25%: -0.2061\t75%: 0.1643\tMax: 2.3653\n",
      "[+02 hr]\tMean: -0.0097\tMin: -2.9805\t25%: -0.3643\t75%: 0.3389\tMax: 4.8466\n",
      "[+06 hr]\tMean: 0.0127\tMin: -8.3737\t25%: -0.9683\t75%: 0.9889\tMax: 13.8852\n",
      "[+12 hr]\tMean: 0.1225\tMin: -12.7328\t25%: -1.4215\t75%: 1.6545\tMax: 21.9007\n",
      "[+24 hr]\tMean: 0.2836\tMin: -19.8572\t25%: -2.0983\t75%: 2.6201\tMax: 33.6513\n",
      "\n",
      "AFTER 30 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0267\tMin: -1.6285\t25%: -0.2254\t75%: 0.1713\tMax: 1.8831\n",
      "[+02 hr]\tMean: -0.0258\tMin: -3.1211\t25%: -0.4102\t75%: 0.3478\tMax: 3.6020\n",
      "[+06 hr]\tMean: 0.0161\tMin: -8.5786\t25%: -1.0104\t75%: 1.0217\tMax: 10.3535\n",
      "[+12 hr]\tMean: 0.1515\tMin: -13.6094\t25%: -1.4843\t75%: 1.7474\tMax: 16.3117\n",
      "[+24 hr]\tMean: 0.3718\tMin: -20.5744\t25%: -2.1633\t75%: 2.8576\tMax: 25.0378\n",
      "\n",
      "AFTER 35 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0199\tMin: -1.6105\t25%: -0.2309\t75%: 0.1905\tMax: 2.5283\n",
      "[+02 hr]\tMean: -0.0300\tMin: -3.0202\t25%: -0.4220\t75%: 0.3645\tMax: 4.3922\n",
      "[+06 hr]\tMean: 0.0166\tMin: -8.0679\t25%: -1.0751\t75%: 1.0757\tMax: 12.7491\n",
      "[+12 hr]\tMean: 0.1198\tMin: -12.6574\t25%: -1.6126\t75%: 1.8018\tMax: 19.6796\n",
      "[+24 hr]\tMean: 0.2362\tMin: -19.6729\t25%: -2.4548\t75%: 2.8481\tMax: 30.0543\n",
      "\n",
      "AFTER 40 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0025\tMin: -1.5563\t25%: -0.2123\t75%: 0.2094\tMax: 2.5599\n",
      "[+02 hr]\tMean: -0.0149\tMin: -2.8978\t25%: -0.4258\t75%: 0.3734\tMax: 5.0627\n",
      "[+06 hr]\tMean: -0.0157\tMin: -7.5951\t25%: -1.1343\t75%: 1.0313\tMax: 13.3318\n",
      "[+12 hr]\tMean: 0.1028\tMin: -11.5503\t25%: -1.6818\t75%: 1.7641\tMax: 20.8150\n",
      "[+24 hr]\tMean: 0.2596\tMin: -18.4420\t25%: -2.4811\t75%: 2.8455\tMax: 31.9001\n",
      "\n",
      "AFTER 45 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: 0.0179\tMin: -1.6933\t25%: -0.1988\t75%: 0.2261\tMax: 2.0692\n",
      "[+02 hr]\tMean: 0.0054\tMin: -3.2071\t25%: -0.4170\t75%: 0.4113\tMax: 4.0034\n",
      "[+06 hr]\tMean: 0.1220\tMin: -8.4225\t25%: -1.0404\t75%: 1.2448\tMax: 10.7114\n",
      "[+12 hr]\tMean: 0.3144\tMin: -13.4573\t25%: -1.4933\t75%: 2.0865\tMax: 16.4406\n",
      "[+24 hr]\tMean: 0.5666\tMin: -20.4607\t25%: -2.2680\t75%: 3.2897\tMax: 24.8885\n",
      "\n",
      "AFTER 50 EPOCHS TRAINING\n",
      "[+01 hr]\tMean: -0.0022\tMin: -1.3711\t25%: -0.2149\t75%: 0.2062\tMax: 2.2990\n",
      "[+02 hr]\tMean: 0.0337\tMin: -2.6266\t25%: -0.3799\t75%: 0.4446\tMax: 4.4464\n",
      "[+06 hr]\tMean: 0.0683\tMin: -7.8864\t25%: -1.0717\t75%: 1.2032\tMax: 12.1061\n",
      "[+12 hr]\tMean: 0.1842\tMin: -11.6952\t25%: -1.6180\t75%: 1.9870\tMax: 18.8141\n",
      "[+24 hr]\tMean: 0.3985\tMin: -17.7805\t25%: -2.3829\t75%: 3.1900\tMax: 29.0723\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# 1/2: CHANGE if more epochs added\n",
    "###############################################################\n",
    "\n",
    "# To iterate through training epochs\n",
    "epochs = ['05 epochs', '10 epochs', '15 epochs', '20 epochs', \\\n",
    "          '25 epochs', '30 epochs', '35 epochs', '40 epochs', \\\n",
    "          '45 epochs', '50 epochs']\n",
    "\n",
    "# Object 1: To zip all dfs together later\n",
    "all_dfs = (reddit_test_df.values, \\\n",
    "           predictions_5, \\\n",
    "           predictions_10, \\\n",
    "           predictions_15, \\\n",
    "           predictions_20, \\\n",
    "           predictions_25, \\\n",
    "           predictions_30, \\\n",
    "           predictions_35, \\\n",
    "           predictions_40, \\\n",
    "           predictions_45, \\\n",
    "           predictions_50)\n",
    "\n",
    "# Object 2: To print below\n",
    "all_predictions = [('AFTER 5 EPOCHS TRAINING', predictions_5),\n",
    "                   ('AFTER 10 EPOCHS TRAINING', predictions_10),\n",
    "                   ('AFTER 15 EPOCHS TRAINING', predictions_15),\n",
    "                   ('AFTER 20 EPOCHS TRAINING', predictions_20),\n",
    "                   ('AFTER 25 EPOCHS TRAINING', predictions_25),\n",
    "                   ('AFTER 30 EPOCHS TRAINING', predictions_30), \n",
    "                   ('AFTER 35 EPOCHS TRAINING', predictions_35), \n",
    "                   ('AFTER 40 EPOCHS TRAINING', predictions_40), \n",
    "                   ('AFTER 45 EPOCHS TRAINING', predictions_45), \n",
    "                   ('AFTER 50 EPOCHS TRAINING', predictions_50)]\n",
    "\n",
    "###############################################################\n",
    "# 2/2: DON'T CHANGE if more epochs added\n",
    "###############################################################\n",
    "\n",
    "# Loop through each set and print summary\\n\",\n",
    "for description, prediction in all_predictions:\n",
    "    pred_1hr, summary_1hr = prediction[:,0], pd.Series(np.squeeze(prediction[:,0])).describe()\n",
    "    pred_2hr, summary_2hr = prediction[:,1], pd.Series(np.squeeze(prediction[:,1])).describe()\n",
    "    pred_6hr, summary_6hr = prediction[:,2], pd.Series(np.squeeze(prediction[:,2])).describe()\n",
    "    pred_12hr, summary_12hr = prediction[:,3], pd.Series(np.squeeze(prediction[:,3])).describe()\n",
    "    pred_24hr, summary_24hr = prediction[:,4], pd.Series(np.squeeze(prediction[:,4])).describe()\n",
    "\n",
    "    print('\\n%s' % description)\n",
    "    print('[+01 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_1hr['mean'], summary_1hr['min'], summary_1hr['25%'], summary_1hr['75%'], summary_1hr['max']))\n",
    "    print('[+02 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_2hr['mean'], summary_2hr['min'], summary_2hr['25%'], summary_2hr['75%'], summary_2hr['max']))\n",
    "    print('[+06 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_6hr['mean'], summary_6hr['min'], summary_6hr['25%'], summary_6hr['75%'], summary_6hr['max']))\n",
    "    print('[+12 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_12hr['mean'], summary_12hr['min'], summary_12hr['25%'], summary_12hr['75%'], summary_12hr['max']))\n",
    "    print('[+24 hr]\\tMean: %.4f\\tMin: %.4f\\t25%%: %.4f\\t75%%: %.4f\\tMax: %.4f' % \\\n",
    "          (summary_24hr['mean'], summary_24hr['min'], summary_24hr['25%'], summary_24hr['75%'], summary_24hr['max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, check prediction performance:\n",
    "- How many of the largest (positive) ACTUAL price changes did we PREDICT correctly\n",
    "- How many of the largest (negative) ACTUAL price changes did we PREDICT correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1hr] Top cutoff: 0.9864, Bottom cutoff: -0.7630\n",
      "[2hr] Top cutoff: 1.3951, Bottom cutoff: -1.1409\n",
      "[6hr] Top cutoff: 2.5950, Bottom cutoff: -1.6548\n",
      "[12hr] Top cutoff: 3.8299, Bottom cutoff: -2.4704\n",
      "[24hr] Top cutoff: 6.0746, Bottom cutoff: -2.8883\n"
     ]
    }
   ],
   "source": [
    "# Prediction times\n",
    "prediction_times = ['1hr', '2hr', '6hr', '12hr', '24hr']\n",
    "\n",
    "# Indices of columns in test df and prediction dfs\n",
    "actual_columns = {'date' : 0, 'title' : 4, '1hr' : 5, '2hr' : 6, '6hr' : 7, '12hr' : 8, '24hr' : 9}\n",
    "pred_columns = {'1hr' : 0, '2hr' : 1, '6hr' : 2, '12hr' : 3, '24hr' : 4}\n",
    "\n",
    "# Set cutoffs to only consider largest (positive) price changes\n",
    "pos_percent = 0.80 # Means will consider top 20%\n",
    "pos_1hr = pd.Series(np.squeeze(reddit_test_df['1hr_change'])).quantile(pos_percent)\n",
    "pos_2hr = pd.Series(np.squeeze(reddit_test_df['2hr_change'])).quantile(pos_percent)\n",
    "pos_6hr = pd.Series(np.squeeze(reddit_test_df['6hr_change'])).quantile(pos_percent)\n",
    "pos_12hr = pd.Series(np.squeeze(reddit_test_df['12hr_change'])).quantile(pos_percent)\n",
    "pos_24hr = pd.Series(np.squeeze(reddit_test_df['24hr_change'])).quantile(pos_percent)\n",
    "pos_cutoffs = {'1hr' : pos_1hr, '2hr' : pos_2hr, '6hr' : pos_6hr, '12hr' : pos_12hr, '24hr' : pos_24hr} \n",
    "\n",
    "# Set cutoffs to only consider largest (negative) price changes\n",
    "neg_percent = 0.20 # Means will consider bottom 20%\n",
    "neg_1hr = pd.Series(np.squeeze(reddit_test_df['1hr_change'])).quantile(neg_percent)\n",
    "neg_2hr = pd.Series(np.squeeze(reddit_test_df['2hr_change'])).quantile(neg_percent)\n",
    "neg_6hr = pd.Series(np.squeeze(reddit_test_df['6hr_change'])).quantile(neg_percent)\n",
    "neg_12hr = pd.Series(np.squeeze(reddit_test_df['12hr_change'])).quantile(neg_percent)\n",
    "neg_24hr = pd.Series(np.squeeze(reddit_test_df['24hr_change'])).quantile(neg_percent)\n",
    "neg_cutoffs = {'1hr' : neg_1hr, '2hr' : neg_2hr, '6hr' : neg_6hr, '12hr' : neg_12hr, '24hr' : neg_24hr} \n",
    "\n",
    "# Print\n",
    "for time in prediction_times:\n",
    "    print ('[%s] Top cutoff: %.4f, Bottom cutoff: %.4f' % (time, pos_cutoffs[time], neg_cutoffs[time]))\n",
    "\n",
    "# Initial state of prediction counts\n",
    "initial_pred_counts = {}\n",
    "for epoch in epochs:\n",
    "    initial_pred_counts[epoch] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** PREDICTIONS +1hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 0.99%): 1881\n",
      "[05 epochs train] Above cutoff: 0 (0.00%), Positive: 991 (52.68%)\n",
      "[10 epochs train] Above cutoff: 1 (0.05%), Positive: 996 (52.95%)\n",
      "[15 epochs train] Above cutoff: 4 (0.21%), Positive: 982 (52.21%)\n",
      "[20 epochs train] Above cutoff: 9 (0.48%), Positive: 978 (51.99%)\n",
      "[25 epochs train] Above cutoff: 10 (0.53%), Positive: 879 (46.73%)\n",
      "[30 epochs train] Above cutoff: 7 (0.37%), Positive: 905 (48.11%)\n",
      "[35 epochs train] Above cutoff: 9 (0.48%), Positive: 894 (47.53%)\n",
      "[40 epochs train] Above cutoff: 9 (0.48%), Positive: 958 (50.93%)\n",
      "[45 epochs train] Above cutoff: 18 (0.96%), Positive: 1018 (54.12%)\n",
      "[50 epochs train] Above cutoff: 9 (0.48%), Positive: 989 (52.58%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -0.76%): 1881\n",
      "[05 epochs train] Below cutoff: 0 (0.00%), Negative: 886 (47.10%)\n",
      "[10 epochs train] Below cutoff: 4 (0.21%), Negative: 903 (48.01%)\n",
      "[15 epochs train] Below cutoff: 7 (0.37%), Negative: 897 (47.69%)\n",
      "[20 epochs train] Below cutoff: 13 (0.69%), Negative: 889 (47.26%)\n",
      "[25 epochs train] Below cutoff: 17 (0.90%), Negative: 992 (52.74%)\n",
      "[30 epochs train] Below cutoff: 25 (1.33%), Negative: 1023 (54.39%)\n",
      "[35 epochs train] Below cutoff: 28 (1.49%), Negative: 1002 (53.27%)\n",
      "[40 epochs train] Below cutoff: 37 (1.97%), Negative: 917 (48.75%)\n",
      "[45 epochs train] Below cutoff: 28 (1.49%), Negative: 881 (46.84%)\n",
      "[50 epochs train] Below cutoff: 33 (1.75%), Negative: 949 (50.45%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 12 days (42.86%)\n",
      "[10 epochs train] Correct aggregated predictions: 12 days (42.86%)\n",
      "[15 epochs train] Correct aggregated predictions: 12 days (42.86%)\n",
      "[20 epochs train] Correct aggregated predictions: 14 days (50.00%)\n",
      "[25 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[30 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[35 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[40 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[45 epochs train] Correct aggregated predictions: 13 days (46.43%)\n",
      "[50 epochs train] Correct aggregated predictions: 13 days (46.43%)\n",
      "\n",
      "***** PREDICTIONS +2hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 1.40%): 1871\n",
      "[05 epochs train] Above cutoff: 0 (0.00%), Positive: 924 (49.39%)\n",
      "[10 epochs train] Above cutoff: 5 (0.27%), Positive: 967 (51.68%)\n",
      "[15 epochs train] Above cutoff: 17 (0.91%), Positive: 962 (51.42%)\n",
      "[20 epochs train] Above cutoff: 37 (1.98%), Positive: 974 (52.06%)\n",
      "[25 epochs train] Above cutoff: 33 (1.76%), Positive: 906 (48.42%)\n",
      "[30 epochs train] Above cutoff: 34 (1.82%), Positive: 916 (48.96%)\n",
      "[35 epochs train] Above cutoff: 35 (1.87%), Positive: 893 (47.73%)\n",
      "[40 epochs train] Above cutoff: 44 (2.35%), Positive: 912 (48.74%)\n",
      "[45 epochs train] Above cutoff: 48 (2.57%), Positive: 934 (49.92%)\n",
      "[50 epochs train] Above cutoff: 51 (2.73%), Positive: 994 (53.13%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -1.14%): 1875\n",
      "[05 epochs train] Below cutoff: 0 (0.00%), Negative: 897 (47.84%)\n",
      "[10 epochs train] Below cutoff: 12 (0.64%), Negative: 897 (47.84%)\n",
      "[15 epochs train] Below cutoff: 23 (1.23%), Negative: 860 (45.87%)\n",
      "[20 epochs train] Below cutoff: 47 (2.51%), Negative: 865 (46.13%)\n",
      "[25 epochs train] Below cutoff: 55 (2.93%), Negative: 945 (50.40%)\n",
      "[30 epochs train] Below cutoff: 75 (4.00%), Negative: 962 (51.31%)\n",
      "[35 epochs train] Below cutoff: 84 (4.48%), Negative: 980 (52.27%)\n",
      "[40 epochs train] Below cutoff: 81 (4.32%), Negative: 953 (50.83%)\n",
      "[45 epochs train] Below cutoff: 80 (4.27%), Negative: 912 (48.64%)\n",
      "[50 epochs train] Below cutoff: 80 (4.27%), Negative: 863 (46.03%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 12 days (42.86%)\n",
      "[10 epochs train] Correct aggregated predictions: 14 days (50.00%)\n",
      "[15 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[20 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[25 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[30 epochs train] Correct aggregated predictions: 12 days (42.86%)\n",
      "[35 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[40 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[45 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[50 epochs train] Correct aggregated predictions: 19 days (67.86%)\n",
      "\n",
      "***** PREDICTIONS +6hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 2.60%): 1875\n",
      "[05 epochs train] Above cutoff: 0 (0.00%), Positive: 980 (52.27%)\n",
      "[10 epochs train] Above cutoff: 19 (1.01%), Positive: 1058 (56.43%)\n",
      "[15 epochs train] Above cutoff: 69 (3.68%), Positive: 1021 (54.45%)\n",
      "[20 epochs train] Above cutoff: 117 (6.24%), Positive: 1010 (53.87%)\n",
      "[25 epochs train] Above cutoff: 132 (7.04%), Positive: 954 (50.88%)\n",
      "[30 epochs train] Above cutoff: 149 (7.95%), Positive: 971 (51.79%)\n",
      "[35 epochs train] Above cutoff: 156 (8.32%), Positive: 947 (50.51%)\n",
      "[40 epochs train] Above cutoff: 156 (8.32%), Positive: 959 (51.15%)\n",
      "[45 epochs train] Above cutoff: 171 (9.12%), Positive: 982 (52.37%)\n",
      "[50 epochs train] Above cutoff: 173 (9.23%), Positive: 967 (51.57%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -1.65%): 1881\n",
      "[05 epochs train] Below cutoff: 24 (1.28%), Negative: 924 (49.12%)\n",
      "[10 epochs train] Below cutoff: 71 (3.77%), Negative: 811 (43.12%)\n",
      "[15 epochs train] Below cutoff: 157 (8.35%), Negative: 875 (46.52%)\n",
      "[20 epochs train] Below cutoff: 219 (11.64%), Negative: 897 (47.69%)\n",
      "[25 epochs train] Below cutoff: 265 (14.09%), Negative: 944 (50.19%)\n",
      "[30 epochs train] Below cutoff: 282 (14.99%), Negative: 952 (50.61%)\n",
      "[35 epochs train] Below cutoff: 298 (15.84%), Negative: 939 (49.92%)\n",
      "[40 epochs train] Below cutoff: 327 (17.38%), Negative: 950 (50.51%)\n",
      "[45 epochs train] Below cutoff: 282 (14.99%), Negative: 878 (46.68%)\n",
      "[50 epochs train] Below cutoff: 301 (16.00%), Negative: 897 (47.69%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 10 days (35.71%)\n",
      "[10 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[15 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[20 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[25 epochs train] Correct aggregated predictions: 20 days (71.43%)\n",
      "[30 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[35 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[40 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[45 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[50 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "\n",
      "***** PREDICTIONS +12hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 3.83%): 1883\n",
      "[05 epochs train] Above cutoff: 0 (0.00%), Positive: 1160 (61.60%)\n",
      "[10 epochs train] Above cutoff: 14 (0.74%), Positive: 1183 (62.83%)\n",
      "[15 epochs train] Above cutoff: 80 (4.25%), Positive: 1055 (56.03%)\n",
      "[20 epochs train] Above cutoff: 113 (6.00%), Positive: 1048 (55.66%)\n",
      "[25 epochs train] Above cutoff: 152 (8.07%), Positive: 1014 (53.85%)\n",
      "[30 epochs train] Above cutoff: 158 (8.39%), Positive: 1026 (54.49%)\n",
      "[35 epochs train] Above cutoff: 179 (9.51%), Positive: 996 (52.89%)\n",
      "[40 epochs train] Above cutoff: 168 (8.92%), Positive: 983 (52.20%)\n",
      "[45 epochs train] Above cutoff: 214 (11.36%), Positive: 1015 (53.90%)\n",
      "[50 epochs train] Above cutoff: 207 (10.99%), Positive: 988 (52.47%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -2.47%): 1876\n",
      "[05 epochs train] Below cutoff: 24 (1.28%), Negative: 723 (38.54%)\n",
      "[10 epochs train] Below cutoff: 68 (3.62%), Negative: 716 (38.17%)\n",
      "[15 epochs train] Below cutoff: 177 (9.43%), Negative: 857 (45.68%)\n",
      "[20 epochs train] Below cutoff: 228 (12.15%), Negative: 880 (46.91%)\n",
      "[25 epochs train] Below cutoff: 265 (14.13%), Negative: 921 (49.09%)\n",
      "[30 epochs train] Below cutoff: 299 (15.94%), Negative: 917 (48.88%)\n",
      "[35 epochs train] Below cutoff: 313 (16.68%), Negative: 938 (50.00%)\n",
      "[40 epochs train] Below cutoff: 303 (16.15%), Negative: 906 (48.29%)\n",
      "[45 epochs train] Below cutoff: 287 (15.30%), Negative: 861 (45.90%)\n",
      "[50 epochs train] Below cutoff: 301 (16.04%), Negative: 874 (46.59%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[10 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[15 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[20 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[25 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[30 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[35 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[40 epochs train] Correct aggregated predictions: 19 days (67.86%)\n",
      "[45 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[50 epochs train] Correct aggregated predictions: 15 days (53.57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** PREDICTIONS +24hr IN FUTURE *****\n",
      "\n",
      "Num ACTUAL in top 20% (change >= 6.07%): 1877\n",
      "[05 epochs train] Above cutoff: 0 (0.00%), Positive: 1212 (64.57%)\n",
      "[10 epochs train] Above cutoff: 12 (0.64%), Positive: 1193 (63.56%)\n",
      "[15 epochs train] Above cutoff: 66 (3.52%), Positive: 1061 (56.53%)\n",
      "[20 epochs train] Above cutoff: 110 (5.86%), Positive: 1029 (54.82%)\n",
      "[25 epochs train] Above cutoff: 123 (6.55%), Positive: 1006 (53.60%)\n",
      "[30 epochs train] Above cutoff: 151 (8.04%), Positive: 1034 (55.09%)\n",
      "[35 epochs train] Above cutoff: 170 (9.06%), Positive: 995 (53.01%)\n",
      "[40 epochs train] Above cutoff: 167 (8.90%), Positive: 990 (52.74%)\n",
      "[45 epochs train] Above cutoff: 193 (10.28%), Positive: 1004 (53.49%)\n",
      "[50 epochs train] Above cutoff: 214 (11.40%), Positive: 1012 (53.92%)\n",
      "\n",
      "Num ACTUAL in bottom 20% (change <= -2.89%): 1875\n",
      "[05 epochs train] Below cutoff: 25 (1.33%), Negative: 665 (35.47%)\n",
      "[10 epochs train] Below cutoff: 82 (4.37%), Negative: 701 (37.39%)\n",
      "[15 epochs train] Below cutoff: 235 (12.53%), Negative: 807 (43.04%)\n",
      "[20 epochs train] Below cutoff: 312 (16.64%), Negative: 839 (44.75%)\n",
      "[25 epochs train] Below cutoff: 350 (18.67%), Negative: 909 (48.48%)\n",
      "[30 epochs train] Below cutoff: 385 (20.53%), Negative: 912 (48.64%)\n",
      "[35 epochs train] Below cutoff: 410 (21.87%), Negative: 927 (49.44%)\n",
      "[40 epochs train] Below cutoff: 409 (21.81%), Negative: 915 (48.80%)\n",
      "[45 epochs train] Below cutoff: 382 (20.37%), Negative: 825 (44.00%)\n",
      "[50 epochs train] Below cutoff: 401 (21.39%), Negative: 857 (45.71%)\n",
      "\n",
      "Total days in test set: 28\n",
      "[05 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[10 epochs train] Correct aggregated predictions: 16 days (57.14%)\n",
      "[15 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[20 epochs train] Correct aggregated predictions: 17 days (60.71%)\n",
      "[25 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[30 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[35 epochs train] Correct aggregated predictions: 15 days (53.57%)\n",
      "[40 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[45 epochs train] Correct aggregated predictions: 18 days (64.29%)\n",
      "[50 epochs train] Correct aggregated predictions: 18 days (64.29%)\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# Loop through each prediction time\n",
    "###############################################################\n",
    "for time in prediction_times:\n",
    "       \n",
    "    # To keep track of (largest positive) counts\n",
    "    num_actual_above = 0\n",
    "    num_pred_above, num_pred_positive = initial_pred_counts.copy(), initial_pred_counts.copy()\n",
    "    per_pred_above, per_pred_positive = initial_pred_counts.copy(), initial_pred_counts.copy() \n",
    "    \n",
    "    # To keep track of (largest negative) counts\n",
    "    num_actual_below = 0\n",
    "    num_pred_below, num_pred_negative = initial_pred_counts.copy(), initial_pred_counts.copy()\n",
    "    per_pred_below, per_pred_negative = initial_pred_counts.copy(), initial_pred_counts.copy() \n",
    "    \n",
    "    # To keep track of cummulative daily predictions\n",
    "    total_days = 1\n",
    "    preds_tally, correct_days, per_correct_days = \\\n",
    "        initial_pred_counts.copy(), initial_pred_counts.copy(), initial_pred_counts.copy()\n",
    "    current_date = reddit_test_df.values[0][actual_columns['date']].split(' ')[0]\n",
    "    \n",
    "    #########################################\n",
    "    # Loop through each row in actual test df and prediction dfs\n",
    "    #########################################\n",
    "    for all_items in zip(*all_dfs):\n",
    "    \n",
    "        # Separate \n",
    "        i, preds = 0, {}\n",
    "        actual = all_items[i]\n",
    "        for epoch in epochs:\n",
    "            i += 1\n",
    "            preds[epoch] = all_items[i]\n",
    "        \n",
    "        # Check if actual value >= top cutoff\n",
    "        if actual[actual_columns[time]] >= pos_cutoffs[time]:\n",
    "            # Increment actual count\n",
    "            num_actual_above += 1\n",
    "            # Loop through each set of predictions\n",
    "            for epoch in epochs:\n",
    "                # If prediction >= cutoff   \n",
    "                if preds[epoch][pred_columns[time]] >= pos_cutoffs[time]: num_pred_above[epoch] += 1\n",
    "                # If prediction positive   \n",
    "                if preds[epoch][pred_columns[time]] >= 0: num_pred_positive[epoch] += 1\n",
    "    \n",
    "        # Check if actual value <= bottom cutoff\n",
    "        if actual[actual_columns[time]] <= neg_cutoffs[time]:\n",
    "            # Increment actual count\n",
    "            num_actual_below += 1\n",
    "            # Loop through each set of predictions\n",
    "            for epoch in epochs:\n",
    "                # If prediction >= cutoff   \n",
    "                if preds[epoch][pred_columns[time]] <= neg_cutoffs[time]: num_pred_below[epoch] += 1\n",
    "                # If prediction negative   \n",
    "                if preds[epoch][pred_columns[time]] <= 0: num_pred_negative[epoch] += 1\n",
    "    \n",
    "        # Isolate date of current row\n",
    "        new_date = actual[actual_columns['date']].split(' ')[0]\n",
    "     \n",
    "        # If moved to new date\n",
    "        if not new_date == current_date:\n",
    "            # Check prediction tallys vs actual price changes\n",
    "            for epoch in epochs:\n",
    "                if np.sign(preds_tally[epoch]) == np.sign(actual[actual_columns[time]]):\n",
    "                    correct_days[epoch] += 1\n",
    "            # Update total day count, reset tally, change current_day\n",
    "            total_days += 1\n",
    "            preds_tally = initial_pred_counts.copy()\n",
    "            current_date = new_date\n",
    "    \n",
    "        # Update prediction tallys\n",
    "        for epoch in epochs:\n",
    "            preds_tally[epoch] += preds[epoch][pred_columns[time]]\n",
    "    \n",
    "    #########################################          \n",
    "    # Calculate percentage of correct predictions\n",
    "    #########################################          \n",
    "    for epoch in epochs:\n",
    "        per_pred_above[epoch] = (num_pred_above[epoch] / num_actual_above) * 100\n",
    "        per_pred_positive[epoch] = (num_pred_positive[epoch] / num_actual_above) * 100   \n",
    "        per_pred_below[epoch] = (num_pred_below[epoch] / num_actual_below) * 100\n",
    "        per_pred_negative[epoch] = (num_pred_negative[epoch] / num_actual_below) * 100   \n",
    "        per_correct_days[epoch] = (correct_days[epoch] / total_days) * 100\n",
    "        \n",
    "    #########################################          \n",
    "    # Print results\n",
    "    #########################################   \n",
    "    print ('\\n***** PREDICTIONS +%s IN FUTURE *****' % time)\n",
    "    \n",
    "    print ('\\nNum ACTUAL in top %d%% (change >= %.2f%%): %d' % \\\n",
    "        (100-int(pos_percent*100), pos_cutoffs[time], num_actual_above))           \n",
    "    for epoch in epochs:\n",
    "        print ('[%s train] Above cutoff: %d (%.2f%%), Positive: %d (%.2f%%)' % \\\n",
    "            (epoch, num_pred_above[epoch], per_pred_above[epoch], num_pred_positive[epoch], per_pred_positive[epoch]))\n",
    "        \n",
    "    print ('\\nNum ACTUAL in bottom %d%% (change <= %.2f%%): %d' % \\\n",
    "        (int(neg_percent*100), neg_cutoffs[time], num_actual_below))           \n",
    "    for epoch in epochs:\n",
    "        print ('[%s train] Below cutoff: %d (%.2f%%), Negative: %d (%.2f%%)' % \\\n",
    "            (epoch, num_pred_below[epoch], per_pred_below[epoch], num_pred_negative[epoch], per_pred_negative[epoch]))\n",
    "    \n",
    "    print ('\\nTotal days in test set: %d' % (total_days))           \n",
    "    for epoch in epochs:\n",
    "        print ('[%s train] Correct aggregated predictions: %d days (%.2f%%)' % \\\n",
    "            (epoch, correct_days[epoch], per_correct_days[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
